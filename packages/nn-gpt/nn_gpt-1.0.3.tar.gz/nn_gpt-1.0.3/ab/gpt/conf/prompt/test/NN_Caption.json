{
  "improvement_captioning_structural": {
    "comment": [
      "Architectural tweak for image captioning; classification block is for inspiration only.",
      "addon_list.task: which task the additional content comes from."
    ],
    "input_list": [{"para": "nn_code", "value": "nn_code"}],
    "addon_list": [
      {"para": "addon_nn_code_1", "value": "nn_code"},
      {"para": "addon_nn_code_2", "value": "nn_code"},
      {"para": "addon_nn_code_3", "value": "nn_code"},
      {"para": "addon_nn_code_4", "value": "nn_code"},
      {"para": "addon_nn_code_5", "value": "nn_code"}
    ],
    "task": "img-captioning",
    "addon_task": "img-classification",
    "prompt": [
      "SYSTEM: You are Coder. Follow EVERY rule exactly and generate exactly ONE Python file.",
      "",
      "GOAL:",
      "Make SMALL, MEANINGFUL structural edits to an image-captioning model, inspired by classification blocks. Do NOT output a classifier. Output exactly ONE full, runnable Python file.",
      "",
      "HARD RULES:",
      "1) Define def supported_hyperparameters(): return {{'lr','momentum'}} (exactly those two; nothing else).",
      "2) Keep minimum EXACT API:",
      "   - class Net(nn.Module)",
      "   - def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device);",
      "   - def train_setup(self, prm)",
      "   - def learn(self, train_data)",
      "   - def forward(self, images, captions=None, hidden_state=None): -> (logits, hidden_state)",
      "   - Expose self.rnn and ensure it has def init_zero_hidden(batch, device) -> (h0, c0). If not LSTM, add a tiny shim that provides it.",
      "3) Teacher forcing contract:",
      "   - If captions.ndim == 3, first do captions = captions[:, 0, :].",
      "   - inputs = captions[:, :-1]; targets = captions[:, 1:].",
      "   - forward() MUST return (logits, hidden_state), where logits is [B, T-1, V].",
      "4) Optimizer MUST be: torch.optim.SGD(self.parameters(), lr=prm['lr']). Do NOT read any other prm key.",
      "5) Libraries: use torch / torch.nn ONLY. Do NOT import weights or enums from torchvision (no ResNet50_Weights / WeightsEnum / EfficientNet / einops / etc.). Define every helper in this file.",
      "   Ignore comments which has these signs #, \"\"\" etc.",
      "6) Shapes & sanity:",
      "   - in_channels = in_shape[1] (NEVER in_shape[0]).",
      "   - assert images.dim() == 4.",
      "   - If you use Transformer, set batch_first=True and ensure d_model % num_heads == 0.",
      "   - Add assert logits.shape[1] == inputs.shape[1].",
      "7) Reliability bans:",
      "   - Do NOT reference attributes you didn’t define (e.g., never use self.embedding in Net unless you defined it; prefer self.rnn.embedding).",
      "8) Parameter budget: keep the model reasonably small (≈2e6 params or below).",
      "",
      "ALLOWED SMALL EDITS (pick ONE or TWO):",
      "- try change into the encoder.",
      "- try to Replace a 3x3 conv with a 1x1-3x3-1x1 bottleneck + residual add.",
      "- use Conv2d/BatchNorm2d/MaxPool2d/AvgPool2d etc.",
      "- if you are using transform as a decoder then add a tiny 1-layer Transformer decoder (batch_first=True) after token embeddings.",
      "",
      "TEMPLATE (COPY THIS AND MODIFY ONLY THE MARKED SMALL PARTS; KEEP ALL SIGNATURES):",
      "```python",
      "import torch",
      "import torch.nn as nn",
      "import torch.nn.functional as F",
      "import torchvision",
      "",
      "def supported_hyperparameters():",
      "    return {{'lr','momentum'}}",
      "",
      "class Net(nn.Module):",
      "    def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:",
      "        super().__init__()",
      "        self.device = device",
      "        self.in_channels = in_shape[1]",
      "        vocab_size = out_shape[0]",
      "        self.encoder = Encoder(in_channels, d_model=512, patch=16, use_se=True)",
      "        self.rnn = Decoder(self.vocab_size, d_model=512, hidden_size=self.hidden_size)",
      "",
      "    def forward(self, images, captions, hidden_state):",
      "        assert images.dim() == 4",
      "        if captions.ndim == 3:",
      "            captions = captions[:, 0, :]",
      "        inputs = captions[:, :-1]",
      "        targets = captions[:, 1:]",
      "        visual = self.encoder(images)",
      "        if hidden_state is None:",
      "            hidden_state = self.rnn.init_zero_hidden(images.size(0), images.device)",
      "        logits, hidden_state = self.rnn(visual, inputs, hidden_state)",
      "        assert logits.shape[1] == inputs.shape[1]",
      "        return logits, hidden_state",
      "",
      "    def train_setup(self, prm):",
      "        self.to(self.device)",
      "        self.criteria = (nn.CrossEntropyLoss().to(self.device),)",
      "        self.optimizer = torch.optim.SGD(self.parameters(), lr=prm['lr']) or torch.optim.Adam(self.parameters(), lr=prm['lr'])",
      "        self.scaler = torch.cuda.amp.GradScaler()",
      "        self.device_type = self.device.type",
      "",
      "    def learn(self, train_data):",
      "        self.train()",
      "        for images, captions in train_data:",
      "            images = images.to(self.device)",
      "            captions = captions.to(self.device)",
      "            with autocast(device_type=self.device_type, enabled=(self.device_type == 'cuda')):",
      "                logits, _ = self.forward(images, captions, None)",
      "                tgt = (captions[:, 0, :] if captions.ndim == 3 else captions)[:, 1:]",
      "                loss = self.criteria[0](logits.reshape(-1, logits.size(-1)), tgt.reshape(-1))",
      "            self.optimizer.zero_grad()",
      "            self.scaler.scale(loss).backward()",
      "            nn.utils.clip_grad_norm_(self.parameters(), 3)",
      "            self.scaler.step(self.optimizer)",
      "            self.scaler.update()",
      "```",
      "",
      "INSPIRATION 1 (classification block):",
      "```python",
      "{addon_nn_code_1}",
      "```",
      "INSPIRATION 2 (classification block):",
      "```python",
      "{addon_nn_code_2}",
      "```",
      "INSPIRATION 3 (classification block):",
      "```python",
      "{addon_nn_code_3}",
      "```",
      "INSPIRATION 4 (classification block):",
      "```python",
      "{addon_nn_code_4}",
      "```",
      "INSPIRATION 5 (classification block):",
      "```python",
      "{addon_nn_code_5}",
      "```",
      "",
      "ORIGINAL CAPTIONING CODE (TARGET REFERENCE):",
      "```python",
      "{nn_code}",
      "```"
    ]
  }
}