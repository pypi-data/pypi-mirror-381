# pylint: disable=too-many-lines,too-many-statements
# coding=utf-8
# --------------------------------------------------------------------------
# Code generated by Microsoft (R) AutoRest Code Generator (autorest: 3.10.3, generator: @autorest/python@6.15.0)
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------
from io import IOBase
import sys
from typing import Any, Callable, Dict, IO, Iterable, Iterator, Optional, Type, TypeVar, Union, cast, overload

from azure.core.exceptions import (
    ClientAuthenticationError,
    HttpResponseError,
    ResourceExistsError,
    ResourceNotFoundError,
    ResourceNotModifiedError,
    map_error,
)
from azure.core.paging import ItemPaged
from azure.core.pipeline import PipelineResponse
from azure.core.polling import LROPoller, NoPolling, PollingMethod
from azure.core.polling.base_polling import LROBasePolling
from azure.core.rest import HttpRequest, HttpResponse
from azure.core.tracing.decorator import distributed_trace
from azure.core.utils import case_insensitive_dict

from .. import models as _models
from .._serialization import Serializer

if sys.version_info >= (3, 9):
    from collections.abc import MutableMapping
else:
    from typing import MutableMapping  # type: ignore  # pylint: disable=ungrouped-imports
T = TypeVar("T")
ClsType = Optional[Callable[[PipelineResponse[HttpRequest, HttpResponse], T, Dict[str, Any]], Any]]

_SERIALIZER = Serializer()
_SERIALIZER.client_side_validation = False


def build_items_list_lakehouses_request(
    workspace_id: str, *, continuation_token_parameter: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct parameters
    if continuation_token_parameter is not None:
        _params["continuationToken"] = _SERIALIZER.query(
            "continuation_token_parameter", continuation_token_parameter, "str"
        )

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_items_create_lakehouse_request(workspace_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


def build_items_get_lakehouse_request(workspace_id: str, lakehouse_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, headers=_headers, **kwargs)


def build_items_update_lakehouse_request(workspace_id: str, lakehouse_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="PATCH", url=_url, headers=_headers, **kwargs)


def build_items_delete_lakehouse_request(workspace_id: str, lakehouse_id: str, **kwargs: Any) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="DELETE", url=_url, headers=_headers, **kwargs)


def build_tables_list_tables_request(
    workspace_id: str,
    lakehouse_id: str,
    *,
    max_results: int = 100,
    continuation_token_parameter: Optional[str] = None,
    **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}/tables"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct parameters
    if max_results is not None:
        _params["maxResults"] = _SERIALIZER.query("max_results", max_results, "int", maximum=100, minimum=1)
    if continuation_token_parameter is not None:
        _params["continuationToken"] = _SERIALIZER.query(
            "continuation_token_parameter", continuation_token_parameter, "str"
        )

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_tables_load_table_request(
    workspace_id: str, lakehouse_id: str, table_name: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}/tables/{tableName}/load"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
        "tableName": _SERIALIZER.url(
            "table_name", table_name, "str", pattern=r"^(?=[0-9]*[a-zA-Z_])[a-zA-Z0-9_]{1,256}$"
        ),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


def build_background_jobs_run_on_demand_table_maintenance_request(  # pylint: disable=name-too-long
    workspace_id: str, lakehouse_id: str, *, job_type: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}/jobs/instances"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct parameters
    _params["jobType"] = _SERIALIZER.query("job_type", job_type, "str")

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_background_jobs_create_refresh_materialized_lake_views_schedule_request(  # pylint: disable=name-too-long
    workspace_id: str, lakehouse_id: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}/jobs/RefreshMaterializedLakeViews/schedules"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, headers=_headers, **kwargs)


def build_background_jobs_run_on_demand_refresh_materialized_lake_views_request(  # pylint: disable=name-too-long
    workspace_id: str, lakehouse_id: str, *, job_type: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}/jobs/instances"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct parameters
    _params["jobType"] = _SERIALIZER.query("job_type", job_type, "str")

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="POST", url=_url, params=_params, headers=_headers, **kwargs)


def build_background_jobs_update_refresh_materialized_lake_views_schedule_request(  # pylint: disable=name-too-long
    workspace_id: str, lakehouse_id: str, schedule_id: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}/jobs/RefreshMaterializedLakeViews/schedules/{scheduleId}"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
        "scheduleId": _SERIALIZER.url("schedule_id", schedule_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    if content_type is not None:
        _headers["Content-Type"] = _SERIALIZER.header("content_type", content_type, "str")
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="PATCH", url=_url, headers=_headers, **kwargs)


def build_background_jobs_delete_refresh_materialized_lake_views_schedule_request(  # pylint: disable=name-too-long
    workspace_id: str, lakehouse_id: str, schedule_id: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}/jobs/RefreshMaterializedLakeViews/schedules/{scheduleId}"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
        "scheduleId": _SERIALIZER.url("schedule_id", schedule_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="DELETE", url=_url, headers=_headers, **kwargs)


def build_livy_sessions_list_livy_sessions_request(  # pylint: disable=name-too-long
    workspace_id: str, lakehouse_id: str, *, continuation_token_parameter: Optional[str] = None, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
    _params = case_insensitive_dict(kwargs.pop("params", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}/livySessions"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct parameters
    if continuation_token_parameter is not None:
        _params["continuationToken"] = _SERIALIZER.query(
            "continuation_token_parameter", continuation_token_parameter, "str"
        )

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, params=_params, headers=_headers, **kwargs)


def build_livy_sessions_get_livy_session_request(  # pylint: disable=name-too-long
    workspace_id: str, lakehouse_id: str, livy_id: str, **kwargs: Any
) -> HttpRequest:
    _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})

    accept = _headers.pop("Accept", "application/json")

    # Construct URL
    _url = "/workspaces/{workspaceId}/lakehouses/{lakehouseId}/livySessions/{livyId}"
    path_format_arguments = {
        "workspaceId": _SERIALIZER.url("workspace_id", workspace_id, "str"),
        "lakehouseId": _SERIALIZER.url("lakehouse_id", lakehouse_id, "str"),
        "livyId": _SERIALIZER.url("livy_id", livy_id, "str"),
    }

    _url: str = _url.format(**path_format_arguments)  # type: ignore

    # Construct headers
    _headers["Accept"] = _SERIALIZER.header("accept", accept, "str")

    return HttpRequest(method="GET", url=_url, headers=_headers, **kwargs)


class ItemsOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~microsoft.fabric.api.lakehouse.FabricLakehouseClient`'s
        :attr:`items` attribute.
    """

    models = _models

    def __init__(self, *args, **kwargs):
        input_args = list(args)
        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @distributed_trace
    def list_lakehouses(
        self, workspace_id: str, *, continuation_token_parameter: Optional[str] = None, **kwargs: Any
    ) -> Iterable["_models.Lakehouse"]:
        """Returns a list of lakehouses from the specified workspace.

        This API supports `pagination </rest/api/fabric/articles/pagination>`_.

        Permissions
        -----------

         The caller must have a *viewer* workspace role.

        Required Delegated Scopes
        -------------------------

        Workspace.Read.All or Workspace.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :keyword continuation_token_parameter: A token for retrieving the next page of results. Default
         value is None.
        :paramtype continuation_token_parameter: str
        :return: An iterator like instance of Lakehouse
        :rtype: ~azure.core.paging.ItemPaged[~microsoft.fabric.api.lakehouse.models.Lakehouse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.Lakehouses] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_items_list_lakehouses_request(
                    workspace_id=workspace_id,
                    continuation_token_parameter=continuation_token_parameter,
                    headers=_headers,
                    params=_params,
                )
                _request.url = self._client.format_url(_request.url)

            else:
                _request = HttpRequest("GET", next_link)
                _request.url = self._client.format_url(_request.url)

            return _request

        def extract_data(pipeline_response):
            deserialized = self._deserialize(
                _models._models.Lakehouses, pipeline_response  # pylint: disable=protected-access
            )
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.continuation_uri or None, iter(list_of_elem)

        def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    def _create_lakehouse_initial(
        self,
        workspace_id: str,
        create_lakehouse_request: Union[_models.CreateLakehouseRequest, IO[bytes]],
        **kwargs: Any
    ) -> Iterator[bytes]:
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[Iterator[bytes]] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(create_lakehouse_request, (IOBase, bytes)):
            _content = create_lakehouse_request
        else:
            _json = self._serialize.body(create_lakehouse_request, "CreateLakehouseRequest")

        _request = build_items_create_lakehouse_request(
            workspace_id=workspace_id,
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = True
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201, 202]:
            response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        if response.status_code == 201:
            deserialized = response.iter_bytes()

        if response.status_code == 202:
            response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
            response_headers["x-ms-operation-id"] = self._deserialize("str", response.headers.get("x-ms-operation-id"))
            response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))

            deserialized = response.iter_bytes()

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @overload
    def begin_create_lakehouse(
        self,
        workspace_id: str,
        create_lakehouse_request: _models.CreateLakehouseRequest,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> LROPoller[_models.Lakehouse]:
        """Creates a lakehouse in the specified workspace.

        This API supports `long running operations (LRO)
        </rest/api/fabric/articles/long-running-operation>`_.

        This API does not support create a lakehouse with definition.

        Permissions
        -----------

         The caller must have a *contributor* workspace role.

        Required Delegated Scopes
        -------------------------

         Lakehouse.ReadWrite.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param create_lakehouse_request: Create item request payload. Required.
        :type create_lakehouse_request: ~microsoft.fabric.api.lakehouse.models.CreateLakehouseRequest
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An instance of LROPoller that returns Lakehouse
        :rtype: ~azure.core.polling.LROPoller[~microsoft.fabric.api.lakehouse.models.Lakehouse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def begin_create_lakehouse(
        self,
        workspace_id: str,
        create_lakehouse_request: IO[bytes],
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> LROPoller[_models.Lakehouse]:
        """Creates a lakehouse in the specified workspace.

        This API supports `long running operations (LRO)
        </rest/api/fabric/articles/long-running-operation>`_.

        This API does not support create a lakehouse with definition.

        Permissions
        -----------

         The caller must have a *contributor* workspace role.

        Required Delegated Scopes
        -------------------------

         Lakehouse.ReadWrite.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param create_lakehouse_request: Create item request payload. Required.
        :type create_lakehouse_request: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An instance of LROPoller that returns Lakehouse
        :rtype: ~azure.core.polling.LROPoller[~microsoft.fabric.api.lakehouse.models.Lakehouse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def begin_create_lakehouse(
        self,
        workspace_id: str,
        create_lakehouse_request: Union[_models.CreateLakehouseRequest, IO[bytes]],
        **kwargs: Any
    ) -> LROPoller[_models.Lakehouse]:
        """Creates a lakehouse in the specified workspace.

        This API supports `long running operations (LRO)
        </rest/api/fabric/articles/long-running-operation>`_.

        This API does not support create a lakehouse with definition.

        Permissions
        -----------

         The caller must have a *contributor* workspace role.

        Required Delegated Scopes
        -------------------------

         Lakehouse.ReadWrite.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param create_lakehouse_request: Create item request payload. Is either a
         CreateLakehouseRequest type or a IO[bytes] type. Required.
        :type create_lakehouse_request: ~microsoft.fabric.api.lakehouse.models.CreateLakehouseRequest
         or IO[bytes]
        :return: An instance of LROPoller that returns Lakehouse
        :rtype: ~azure.core.polling.LROPoller[~microsoft.fabric.api.lakehouse.models.Lakehouse]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.Lakehouse] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._create_lakehouse_initial(
                workspace_id=workspace_id,
                create_lakehouse_request=create_lakehouse_request,
                content_type=content_type,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
            raw_result.http_response.read()  # type: ignore
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):
            deserialized = self._deserialize("Lakehouse", pipeline_response.http_response)
            if cls:
                return cls(pipeline_response, deserialized, {})  # type: ignore
            return deserialized

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller[_models.Lakehouse].from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller[_models.Lakehouse](
            self._client, raw_result, get_long_running_output, polling_method  # type: ignore
        )

    @distributed_trace
    def get_lakehouse(self, workspace_id: str, lakehouse_id: str, **kwargs: Any) -> _models.Lakehouse:
        """Returns properties of the specified lakehouse.

        Permissions
        -----------

         The caller must have *read* permissions for the lakehouse.

        Required Delegated Scopes
        -------------------------

         Lakehouse.Read.All or Lakehouse.ReadWrite.All or Item.Read.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :return: Lakehouse
        :rtype: ~microsoft.fabric.api.lakehouse.models.Lakehouse
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.Lakehouse] = kwargs.pop("cls", None)

        _request = build_items_get_lakehouse_request(
            workspace_id=workspace_id,
            lakehouse_id=lakehouse_id,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize("Lakehouse", pipeline_response.http_response)

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @overload
    def update_lakehouse(
        self,
        workspace_id: str,
        lakehouse_id: str,
        update_lakehouse_request: _models.UpdateLakehouseRequest,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.Lakehouse:
        """Updates the properties of the specified lakehouse.

        Permissions
        -----------

         The caller must have *read and write* permissions for the lakehouse.

        Required Delegated Scopes
        -------------------------

         Lakehouse.ReadWrite.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param update_lakehouse_request: Update lakehouse request payload. Required.
        :type update_lakehouse_request: ~microsoft.fabric.api.lakehouse.models.UpdateLakehouseRequest
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: Lakehouse
        :rtype: ~microsoft.fabric.api.lakehouse.models.Lakehouse
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def update_lakehouse(
        self,
        workspace_id: str,
        lakehouse_id: str,
        update_lakehouse_request: IO[bytes],
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.Lakehouse:
        """Updates the properties of the specified lakehouse.

        Permissions
        -----------

         The caller must have *read and write* permissions for the lakehouse.

        Required Delegated Scopes
        -------------------------

         Lakehouse.ReadWrite.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param update_lakehouse_request: Update lakehouse request payload. Required.
        :type update_lakehouse_request: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: Lakehouse
        :rtype: ~microsoft.fabric.api.lakehouse.models.Lakehouse
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def update_lakehouse(
        self,
        workspace_id: str,
        lakehouse_id: str,
        update_lakehouse_request: Union[_models.UpdateLakehouseRequest, IO[bytes]],
        **kwargs: Any
    ) -> _models.Lakehouse:
        """Updates the properties of the specified lakehouse.

        Permissions
        -----------

         The caller must have *read and write* permissions for the lakehouse.

        Required Delegated Scopes
        -------------------------

         Lakehouse.ReadWrite.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param update_lakehouse_request: Update lakehouse request payload. Is either a
         UpdateLakehouseRequest type or a IO[bytes] type. Required.
        :type update_lakehouse_request: ~microsoft.fabric.api.lakehouse.models.UpdateLakehouseRequest
         or IO[bytes]
        :return: Lakehouse
        :rtype: ~microsoft.fabric.api.lakehouse.models.Lakehouse
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.Lakehouse] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(update_lakehouse_request, (IOBase, bytes)):
            _content = update_lakehouse_request
        else:
            _json = self._serialize.body(update_lakehouse_request, "UpdateLakehouseRequest")

        _request = build_items_update_lakehouse_request(
            workspace_id=workspace_id,
            lakehouse_id=lakehouse_id,
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize("Lakehouse", pipeline_response.http_response)

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def delete_lakehouse(  # pylint: disable=inconsistent-return-statements
        self, workspace_id: str, lakehouse_id: str, **kwargs: Any
    ) -> None:
        """Deletes the specified lakehouse.

        Permissions
        -----------

         The caller must have *write* permissions for the lakehouse.

        Required Delegated Scopes
        -------------------------

         Lakehouse.ReadWrite.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_items_delete_lakehouse_request(
            workspace_id=workspace_id,
            lakehouse_id=lakehouse_id,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        if cls:
            return cls(pipeline_response, None, {})  # type: ignore


class TablesOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~microsoft.fabric.api.lakehouse.FabricLakehouseClient`'s
        :attr:`tables` attribute.
    """

    models = _models

    def __init__(self, *args, **kwargs):
        input_args = list(args)
        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @distributed_trace
    def list_tables(
        self,
        workspace_id: str,
        lakehouse_id: str,
        *,
        max_results: int = 100,
        continuation_token_parameter: Optional[str] = None,
        **kwargs: Any
    ) -> Iterable["_models.Table"]:
        """Returns a list of lakehouse Tables.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        This API supports `pagination </rest/api/fabric/articles/pagination>`_.

        Required Delegated Scopes
        -------------------------

        Lakehouse.Read.All or Lakehouse.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :keyword max_results: The maximum number of results per page to return. Default value is 100.
        :paramtype max_results: int
        :keyword continuation_token_parameter: Token to retrieve the next page of results, if
         available. Default value is None.
        :paramtype continuation_token_parameter: str
        :return: An iterator like instance of Table
        :rtype: ~azure.core.paging.ItemPaged[~microsoft.fabric.api.lakehouse.models.Table]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.Tables] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_tables_list_tables_request(
                    workspace_id=workspace_id,
                    lakehouse_id=lakehouse_id,
                    max_results=max_results,
                    continuation_token_parameter=continuation_token_parameter,
                    headers=_headers,
                    params=_params,
                )
                _request.url = self._client.format_url(_request.url)

            else:
                _request = HttpRequest("GET", next_link)
                _request.url = self._client.format_url(_request.url)

            return _request

        def extract_data(pipeline_response):
            deserialized = self._deserialize(
                _models._models.Tables, pipeline_response  # pylint: disable=protected-access
            )
            list_of_elem = deserialized.data
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.continuation_uri or None, iter(list_of_elem)

        def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    def _load_table_initial(
        self,
        workspace_id: str,
        lakehouse_id: str,
        table_name: str,
        load_table_request: Union[_models.LoadTableRequest, IO[bytes]],
        **kwargs: Any
    ) -> Iterator[bytes]:
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[Iterator[bytes]] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(load_table_request, (IOBase, bytes)):
            _content = load_table_request
        else:
            _json = self._serialize.body(load_table_request, "LoadTableRequest")

        _request = build_tables_load_table_request(
            workspace_id=workspace_id,
            lakehouse_id=lakehouse_id,
            table_name=table_name,
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = True
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            response.read()  # Load the body in memory and close the socket
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
        response_headers["x-ms-operation-id"] = self._deserialize("str", response.headers.get("x-ms-operation-id"))
        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))

        deserialized = response.iter_bytes()

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @overload
    def begin_load_table(
        self,
        workspace_id: str,
        lakehouse_id: str,
        table_name: str,
        load_table_request: _models.LoadTableRequest,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> LROPoller[None]:
        """Starts a load table operation and returns the operation status URL in the response location
        header.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        This API supports `long running operations (LRO)
        </rest/api/fabric/articles/long-running-operation>`_.

        Permissions
        -----------

        Write permission to the lakehouse item.

        Required Delegated Scopes
        -------------------------

        Lakehouse.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse item ID. Required.
        :type lakehouse_id: str
        :param table_name: The table name. Required.
        :type table_name: str
        :param load_table_request: The load table request payload. Required.
        :type load_table_request: ~microsoft.fabric.api.lakehouse.models.LoadTableRequest
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An instance of LROPoller that returns None
        :rtype: ~azure.core.polling.LROPoller[None]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def begin_load_table(
        self,
        workspace_id: str,
        lakehouse_id: str,
        table_name: str,
        load_table_request: IO[bytes],
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> LROPoller[None]:
        """Starts a load table operation and returns the operation status URL in the response location
        header.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        This API supports `long running operations (LRO)
        </rest/api/fabric/articles/long-running-operation>`_.

        Permissions
        -----------

        Write permission to the lakehouse item.

        Required Delegated Scopes
        -------------------------

        Lakehouse.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse item ID. Required.
        :type lakehouse_id: str
        :param table_name: The table name. Required.
        :type table_name: str
        :param load_table_request: The load table request payload. Required.
        :type load_table_request: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: An instance of LROPoller that returns None
        :rtype: ~azure.core.polling.LROPoller[None]
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def begin_load_table(
        self,
        workspace_id: str,
        lakehouse_id: str,
        table_name: str,
        load_table_request: Union[_models.LoadTableRequest, IO[bytes]],
        **kwargs: Any
    ) -> LROPoller[None]:
        """Starts a load table operation and returns the operation status URL in the response location
        header.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        This API supports `long running operations (LRO)
        </rest/api/fabric/articles/long-running-operation>`_.

        Permissions
        -----------

        Write permission to the lakehouse item.

        Required Delegated Scopes
        -------------------------

        Lakehouse.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse item ID. Required.
        :type lakehouse_id: str
        :param table_name: The table name. Required.
        :type table_name: str
        :param load_table_request: The load table request payload. Is either a LoadTableRequest type or
         a IO[bytes] type. Required.
        :type load_table_request: ~microsoft.fabric.api.lakehouse.models.LoadTableRequest or IO[bytes]
        :return: An instance of LROPoller that returns None
        :rtype: ~azure.core.polling.LROPoller[None]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[None] = kwargs.pop("cls", None)
        polling: Union[bool, PollingMethod] = kwargs.pop("polling", True)
        lro_delay = kwargs.pop("polling_interval", self._config.polling_interval)
        cont_token: Optional[str] = kwargs.pop("continuation_token", None)
        if cont_token is None:
            raw_result = self._load_table_initial(
                workspace_id=workspace_id,
                lakehouse_id=lakehouse_id,
                table_name=table_name,
                load_table_request=load_table_request,
                content_type=content_type,
                cls=lambda x, y, z: x,
                headers=_headers,
                params=_params,
                **kwargs
            )
            raw_result.http_response.read()  # type: ignore
        kwargs.pop("error_map", None)

        def get_long_running_output(pipeline_response):  # pylint: disable=inconsistent-return-statements
            if cls:
                return cls(pipeline_response, None, {})  # type: ignore

        if polling is True:
            polling_method: PollingMethod = cast(PollingMethod, LROBasePolling(lro_delay, **kwargs))
        elif polling is False:
            polling_method = cast(PollingMethod, NoPolling())
        else:
            polling_method = polling
        if cont_token:
            return LROPoller[None].from_continuation_token(
                polling_method=polling_method,
                continuation_token=cont_token,
                client=self._client,
                deserialization_callback=get_long_running_output,
            )
        return LROPoller[None](self._client, raw_result, get_long_running_output, polling_method)  # type: ignore


class BackgroundJobsOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~microsoft.fabric.api.lakehouse.FabricLakehouseClient`'s
        :attr:`background_jobs` attribute.
    """

    models = _models

    def __init__(self, *args, **kwargs):
        input_args = list(args)
        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @overload
    def run_on_demand_table_maintenance(  # pylint: disable=inconsistent-return-statements
        self,
        workspace_id: str,
        lakehouse_id: str,
        run_on_demand_table_maintenance_request: _models.RunOnDemandTableMaintenanceRequest,
        *,
        job_type: str,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> None:
        """Run on-demand `table maintenance </fabric/data-engineering/lakehouse-table-maintenance>`_ job
        instance.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes
        -------------------------

        Lakehouse.Execute.All or Item.Execute.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The Lakehouse item ID. Required.
        :type lakehouse_id: str
        :param run_on_demand_table_maintenance_request: Run on-demand table maintenance request
         payload. Required.
        :type run_on_demand_table_maintenance_request:
         ~microsoft.fabric.api.lakehouse.models.RunOnDemandTableMaintenanceRequest
        :keyword job_type: *TableMaintenance* job type. Required.
        :paramtype job_type: str
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def run_on_demand_table_maintenance(  # pylint: disable=inconsistent-return-statements
        self,
        workspace_id: str,
        lakehouse_id: str,
        run_on_demand_table_maintenance_request: IO[bytes],
        *,
        job_type: str,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> None:
        """Run on-demand `table maintenance </fabric/data-engineering/lakehouse-table-maintenance>`_ job
        instance.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes
        -------------------------

        Lakehouse.Execute.All or Item.Execute.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The Lakehouse item ID. Required.
        :type lakehouse_id: str
        :param run_on_demand_table_maintenance_request: Run on-demand table maintenance request
         payload. Required.
        :type run_on_demand_table_maintenance_request: IO[bytes]
        :keyword job_type: *TableMaintenance* job type. Required.
        :paramtype job_type: str
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def run_on_demand_table_maintenance(  # pylint: disable=inconsistent-return-statements
        self,
        workspace_id: str,
        lakehouse_id: str,
        run_on_demand_table_maintenance_request: Union[_models.RunOnDemandTableMaintenanceRequest, IO[bytes]],
        *,
        job_type: str,
        **kwargs: Any
    ) -> None:
        """Run on-demand `table maintenance </fabric/data-engineering/lakehouse-table-maintenance>`_ job
        instance.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes
        -------------------------

        Lakehouse.Execute.All or Item.Execute.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The Lakehouse item ID. Required.
        :type lakehouse_id: str
        :param run_on_demand_table_maintenance_request: Run on-demand table maintenance request
         payload. Is either a RunOnDemandTableMaintenanceRequest type or a IO[bytes] type. Required.
        :type run_on_demand_table_maintenance_request:
         ~microsoft.fabric.api.lakehouse.models.RunOnDemandTableMaintenanceRequest or IO[bytes]
        :keyword job_type: *TableMaintenance* job type. Required.
        :paramtype job_type: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[None] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(run_on_demand_table_maintenance_request, (IOBase, bytes)):
            _content = run_on_demand_table_maintenance_request
        else:
            _json = self._serialize.body(run_on_demand_table_maintenance_request, "RunOnDemandTableMaintenanceRequest")

        _request = build_background_jobs_run_on_demand_table_maintenance_request(
            workspace_id=workspace_id,
            lakehouse_id=lakehouse_id,
            job_type=job_type,
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @overload
    def create_refresh_materialized_lake_views_schedule(  # pylint: disable=name-too-long
        self,
        workspace_id: str,
        lakehouse_id: str,
        create_schedule_request: _models.CreateLakehouseRefreshMaterializedLakeViewsScheduleRequest,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.LakehouseRefreshMaterializedLakeViewsSchedule:
        """Create a new Refresh MaterializedLakeViews schedule for a lakehouse.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes:
        --------------------------

        (Lakehouse.Execute.All or Item.Execute.All) and (Lakehouse.ReadWrite.All or Item.ReadWrite.All)

        Limitations
        -----------


        * A lakehouse can create maximum 20 schedulers.
        * Materialized Lake View supports only one active refresh schedule per lineage.

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - No


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param create_schedule_request: A lakehouse refresh materialized lake views schedule create
         request. Required.
        :type create_schedule_request:
         ~microsoft.fabric.api.lakehouse.models.CreateLakehouseRefreshMaterializedLakeViewsScheduleRequest
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: LakehouseRefreshMaterializedLakeViewsSchedule
        :rtype: ~microsoft.fabric.api.lakehouse.models.LakehouseRefreshMaterializedLakeViewsSchedule
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def create_refresh_materialized_lake_views_schedule(  # pylint: disable=name-too-long
        self,
        workspace_id: str,
        lakehouse_id: str,
        create_schedule_request: IO[bytes],
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.LakehouseRefreshMaterializedLakeViewsSchedule:
        """Create a new Refresh MaterializedLakeViews schedule for a lakehouse.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes:
        --------------------------

        (Lakehouse.Execute.All or Item.Execute.All) and (Lakehouse.ReadWrite.All or Item.ReadWrite.All)

        Limitations
        -----------


        * A lakehouse can create maximum 20 schedulers.
        * Materialized Lake View supports only one active refresh schedule per lineage.

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - No


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param create_schedule_request: A lakehouse refresh materialized lake views schedule create
         request. Required.
        :type create_schedule_request: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: LakehouseRefreshMaterializedLakeViewsSchedule
        :rtype: ~microsoft.fabric.api.lakehouse.models.LakehouseRefreshMaterializedLakeViewsSchedule
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def create_refresh_materialized_lake_views_schedule(  # pylint: disable=name-too-long
        self,
        workspace_id: str,
        lakehouse_id: str,
        create_schedule_request: Union[_models.CreateLakehouseRefreshMaterializedLakeViewsScheduleRequest, IO[bytes]],
        **kwargs: Any
    ) -> _models.LakehouseRefreshMaterializedLakeViewsSchedule:
        """Create a new Refresh MaterializedLakeViews schedule for a lakehouse.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes:
        --------------------------

        (Lakehouse.Execute.All or Item.Execute.All) and (Lakehouse.ReadWrite.All or Item.ReadWrite.All)

        Limitations
        -----------


        * A lakehouse can create maximum 20 schedulers.
        * Materialized Lake View supports only one active refresh schedule per lineage.

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - No


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param create_schedule_request: A lakehouse refresh materialized lake views schedule create
         request. Is either a CreateLakehouseRefreshMaterializedLakeViewsScheduleRequest type or a
         IO[bytes] type. Required.
        :type create_schedule_request:
         ~microsoft.fabric.api.lakehouse.models.CreateLakehouseRefreshMaterializedLakeViewsScheduleRequest
         or IO[bytes]
        :return: LakehouseRefreshMaterializedLakeViewsSchedule
        :rtype: ~microsoft.fabric.api.lakehouse.models.LakehouseRefreshMaterializedLakeViewsSchedule
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.LakehouseRefreshMaterializedLakeViewsSchedule] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(create_schedule_request, (IOBase, bytes)):
            _content = create_schedule_request
        else:
            _json = self._serialize.body(
                create_schedule_request, "CreateLakehouseRefreshMaterializedLakeViewsScheduleRequest"
            )

        _request = build_background_jobs_create_refresh_materialized_lake_views_schedule_request(
            workspace_id=workspace_id,
            lakehouse_id=lakehouse_id,
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [201]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))

        deserialized = self._deserialize(
            "LakehouseRefreshMaterializedLakeViewsSchedule", pipeline_response.http_response
        )

        if cls:
            return cls(pipeline_response, deserialized, response_headers)  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def run_on_demand_refresh_materialized_lake_views(  # pylint: disable=inconsistent-return-statements,name-too-long
        self, workspace_id: str, lakehouse_id: str, *, job_type: str, **kwargs: Any
    ) -> None:
        """Run on-demand `Refresh MaterializedLakeViews
        </fabric/data-engineering/materialized-lake-views/refresh-materialized-lake-view>`_ job
        instance.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes
        -------------------------

        Lakehouse.Execute.All or Item.Execute.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - No


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :keyword job_type: *RefreshMaterializedLakeViews* job type. Required.
        :paramtype job_type: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_background_jobs_run_on_demand_refresh_materialized_lake_views_request(
            workspace_id=workspace_id,
            lakehouse_id=lakehouse_id,
            job_type=job_type,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [202]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        response_headers = {}
        response_headers["Location"] = self._deserialize("str", response.headers.get("Location"))
        response_headers["Retry-After"] = self._deserialize("int", response.headers.get("Retry-After"))

        if cls:
            return cls(pipeline_response, None, response_headers)  # type: ignore

    @overload
    def update_refresh_materialized_lake_views_schedule(  # pylint: disable=name-too-long
        self,
        workspace_id: str,
        lakehouse_id: str,
        schedule_id: str,
        update_schedule_request: _models.UpdateLakehouseRefreshMaterializedLakeViewsScheduleRequest,
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.LakehouseRefreshMaterializedLakeViewsSchedule:
        """Update an existing Refresh MaterializedLakeViews schedule for a lakehouse.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes:
        --------------------------

        (Lakehouse.Execute.All or Item.Execute.All) and (Lakehouse.ReadWrite.All or Item.ReadWrite.All)

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - No


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param schedule_id: The lakehouse schedule ID. Required.
        :type schedule_id: str
        :param update_schedule_request: A lakehouse refresh materialized lake views schedule update
         request. Required.
        :type update_schedule_request:
         ~microsoft.fabric.api.lakehouse.models.UpdateLakehouseRefreshMaterializedLakeViewsScheduleRequest
        :keyword content_type: Body Parameter content-type. Content type parameter for JSON body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: LakehouseRefreshMaterializedLakeViewsSchedule
        :rtype: ~microsoft.fabric.api.lakehouse.models.LakehouseRefreshMaterializedLakeViewsSchedule
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @overload
    def update_refresh_materialized_lake_views_schedule(  # pylint: disable=name-too-long
        self,
        workspace_id: str,
        lakehouse_id: str,
        schedule_id: str,
        update_schedule_request: IO[bytes],
        *,
        content_type: str = "application/json",
        **kwargs: Any
    ) -> _models.LakehouseRefreshMaterializedLakeViewsSchedule:
        """Update an existing Refresh MaterializedLakeViews schedule for a lakehouse.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes:
        --------------------------

        (Lakehouse.Execute.All or Item.Execute.All) and (Lakehouse.ReadWrite.All or Item.ReadWrite.All)

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - No


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param schedule_id: The lakehouse schedule ID. Required.
        :type schedule_id: str
        :param update_schedule_request: A lakehouse refresh materialized lake views schedule update
         request. Required.
        :type update_schedule_request: IO[bytes]
        :keyword content_type: Body Parameter content-type. Content type parameter for binary body.
         Default value is "application/json".
        :paramtype content_type: str
        :return: LakehouseRefreshMaterializedLakeViewsSchedule
        :rtype: ~microsoft.fabric.api.lakehouse.models.LakehouseRefreshMaterializedLakeViewsSchedule
        :raises ~azure.core.exceptions.HttpResponseError:
        """

    @distributed_trace
    def update_refresh_materialized_lake_views_schedule(  # pylint: disable=name-too-long
        self,
        workspace_id: str,
        lakehouse_id: str,
        schedule_id: str,
        update_schedule_request: Union[_models.UpdateLakehouseRefreshMaterializedLakeViewsScheduleRequest, IO[bytes]],
        **kwargs: Any
    ) -> _models.LakehouseRefreshMaterializedLakeViewsSchedule:
        """Update an existing Refresh MaterializedLakeViews schedule for a lakehouse.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes:
        --------------------------

        (Lakehouse.Execute.All or Item.Execute.All) and (Lakehouse.ReadWrite.All or Item.ReadWrite.All)

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - No


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param schedule_id: The lakehouse schedule ID. Required.
        :type schedule_id: str
        :param update_schedule_request: A lakehouse refresh materialized lake views schedule update
         request. Is either a UpdateLakehouseRefreshMaterializedLakeViewsScheduleRequest type or a
         IO[bytes] type. Required.
        :type update_schedule_request:
         ~microsoft.fabric.api.lakehouse.models.UpdateLakehouseRefreshMaterializedLakeViewsScheduleRequest
         or IO[bytes]
        :return: LakehouseRefreshMaterializedLakeViewsSchedule
        :rtype: ~microsoft.fabric.api.lakehouse.models.LakehouseRefreshMaterializedLakeViewsSchedule
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = case_insensitive_dict(kwargs.pop("headers", {}) or {})
        _params = kwargs.pop("params", {}) or {}

        content_type: Optional[str] = kwargs.pop("content_type", _headers.pop("Content-Type", None))
        cls: ClsType[_models.LakehouseRefreshMaterializedLakeViewsSchedule] = kwargs.pop("cls", None)

        content_type = content_type or "application/json"
        _json = None
        _content = None
        if isinstance(update_schedule_request, (IOBase, bytes)):
            _content = update_schedule_request
        else:
            _json = self._serialize.body(
                update_schedule_request, "UpdateLakehouseRefreshMaterializedLakeViewsScheduleRequest"
            )

        _request = build_background_jobs_update_refresh_materialized_lake_views_schedule_request(
            workspace_id=workspace_id,
            lakehouse_id=lakehouse_id,
            schedule_id=schedule_id,
            content_type=content_type,
            json=_json,
            content=_content,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize(
            "LakehouseRefreshMaterializedLakeViewsSchedule", pipeline_response.http_response
        )

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore

    @distributed_trace
    def delete_refresh_materialized_lake_views_schedule(  # pylint: disable=inconsistent-return-statements,name-too-long
        self, workspace_id: str, lakehouse_id: str, schedule_id: str, **kwargs: Any
    ) -> None:
        """Delete an existing Refresh MaterializedLakeViews schedule for a lakehouse.

        ..

           [!NOTE]
           This API is part of a Preview release and is provided for evaluation and development
        purposes only. It may change based on feedback and is not recommended for production use.


        Required Delegated Scopes
        -------------------------

        Lakehouse.ReadWrite.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - No


        Interface
        ---------.

        :param workspace_id: The workspace ID. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param schedule_id: The lakehouse schedule ID. Required.
        :type schedule_id: str
        :return: None
        :rtype: None
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[None] = kwargs.pop("cls", None)

        _request = build_background_jobs_delete_refresh_materialized_lake_views_schedule_request(
            workspace_id=workspace_id,
            lakehouse_id=lakehouse_id,
            schedule_id=schedule_id,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        if cls:
            return cls(pipeline_response, None, {})  # type: ignore


class LivySessionsOperations:
    """
    .. warning::
        **DO NOT** instantiate this class directly.

        Instead, you should access the following operations through
        :class:`~microsoft.fabric.api.lakehouse.FabricLakehouseClient`'s
        :attr:`livy_sessions` attribute.
    """

    models = _models

    def __init__(self, *args, **kwargs):
        input_args = list(args)
        self._client = input_args.pop(0) if input_args else kwargs.pop("client")
        self._config = input_args.pop(0) if input_args else kwargs.pop("config")
        self._serialize = input_args.pop(0) if input_args else kwargs.pop("serializer")
        self._deserialize = input_args.pop(0) if input_args else kwargs.pop("deserializer")

    @distributed_trace
    def list_livy_sessions(
        self, workspace_id: str, lakehouse_id: str, *, continuation_token_parameter: Optional[str] = None, **kwargs: Any
    ) -> Iterable["_models.LivySession"]:
        """Returns a list of livy sessions from the specified item identifier.

        This API supports `pagination </rest/api/fabric/articles/pagination>`_.

        Permissions
        -----------

         The caller must have *viewer* or higher workspace role.

        Required Delegated Scopes
        -------------------------

         Lakehouse.Read.All or Lakehouse.ReadWrite.All or Item.Read.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace identifier. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :keyword continuation_token_parameter: Token to retrieve the next page of results, if
         available. Default value is None.
        :paramtype continuation_token_parameter: str
        :return: An iterator like instance of LivySession
        :rtype: ~azure.core.paging.ItemPaged[~microsoft.fabric.api.lakehouse.models.LivySession]
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models._models.LivySessions] = kwargs.pop("cls", None)  # pylint: disable=protected-access

        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        def prepare_request(next_link=None):
            if not next_link:

                _request = build_livy_sessions_list_livy_sessions_request(
                    workspace_id=workspace_id,
                    lakehouse_id=lakehouse_id,
                    continuation_token_parameter=continuation_token_parameter,
                    headers=_headers,
                    params=_params,
                )
                _request.url = self._client.format_url(_request.url)

            else:
                _request = HttpRequest("GET", next_link)
                _request.url = self._client.format_url(_request.url)

            return _request

        def extract_data(pipeline_response):
            deserialized = self._deserialize(
                _models._models.LivySessions, pipeline_response  # pylint: disable=protected-access
            )
            list_of_elem = deserialized.value
            if cls:
                list_of_elem = cls(list_of_elem)  # type: ignore
            return deserialized.continuation_uri or None, iter(list_of_elem)

        def get_next(next_link=None):
            _request = prepare_request(next_link)

            _stream = False
            pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
                _request, stream=_stream, **kwargs
            )
            response = pipeline_response.http_response

            if response.status_code not in [200]:
                map_error(status_code=response.status_code, response=response, error_map=error_map)
                error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
                raise HttpResponseError(response=response, model=error)

            return pipeline_response

        return ItemPaged(get_next, extract_data)

    @distributed_trace
    def get_livy_session(
        self, workspace_id: str, lakehouse_id: str, livy_id: str, **kwargs: Any
    ) -> _models.LivySession:
        """Returns properties of the specified livy session.

        Permissions
        -----------

         The caller must have *viewer* or higher workspace role.

        Required Delegated Scopes
        -------------------------

         Lakehouse.Read.All or Lakehouse.ReadWrite.All or Item.Read.All or Item.ReadWrite.All

        Microsoft Entra supported identities
        ------------------------------------

        This API supports the Microsoft `identities </rest/api/fabric/articles/identity-support>`_
        listed in this section.

        .. list-table::
           :header-rows: 1

           * - Identity
             - Support
           * - User
             - Yes
           * - `Service principal
        </entra/identity-platform/app-objects-and-service-principals#service-principal-object>`_ and
        `Managed identities </entra/identity/managed-identities-azure-resources/overview>`_
             - Yes


        Interface
        ---------.

        :param workspace_id: The workspace identifier. Required.
        :type workspace_id: str
        :param lakehouse_id: The lakehouse ID. Required.
        :type lakehouse_id: str
        :param livy_id: The session identifier. Required.
        :type livy_id: str
        :return: LivySession
        :rtype: ~microsoft.fabric.api.lakehouse.models.LivySession
        :raises ~azure.core.exceptions.HttpResponseError:
        """
        error_map: MutableMapping[int, Type[HttpResponseError]] = {
            401: ClientAuthenticationError,
            404: ResourceNotFoundError,
            409: ResourceExistsError,
            304: ResourceNotModifiedError,
        }
        error_map.update(kwargs.pop("error_map", {}) or {})

        _headers = kwargs.pop("headers", {}) or {}
        _params = kwargs.pop("params", {}) or {}

        cls: ClsType[_models.LivySession] = kwargs.pop("cls", None)

        _request = build_livy_sessions_get_livy_session_request(
            workspace_id=workspace_id,
            lakehouse_id=lakehouse_id,
            livy_id=livy_id,
            headers=_headers,
            params=_params,
        )
        _request.url = self._client.format_url(_request.url)

        _stream = False
        pipeline_response: PipelineResponse = self._client._pipeline.run(  # pylint: disable=protected-access
            _request, stream=_stream, **kwargs
        )

        response = pipeline_response.http_response

        if response.status_code not in [200]:
            map_error(status_code=response.status_code, response=response, error_map=error_map)
            error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)
            raise HttpResponseError(response=response, model=error)

        deserialized = self._deserialize("LivySession", pipeline_response.http_response)

        if cls:
            return cls(pipeline_response, deserialized, {})  # type: ignore

        return deserialized  # type: ignore
