# coding=utf-8
# --------------------------------------------------------------------------
# Code generated by Microsoft (R) AutoRest Code Generator (autorest: 3.10.3, generator: @autorest/python@6.15.0)
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

from enum import Enum
from azure.core import CaseInsensitiveEnumMeta


class AggregationFunction(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The aggregation function."""

    AVERAGE = "Average"
    COUNT = "Count"
    MAXIMUM = "Maximum"
    MINIMUM = "Minimum"
    PERCENTILE_CONTINUOUS = "PercentileContinuous"
    PERCENTILE_DISCRETE = "PercentileDiscrete"
    STANDARD_DEVIATION = "StandardDeviation"
    STANDARD_DEVIATION_POPULATION = "StandardDeviationPopulation"
    SUM = "Sum"
    VARIANCE = "Variance"
    VARIANCE_POPULATION = "VariancePopulation"


class AmazonKinesisSourcePropertiesRegion(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The Amazon Kinesis region name."""

    AF_SOUTH1 = "af-south-1"
    AP_EAST1 = "ap-east-1"
    AP_NORTHEAST1 = "ap-northeast-1"
    AP_NORTHEAST2 = "ap-northeast-2"
    AP_NORTHEAST3 = "ap-northeast-3"
    AP_SOUTH1 = "ap-south-1"
    AP_SOUTH2 = "ap-south-2"
    AP_SOUTHEAST1 = "ap-southeast-1"
    AP_SOUTHEAST2 = "ap-southeast-2"
    AP_SOUTHEAST3 = "ap-southeast-3"
    AP_SOUTHEAST4 = "ap-southeast-4"
    AP_SOUTHEAST5 = "ap-southeast-5"
    CA_CENTRAL1 = "ca-central-1"
    CA_WEST1 = "ca-west-1"
    EU_CENTRAL1 = "eu-central-1"
    EU_CENTRAL2 = "eu-central-2"
    EU_NORTH1 = "eu-north-1"
    EU_SOUTH1 = "eu-south-1"
    EU_SOUTH2 = "eu-south-2"
    EU_WEST1 = "eu-west-1"
    EU_WEST2 = "eu-west-2"
    EU_WEST3 = "eu-west-3"
    IL_CENTRAL1 = "il-central-1"
    ME_CENTRAL1 = "me-central-1"
    ME_SOUTH1 = "me-south-1"
    SA_EAST1 = "sa-east-1"
    US_EAST1 = "us-east-1"
    US_EAST2 = "us-east-2"
    US_GOV_EAST1 = "us-gov-east-1"
    US_GOV_WEST1 = "us-gov-west-1"
    US_WEST1 = "us-west-1"
    US_WEST2 = "us-west-2"


class AmazonMSKKafkaSourcePropertiesSaslMechanism(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The SASL mechanism."""

    PLAIN = "PLAIN"
    SCRAM_SHA256 = "SCRAM-SHA-256"
    SCRAM_SHA512 = "SCRAM-SHA-512"


class AmazonMSKKafkaSourcePropertiesSecurityProtocol(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The security protocol."""

    SASL_PLAINTEXT = "SASL_PLAINTEXT"
    PLAINTEXT = "PLAINTEXT"
    SASL_SSL = "SASL_SSL"
    SSL = "SSL"


class ApacheKafkaSourcePropertiesSaslMechanism(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The SASL mechanism."""

    PLAIN = "PLAIN"
    SCRAM_SHA256 = "SCRAM-SHA-256"
    SCRAM_SHA512 = "SCRAM-SHA-512"


class ApacheKafkaSourcePropertiesSecurityProtocol(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The security protocol."""

    SASL_PLAINTEXT = "SASL_PLAINTEXT"
    PLAINTEXT = "PLAINTEXT"
    SASL_SSL = "SASL_SSL"
    SSL = "SSL"


class AzureBlobStorageEventsIncludedEventTypesItem(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """AzureBlobStorageEventsIncludedEventTypesItem."""

    MICROSOFT_STORAGE_BLOB_CREATED = "Microsoft.Storage.BlobCreated"
    MICROSOFT_STORAGE_BLOB_DELETED = "Microsoft.Storage.BlobDeleted"
    MICROSOFT_STORAGE_BLOB_RENAMED = "Microsoft.Storage.BlobRenamed"
    MICROSOFT_STORAGE_BLOB_TIER_CHANGED = "Microsoft.Storage.BlobTierChanged"
    MICROSOFT_STORAGE_DIRECTORY_CREATED = "Microsoft.Storage.DirectoryCreated"
    MICROSOFT_STORAGE_DIRECTORY_DELETED = "Microsoft.Storage.DirectoryDeleted"
    MICROSOFT_STORAGE_DIRECTORY_RENAMED = "Microsoft.Storage.DirectoryRenamed"
    MICROSOFT_STORAGE_BLOB_INVENTORY_POLICY_COMPLETED = "Microsoft.Storage.BlobInventoryPolicyCompleted"
    MICROSOFT_STORAGE_ASYNC_OPERATION_INITIATED = "Microsoft.Storage.AsyncOperationInitiated"
    MICROSOFT_STORAGE_LIFECYCLE_POLICY_COMPLETED = "Microsoft.Storage.LifecyclePolicyCompleted"


class AzureCosmosDBCDCSourcePropertiesOffsetPolicy(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The offset policy."""

    EARLIEST = "Earliest"
    LATEST = "Latest"


class BaseKafkaSourcePropertiesAutoOffsetReset(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The auto offset reset property. Default is None."""

    NONE = "None"
    EARLIEST = "Earliest"
    LATEST = "Latest"


class CompatibilityLevel(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Represents the compatibility level of the Eventstream topology. Additional compatibility levels
    may be added over time.
    """

    ONE0 = "1.0"
    """The compatibility level of the Eventstream topology is 1.0."""


class CsvSerializationPropertiesEncoding(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The encoding type."""

    UTF8 = "UTF8"


class CsvSerializationPropertiesFormat(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The format type."""

    WITH_HEADERS = "WithHeaders"
    WITHOUT_HEADERS = "WithoutHeaders"


class DataSourceStartType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Represents the start type of the data source. Additional start types may be added over time."""

    NOW = "Now"
    """The data source starts now."""
    WHEN_LAST_STOPPED = "WhenLastStopped"
    """The data source starts when it was last stopped."""
    CUSTOM_TIME = "CustomTime"
    """The data source starts at a custom time."""


class DataType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Represents the data type. Additional data types may be added over time."""

    BIG_INT = "BigInt"
    """BigInt data type."""
    FLOAT = "Float"
    """Float data type."""
    NVARCHAR_MAX_ = "Nvarchar(max)"
    """Nvarchar(max) data type."""
    DATE_TIME = "DateTime"
    """DateTime data type."""
    BIT = "Bit"
    """Bit data type."""
    RECORD = "Record"
    """Record data type."""
    ARRAY = "Array"
    """Array data type."""
    ANY = "Any"
    """Unknown data type."""


class DestinationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Represents the type of the destination. Additional destination types may be added over time."""

    ACTIVATOR = "Activator"
    """The Activator destination type."""
    CUSTOM_ENDPOINT = "CustomEndpoint"
    """The CustomEndpoint destination type."""
    EVENTHOUSE = "Eventhouse"
    """The Eventhouse destination type."""
    LAKEHOUSE = "Lakehouse"
    """The Lakehouse destination type."""


class EventhouseDestinationPropertiesDataIngestionMode(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The data ingestion mode."""

    DIRECT_INGESTION = "DirectIngestion"
    PROCESSED_INGESTION = "ProcessedIngestion"


class FabricCapacityUtilizationEventsSourcePropertiesEventScope(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """FabricCapacityUtilizationEventsSourcePropertiesEventScope."""

    TENANT = "Tenant"
    CAPACITY = "Capacity"
    WORKSPACE = "Workspace"
    ITEM = "Item"
    SUB_ITEM = "SubItem"


class FabricJobEventsSourcePropertiesEventScope(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """FabricJobEventsSourcePropertiesEventScope."""

    TENANT = "Tenant"
    CAPACITY = "Capacity"
    WORKSPACE = "Workspace"
    ITEM = "Item"
    SUB_ITEM = "SubItem"


class FabricWorkspaceItemEventsSourcePropertiesEventScope(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """FabricWorkspaceItemEventsSourcePropertiesEventScope."""

    TENANT = "Tenant"
    CAPACITY = "Capacity"
    WORKSPACE = "Workspace"
    ITEM = "Item"
    SUB_ITEM = "SubItem"


class FilterConditionOperatorType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The operator type."""

    EQUALS = "Equals"
    NOT_EQUALS = "NotEquals"
    GREATER_THAN = "GreaterThan"
    GREATER_THAN_OR_EQUALS = "GreaterThanOrEquals"
    LESS_THAN = "LessThan"
    LESS_THAN_OR_EQUALS = "LessThanOrEquals"
    CONTAINS = "Contains"
    DOES_NOT_CONTAIN = "DoesNotContain"
    STARTS_WITH = "StartsWith"
    DOES_NOT_START_WITH = "DoesNotStartWith"
    ENDS_WITH = "EndsWith"
    DOES_NOT_END_WITH = "DoesNotEndWith"
    IS_EMPTY = "IsEmpty"
    IS_NULL = "IsNull"
    IS_NOT_NULL = "IsNotNull"
    IS_NOT_NULL_OR_EMPTY = "IsNotNullOrEmpty"


class GroupByWindowType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The type of the window."""

    TUMBLING = "Tumbling"
    HOPPING = "Hopping"
    SLIDING = "Sliding"
    SNAPSHOT = "Snapshot"
    SESSION = "Session"


class ItemType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The type of the item. Additional item types may be added over time."""

    DASHBOARD = "Dashboard"
    """PowerBI dashboard."""
    REPORT = "Report"
    """PowerBI report."""
    SEMANTIC_MODEL = "SemanticModel"
    """PowerBI semantic model."""
    PAGINATED_REPORT = "PaginatedReport"
    """PowerBI paginated report."""
    DATAMART = "Datamart"
    """PowerBI datamart."""
    LAKEHOUSE = "Lakehouse"
    """A lakehouse."""
    EVENTHOUSE = "Eventhouse"
    """An eventhouse."""
    ENVIRONMENT = "Environment"
    """An environment."""
    KQL_DATABASE = "KQLDatabase"
    """A KQL database."""
    KQL_QUERYSET = "KQLQueryset"
    """A KQL queryset."""
    KQL_DASHBOARD = "KQLDashboard"
    """A KQL dashboard."""
    DATA_PIPELINE = "DataPipeline"
    """A data pipeline."""
    NOTEBOOK = "Notebook"
    """A notebook."""
    SPARK_JOB_DEFINITION = "SparkJobDefinition"
    """A spark job definition."""
    ML_EXPERIMENT = "MLExperiment"
    """A machine learning experiment."""
    ML_MODEL = "MLModel"
    """A machine learning model."""
    WAREHOUSE = "Warehouse"
    """A warehouse."""
    EVENTSTREAM = "Eventstream"
    """An eventstream."""
    SQL_ENDPOINT = "SQLEndpoint"
    """An SQL endpoint."""
    MIRRORED_WAREHOUSE = "MirroredWarehouse"
    """A mirrored warehouse."""
    MIRRORED_DATABASE = "MirroredDatabase"
    """A mirrored database."""
    REFLEX = "Reflex"
    """A Reflex."""
    GRAPH_QL_API = "GraphQLApi"
    """An API for GraphQL item."""
    MOUNTED_DATA_FACTORY = "MountedDataFactory"
    """A MountedDataFactory."""
    APACHE_AIRFLOW_JOB = "ApacheAirflowJob"
    """An ApacheAirflowJob."""
    SQL_DATABASE = "SQLDatabase"
    """A SQLDatabase."""
    COPY_JOB = "CopyJob"
    """A Copy job."""
    VARIABLE_LIBRARY = "VariableLibrary"
    """A VariableLibrary."""
    MIRRORED_AZURE_DATABRICKS_CATALOG = "MirroredAzureDatabricksCatalog"
    """A mirrored azure databricks catalog."""
    DATAFLOW = "Dataflow"
    """A Dataflow."""
    WAREHOUSE_SNAPSHOT = "WarehouseSnapshot"
    """A Warehouse snapshot."""
    DIGITAL_TWIN_BUILDER = "DigitalTwinBuilder"
    """A DigitalTwinBuilder."""
    DIGITAL_TWIN_BUILDER_FLOW = "DigitalTwinBuilderFlow"
    """A Digital Twin Builder Flow."""
    ANOMALY_DETECTOR = "AnomalyDetector"
    """An Anomaly Detector."""
    MAP = "Map"
    """A Map."""
    USER_DATA_FUNCTION = "UserDataFunction"
    """A User Data Function."""


class JoinOperatorPropertiesJoinType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The type of the join."""

    INNER = "Inner"
    LEFT_OUTER = "LeftOuter"


class JsonSerializationPropertiesEncoding(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The encoding type."""

    UTF8 = "UTF8"


class NodeStatus(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The status of the node. Additional node status may be added over time."""

    UNKNOWN = "Unknown"
    """The status of the node is unknown."""
    CREATING = "Creating"
    """The node is being created."""
    CREATED = "Created"
    """The node has been created."""
    UPDATING = "Updating"
    """The node is being updated."""
    RUNNING = "Running"
    """The node is running."""
    PAUSED = "Paused"
    """The node is paused."""
    FAILED = "Failed"
    """The node has failed."""
    WARNING = "Warning"
    """The node has a warning."""
    DELETING = "Deleting"
    """The node is being deleted."""
    PAUSING = "Pausing"
    """The node is being paused."""
    RESUMING = "Resuming"
    """The node is being resumed."""
    EXTERNAL = "External"
    """The node status depends on an external service."""


class OperatorCommonDurationUnit(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The unit of the duration."""

    MICROSECOND = "Microsecond"
    MILLISECOND = "Millisecond"
    SECOND = "Second"
    MINUTE = "Minute"
    HOUR = "Hour"
    DAY = "Day"
    WEEKDAY = "Weekday"
    WEEK = "Week"
    DAY_OF_YEAR = "DayOfYear"
    MONTH = "Month"
    QUARTER = "Quarter"
    YEAR = "Year"


class OperatorType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The type of the operator. Additional operator types may be added over time."""

    FILTER = "Filter"
    """The operator filters the input data."""
    JOIN = "Join"
    """The operator joins the input data."""
    MANAGE_FIELDS = "ManageFields"
    """The operator manages the fields of the input data."""
    AGGREGATE = "Aggregate"
    """The operator aggregates the input data."""
    GROUP_BY = "GroupBy"
    """The operator groups the input data."""
    UNION = "Union"
    """The operator unions the input data."""
    EXPAND = "Expand"
    """The operator expands the input data."""


class PayloadType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The type of the definition part payload. Additional payload types may be added over time."""

    INLINE_BASE64 = "InlineBase64"
    """Inline Base 64."""


class SampleDataSourcePropertiesType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The sample data type."""

    YELLOW_TAXI = "YellowTaxi"
    STOCK_MARKET = "StockMarket"
    BICYCLES = "Bicycles"


class SerializationType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The serialization type."""

    AVRO = "Avro"
    """The serialization type is Avro."""
    JSON = "Json"
    """The serialization type is JSON."""
    CSV = "Csv"
    """The serialization type is CSV."""


class SourceType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Represents the type of the source. Additional source types may be added over time."""

    AMAZON_KINESIS = "AmazonKinesis"
    """The Amazon Kinesis source type."""
    AMAZON_MSK_KAFKA = "AmazonMSKKafka"
    """The Amazon MSK Kafka source type."""
    APACHE_KAFKA = "ApacheKafka"
    """The Apache Kafka source type."""
    AZURE_BLOB_STORAGE_EVENTS = "AzureBlobStorageEvents"
    """The Azure Blob Storage Events source type."""
    AZURE_COSMOS_DBCDC = "AzureCosmosDBCDC"
    """The Azure Cosmos DB CDC source type."""
    AZURE_EVENT_HUB = "AzureEventHub"
    """The Azure Event Hub source type."""
    AZURE_IO_T_HUB = "AzureIoTHub"
    """The Azure IoT Hub source type."""
    AZURE_SQLDBCDC = "AzureSQLDBCDC"
    """The Azure SQL DB CDC source type."""
    AZURE_SQLMIDBCDC = "AzureSQLMIDBCDC"
    """The Azure SQL MI DB CDC source type."""
    CONFLUENT_CLOUD = "ConfluentCloud"
    """The Confluent Cloud source type."""
    CUSTOM_ENDPOINT = "CustomEndpoint"
    """The Custom Endpoint source type."""
    FABRIC_CAPACITY_UTILIZATION_EVENTS = "FabricCapacityUtilizationEvents"
    """The Fabric Capacity Utilization Events source type."""
    FABRIC_JOB_EVENTS = "FabricJobEvents"
    """The Fabric Job Events source type."""
    FABRIC_ONE_LAKE_EVENTS = "FabricOneLakeEvents"
    """The Fabric One Lake Events source type."""
    FABRIC_WORKSPACE_ITEM_EVENTS = "FabricWorkspaceItemEvents"
    """The Fabric Workspace Item Events source type."""
    GOOGLE_PUB_SUB = "GooglePubSub"
    """The Google PubSub source type."""
    MY_SQLCDC = "MySQLCDC"
    """The MySQL CDC source type."""
    POSTGRE_SQLCDC = "PostgreSQLCDC"
    """The PostgreSQL CDC source type."""
    SQL_SERVER_ON_VMDBCDC = "SQLServerOnVMDBCDC"
    """The SQL Server on VM DB CDC source type."""
    SAMPLE_DATA = "SampleData"
    """The Sample Data source type."""


class StreamType(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """Represents the type of the stream. Additional stream types may be added over time."""

    DEFAULT_STREAM = "DefaultStream"
    """The stream is a default stream."""
    DERIVED_STREAM = "DerivedStream"
    """The stream is derived from another stream."""


class Type(str, Enum, metaclass=CaseInsensitiveEnumMeta):
    """The operation type."""

    FUNCTION_CALL = "FunctionCall"
    """Function call operation."""
    CAST = "Cast"
    """Cast operation."""
    RENAME = "Rename"
    """Rename operation."""
