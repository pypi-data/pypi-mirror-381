#!/usr/bin/env python3
"""
Issues ç»Ÿä¸€åŒæ­¥è„šæœ¬ - æ”¯æŒæ‰€æœ‰å±æ€§çš„åŒæ­¥

åŠŸèƒ½:
- åŸºæœ¬å±æ€§åŒæ­¥: assignee, labels, title, body, milestone (REST API)
- é¡¹ç›®æ¿åŒæ­¥: projects (GraphQL API)
- æ”¯æŒå¼ºåˆ¶æ›´æ–°å’Œé¢„è§ˆæ¨¡å¼
- å®Œæ•´çš„é”™è¯¯å¤„ç†å’ŒçŠ¶æ€æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•:
    python3 sync_issues.py --preview                    # é¢„è§ˆæ‰€æœ‰æ›´æ”¹
    python3 sync_issues.py --apply-all --confirm        # åº”ç”¨æ‰€æœ‰æ›´æ”¹
    python3 sync_issues.py --apply-basic --confirm      # ä»…åŒæ­¥åŸºæœ¬å±æ€§
    python3 sync_issues.py --apply-projects --confirm   # ä»…åŒæ­¥é¡¹ç›®æ¿
    python3 sync_issues.py --force-update               # å¼ºåˆ¶æ›´æ–°ï¼ˆå¿½ç•¥æ—¶é—´æˆ³ï¼‰

ä½œè€…: SAGE Team
æ—¥æœŸ: 2025-08-30
"""
import argparse
import json
import re
import sys
import time
from datetime import datetime
from pathlib import Path

import requests
from github_helper import GitHubProjectManager

SCRIPT_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(SCRIPT_DIR.parent))  # Add parent directory to path


# åŠ¨æ€å¯¼å…¥configæ¨¡å—
try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥ï¼ˆå½“ä½œä¸ºæ¨¡å—è¿è¡Œæ—¶ï¼‰
    from ..config import IssuesConfig
    from ..issue_data_manager import IssueDataManager
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç»å¯¹å¯¼å…¥
    sys.path.insert(0, str(SCRIPT_DIR.parent))
    from config import IssuesConfig
    from issue_data_manager import IssueDataManager

# Import github_helper directly
sys.path.insert(0, str(SCRIPT_DIR))


class GitHubClient:
    """Simple GitHub API client"""

    def __init__(self, config):
        self.config = config
        self.session = requests.Session()

        if config.github_token:
            headers = {
                "Authorization": f"token {config.github_token}",
                "Accept": "application/vnd.github.v3+json",
            }
            self.session.headers.update(headers)
        else:
            raise ValueError("GitHub Token is required for sync operations")


def graphql_request(
    session: requests.Session,
    query: str,
    variables: dict | None = None,
    retries: int = 2,
):
    payload = {"query": query}
    if variables is not None:
        payload["variables"] = variables
    attempt = 0
    while True:
        try:
            resp = session.post(
                "https://api.github.com/graphql", json=payload, timeout=30
            )
            resp.raise_for_status()
            data = resp.json()
            return True, data
        except Exception as e:
            attempt += 1
            if attempt > retries:
                return False, str(e)
            time.sleep(1 * attempt)


class IssuesSyncer:
    def __init__(self):
        self.config = IssuesConfig()
        self.github_client = GitHubClient(self.config)
        self.project_manager = GitHubProjectManager()
        self.workspace_dir = self.config.workspace_path
        self.output_dir = self.config.output_path

        # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        self.data_manager = IssueDataManager(self.workspace_dir)

        # é»˜è®¤å¯ç”¨å¼ºåˆ¶æ›´æ–°
        self.force_update = True

        # å›¢é˜Ÿåˆ°é¡¹ç›®çš„æ˜ å°„
        self.team_to_project = {
            "intellistream": 6,  # IntelliStreamæ€»ä½“é¡¹ç›®
            "sage-kernel": 12,
            "sage-middleware": 13,
            "sage-apps": 14,
        }

    def detect_all_changes(self):
        """æ£€æµ‹æ‰€æœ‰ç±»å‹çš„æ›´æ”¹"""
        basic_changes = self.detect_basic_changes()
        project_changes = self.detect_project_changes()

        all_changes = basic_changes + project_changes

        if all_changes:
            print(f"ğŸ“‹ æ£€æµ‹åˆ° {len(all_changes)} ä¸ªå¾…åŒæ­¥æ›´æ”¹:")

            basic_count = len([c for c in all_changes if c["type"] == "basic"])
            project_count = len([c for c in all_changes if c["type"] == "project"])

            if basic_count > 0:
                print(f"  ğŸ”§ åŸºæœ¬å±æ€§æ›´æ”¹: {basic_count} ä¸ª")
            if project_count > 0:
                print(f"  ğŸ“‹ é¡¹ç›®æ¿æ›´æ”¹: {project_count} ä¸ª")

            for change in all_changes[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
                print(f"   - [{change['type']}] {change['description']}")

            if len(all_changes) > 20:
                print(f"   ... ä»¥åŠå…¶ä»– {len(all_changes) - 20} ä¸ªæ›´æ”¹")

        return all_changes

    def detect_changes_limited(self, limit=50, recent_only=False):
        """æ£€æµ‹æœ‰é™æ•°é‡çš„æ›´æ”¹ï¼ˆç”¨äºå¿«é€Ÿé¢„è§ˆï¼‰"""
        from datetime import datetime, timedelta

        changes = []

        # ä½¿ç”¨æ–°æ¶æ„ï¼šè¯»å–dataç›®å½•ä¸‹çš„JSONæ–‡ä»¶
        data_dir = self.workspace_dir / "data"
        if not data_dir.exists():
            print("âŒ dataç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½issuesæ•°æ®")
            return changes

        files = list(data_dir.glob("issue_*.json"))

        # å¦‚æœåªæ£€æŸ¥æœ€è¿‘æ›´æ–°çš„issues
        if recent_only:
            cutoff_date = datetime.now() - timedelta(days=7)
            filtered_files = []

            for f in files:
                try:
                    issue_data = self.data_manager.get_issue(int(f.stem.split("_")[1]))
                    if issue_data:
                        updated_str = issue_data["metadata"].get("updated_at", "")
                        if updated_str:
                            updated_date = datetime.fromisoformat(
                                updated_str.replace("Z", "+00:00")
                            )
                            if updated_date.replace(tzinfo=None) > cutoff_date:
                                filtered_files.append(f)
                except Exception:
                    continue

            files = filtered_files
            print(f"ğŸ” è¿‡æ»¤åˆ°æœ€è¿‘7å¤©æ›´æ–°çš„issues: {len(files)} ä¸ª")

        # é™åˆ¶æ£€æŸ¥æ•°é‡
        files = files[:limit]
        print(f"ğŸ” æ£€æŸ¥ {len(files)} ä¸ªJSONæ–‡ä»¶...")

        for i, f in enumerate(files):
            print(f"ğŸ” è¿›åº¦: {i + 1}/{len(files)} - Issue #{f.stem.split('_')[1]}")

            try:
                # ä½¿ç”¨æ•°æ®ç®¡ç†å™¨è¯»å–issue
                issue_number = int(f.stem.split("_")[1])
                local_data = self.data_manager.get_issue(issue_number)
                if not local_data:
                    continue

                # è·å–è¿œç«¯æ•°æ®
                remote_data = self._get_remote_issue(issue_number)
                if not remote_data:
                    continue

                # æ¯”è¾ƒå¹¶æ£€æµ‹æ›´æ”¹
                changes_detected = self._compare_basic_attributes_json(
                    local_data, remote_data, issue_number, str(f)
                )
                changes.extend(changes_detected)

            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {f} æ—¶å‡ºé”™: {e}")
                continue

        return changes

    def sync_all_changes(self, apply_projects=False, auto_confirm=False):
        """ç»Ÿä¸€åŒæ­¥æ‰€æœ‰ç±»å‹çš„æ›´æ”¹"""
        changes = self.detect_all_changes()
        if not changes:
            print("âœ… æ²¡æœ‰æ£€æµ‹åˆ°éœ€è¦åŒæ­¥çš„æ›´æ”¹")
            return True

        # åˆ†ç»„å¤„ç†ä¸åŒç±»å‹çš„æ›´æ”¹
        basic_changes = [c for c in changes if c["type"] == "basic"]
        project_changes = [c for c in changes if c["type"] == "project"]

        print(f"ğŸ“‹ æ£€æµ‹åˆ° {len(changes)} ä¸ªå¾…åŒæ­¥æ›´æ”¹:")
        if basic_changes:
            print(f"  ğŸ”§ åŸºæœ¬å±æ€§æ›´æ”¹: {len(basic_changes)} ä¸ª")
        if project_changes:
            print(f"  ğŸ“‹ é¡¹ç›®æ¿æ›´æ”¹: {len(project_changes)} ä¸ª")

        # å¦‚æœæ²¡æœ‰apply_projectsä¸”æœ‰é¡¹ç›®æ›´æ”¹ï¼Œåªæ˜¾ç¤ºé¢„è§ˆ
        if project_changes and not apply_projects:
            print(f"\nğŸ’¡ å‘ç° {len(project_changes)} ä¸ªé¡¹ç›®æ¿æ›´æ”¹:")
            for change in project_changes[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                print(f"   - {change['description']}")
            if len(project_changes) > 10:
                print(f"   ... ä»¥åŠå…¶ä»– {len(project_changes) - 10} ä¸ªé¡¹ç›®æ¿æ›´æ”¹")
            print("ğŸ’¡ ä½¿ç”¨ --apply-projects å‚æ•°æ¥åº”ç”¨é¡¹ç›®æ¿æ›´æ”¹")

            # åªå¤„ç†åŸºæœ¬å±æ€§æ›´æ”¹
            if basic_changes:
                print(f"\nğŸš€ å¼€å§‹åŒæ­¥åŸºæœ¬å±æ€§æ›´æ”¹ ({len(basic_changes)} ä¸ª)...")
                return self._sync_basic_changes_only(basic_changes)
            else:
                return True

        # éœ€è¦ç”¨æˆ·ç¡®è®¤ï¼ˆé™¤éauto_confirmä¸ºTrueï¼‰
        if not auto_confirm:
            confirm = (
                input(f"\næ˜¯å¦åŒæ­¥è¿™ {len(changes)} ä¸ªæ›´æ”¹? (y/N): ").lower().strip()
            )
            if confirm != "y":
                print("âŒ åŒæ­¥å·²å–æ¶ˆ")
                return False

        print(f"\nğŸš€ å¼€å§‹åŒæ­¥ {len(changes)} ä¸ªæ›´æ”¹...")

        success_count = 0

        # å¤„ç†åŸºæœ¬å±æ€§æ›´æ”¹ (ä½¿ç”¨REST API)
        if basic_changes:
            print(f"\nğŸ“ åŒæ­¥åŸºæœ¬å±æ€§æ›´æ”¹ ({len(basic_changes)} ä¸ª)...")
            for change in basic_changes:
                if self._apply_basic_change(change):
                    success_count += 1
                    print(f"âœ… {change['description']}")
                else:
                    print(f"âŒ {change['description']}")

        # å¤„ç†é¡¹ç›®æ¿æ›´æ”¹ (ä½¿ç”¨GraphQL API)
        if project_changes and apply_projects:
            print(f"\nğŸ“‹ åŒæ­¥é¡¹ç›®æ¿æ›´æ”¹ ({len(project_changes)} ä¸ª)...")
            success = self._apply_project_changes(project_changes)
            if success:
                success_count += len(project_changes)
                print(f"âœ… æˆåŠŸå¤„ç† {len(project_changes)} ä¸ªé¡¹ç›®æ¿æ›´æ”¹")
            else:
                print("âŒ é¡¹ç›®æ¿æ›´æ”¹å¤„ç†å¤±è´¥")

        print(f"\nâœ¨ åŒæ­¥å®Œæˆ: {success_count}/{len(changes)} ä¸ªæ›´æ”¹æˆåŠŸ")

        # å¦‚æœæœ‰æˆåŠŸçš„æ›´æ”¹ï¼Œé‡æ–°ç”Ÿæˆè§†å›¾
        if success_count > 0:
            print("\nğŸ”„ é‡æ–°ç”Ÿæˆè§†å›¾...")
            try:
                # é‡æ–°ä¸‹è½½å¹¶æ›´æ–°æœ¬åœ°æ•°æ®
                self._update_local_data_after_sync(basic_changes[:success_count])

                # é‡æ–°ç”Ÿæˆæ‰€æœ‰è§†å›¾
                self.data_manager.generate_all_views()
                print("âœ… è§†å›¾é‡æ–°ç”Ÿæˆå®Œæˆ")
            except Exception as e:
                print(f"âš ï¸ è§†å›¾é‡æ–°ç”Ÿæˆå¤±è´¥: {e}")

        return success_count == len(changes)

    def _update_local_data_after_sync(self, successful_changes):
        """åŒæ­¥æˆåŠŸåæ›´æ–°æœ¬åœ°æ•°æ®"""
        for change in successful_changes:
            if change["type"] == "basic":
                issue_number = change["issue_number"]
                try:
                    # é‡æ–°ä»GitHubè·å–æœ€æ–°æ•°æ®
                    remote_data = self._get_remote_issue(issue_number)
                    if remote_data:
                        # è·å–ç°æœ‰çš„æœ¬åœ°æ•°æ®
                        local_data = self.data_manager.get_issue(issue_number)
                        if local_data:
                            # æ›´æ–°metadataéƒ¨åˆ†
                            local_data["metadata"].update(
                                {
                                    "title": remote_data.get("title", ""),
                                    "labels": [
                                        label.get("name")
                                        for label in remote_data.get("labels", [])
                                    ],
                                    "assignees": (
                                        [remote_data["assignee"]["login"]]
                                        if remote_data.get("assignee")
                                        else []
                                    ),
                                    "milestone": remote_data.get("milestone"),
                                    "updated_at": remote_data.get("updated_at"),
                                }
                            )

                            # æ›´æ–°contentéƒ¨åˆ†
                            local_data["content"]["body"] = remote_data.get("body", "")

                            # æ›´æ–°trackingä¿¡æ¯
                            local_data["tracking"][
                                "last_synced"
                            ] = datetime.now().isoformat()
                            local_data["tracking"]["update_history"].append(
                                {
                                    "timestamp": datetime.now().isoformat(),
                                    "action": "sync_update",
                                    "github_updated": remote_data.get("updated_at"),
                                }
                            )

                            # ä¿å­˜æ›´æ–°åçš„æ•°æ®
                            self.data_manager.save_issue(issue_number, local_data)
                            print(f"  âœ… å·²æ›´æ–°æœ¬åœ°æ•°æ®: Issue #{issue_number}")

                except Exception as e:
                    print(f"  âš ï¸ æ›´æ–°æœ¬åœ°æ•°æ®å¤±è´¥ Issue #{issue_number}: {e}")

    def _sync_basic_changes_only(self, basic_changes):
        """ä»…åŒæ­¥åŸºæœ¬å±æ€§æ›´æ”¹"""
        success_count = 0
        for change in basic_changes:
            if self._apply_basic_change(change):
                success_count += 1
                print(f"âœ… {change['description']}")
            else:
                print(f"âŒ {change['description']}")

        print(f"\nâœ¨ åŸºæœ¬å±æ€§åŒæ­¥å®Œæˆ: {success_count}/{len(basic_changes)} ä¸ªæ›´æ”¹æˆåŠŸ")
        return success_count == len(basic_changes)

    def _apply_basic_change(self, change):
        """åº”ç”¨åŸºæœ¬å±æ€§æ›´æ”¹ (REST API)"""
        issue_number = change["issue_number"]
        local_data = change["local_data"]

        url = f"https://api.github.com/repos/{self.config.GITHUB_OWNER}/{self.config.GITHUB_REPO}/issues/{issue_number}"

        # æ„å»ºæ›´æ–°æ•°æ®
        update_data = {}

        # åªæ›´æ–°æœ‰å·®å¼‚çš„å±æ€§
        for attr in change["changed_attributes"]:
            if attr == "æ ‡é¢˜" and local_data["title"]:
                update_data["title"] = local_data["title"]
            elif attr == "å†…å®¹" and local_data["body"]:
                update_data["body"] = local_data["body"]
            elif attr == "æ ‡ç­¾":
                update_data["labels"] = local_data["labels"]
            elif attr == "åˆ†é…ç»™":
                if local_data["assignee"]:
                    update_data["assignee"] = local_data["assignee"]
                else:
                    update_data["assignee"] = None
            elif attr == "é‡Œç¨‹ç¢‘":
                if local_data["milestone"]:
                    # éœ€è¦è·å–milestoneçš„number
                    milestone_number = self._get_milestone_number(
                        local_data["milestone"]
                    )
                    if milestone_number:
                        update_data["milestone"] = milestone_number
                else:
                    update_data["milestone"] = None

        if not update_data:
            return True

        try:
            resp = self.github_client.session.patch(url, json=update_data, timeout=30)
            return resp.status_code == 200
        except Exception as e:
            print(f"   âŒ æ›´æ–°å¤±è´¥: {e}")
            return False

    def _apply_project_changes(self, project_changes):
        """åº”ç”¨é¡¹ç›®æ¿æ›´æ”¹ (GraphQL API)"""
        if not project_changes:
            return True

        success_count = 0

        try:
            for change in project_changes:
                issue_number = change["issue_number"]
                target_project_number = change["target_project_number"]
                target_project = change["target_project"]

                print(
                    f"   ğŸ”„ ç§»åŠ¨Issue #{issue_number}åˆ°é¡¹ç›®{target_project} (#{target_project_number})..."
                )

                # è·å–issueçš„node_id
                issue_data = self._get_remote_issue(issue_number)
                if not issue_data:
                    print(f"   âŒ æ— æ³•è·å–Issue #{issue_number}çš„æ•°æ®")
                    continue

                issue_node_id = issue_data.get("node_id")
                if not issue_node_id:
                    print(f"   âŒ æ— æ³•è·å–Issue #{issue_number}çš„node_id")
                    continue

                # è·å–é¡¹ç›®çš„project_id
                project_id = self.project_manager.get_project_id(target_project_number)
                if not project_id:
                    print(f"   âŒ æ— æ³•è·å–é¡¹ç›®#{target_project_number}çš„project_id")
                    continue

                # æ£€æŸ¥issueæ˜¯å¦å·²åœ¨ç›®æ ‡é¡¹ç›®ä¸­
                if target_project_number in change["current_projects"]:
                    print(f"   â­ï¸ Issue #{issue_number}å·²åœ¨ç›®æ ‡é¡¹ç›®ä¸­ï¼Œè·³è¿‡")
                    success_count += 1
                    continue

                # ä½¿ç”¨GraphQLæ·»åŠ issueåˆ°é¡¹ç›®
                success = self._add_issue_to_project(
                    issue_node_id, project_id, target_project_number
                )
                if success:
                    success_count += 1
                    print(f"   âœ… æˆåŠŸç§»åŠ¨Issue #{issue_number}åˆ°é¡¹ç›®{target_project}")
                else:
                    print(f"   âŒ ç§»åŠ¨Issue #{issue_number}å¤±è´¥")

            return success_count == len(project_changes)

        except Exception as e:
            print(f"   âŒ é¡¹ç›®æ¿æ›´æ”¹å¤±è´¥: {e}")
            return False

    def _add_issue_to_project(self, issue_node_id, project_id, project_number):
        """ä½¿ç”¨GraphQLå°†issueæ·»åŠ åˆ°é¡¹ç›®"""
        try:
            mutation = """
                mutation($projectId: ID!, $contentId: ID!) {
                    addProjectV2ItemById(input: {
                        projectId: $projectId,
                        contentId: $contentId
                    }) {
                        item {
                            id
                        }
                    }
                }
            """

            variables = {"projectId": project_id, "contentId": issue_node_id}

            # ä½¿ç”¨project_managerçš„GraphQLå®¢æˆ·ç«¯
            response = self.project_manager.execute_graphql(mutation, variables)

            if (
                response
                and "data" in response
                and response["data"]["addProjectV2ItemById"]
            ):
                return True
            else:
                print(f"   âŒ GraphQLå“åº”é”™è¯¯: {response}")
                return False

        except Exception as e:
            print(f"   âŒ GraphQLè°ƒç”¨å¤±è´¥: {e}")
            return False

    def _get_milestone_number(self, milestone_title):
        """è·å–milestoneçš„ç¼–å·"""
        url = f"https://api.github.com/repos/{self.config.GITHUB_OWNER}/{self.config.GITHUB_REPO}/milestones"
        try:
            resp = self.github_client.session.get(url, timeout=20)
            if resp.status_code == 200:
                milestones = resp.json()
                for m in milestones:
                    if m["title"] == milestone_title:
                        return m["number"]
        except Exception:
            pass
        return None

    def sync_one_issue(self, issue_number):
        """åŒæ­¥å•ä¸ªissue"""
        print(f"ğŸ”„ æ£€æŸ¥issue #{issue_number}...")

        issues_dir = self.workspace_dir / "issues"
        file_pattern = f"open_{issue_number}_*.md"
        files = list(issues_dir.glob(file_pattern))

        if not files:
            print(f"âŒ æœªæ‰¾åˆ°issue #{issue_number}çš„æœ¬åœ°æ–‡ä»¶")
            return False

        # æ£€æµ‹è¿™ä¸ªissueçš„æ‰€æœ‰æ›´æ”¹
        all_changes = []
        for f in files:
            text = f.read_text(encoding="utf-8")
            local_data = self._parse_local_issue(text)

            # æ£€æµ‹åŸºæœ¬å±æ€§æ›´æ”¹
            remote_data = self._get_remote_issue(issue_number)
            if remote_data:
                basic_changes = self._compare_basic_attributes(
                    local_data, remote_data, issue_number, str(f)
                )
                all_changes.extend(basic_changes)

            # æ£€æµ‹é¡¹ç›®æ›´æ”¹
            local_project = self._parse_local_project(text)
            if local_project:
                current_projects = self._get_issue_current_projects(issue_number)
                expected_project_num = self.team_to_project.get(local_project)
                if (
                    expected_project_num
                    and expected_project_num not in current_projects
                ):
                    all_changes.append(
                        {
                            "type": "project",
                            "description": f"Issue #{issue_number} - ç§»åŠ¨åˆ°é¡¹ç›® {local_project}",
                            "issue_number": issue_number,
                            "current_projects": current_projects,
                            "target_project": local_project,
                            "target_project_number": expected_project_num,
                            "file": str(f),
                        }
                    )

        if not all_changes:
            print(f"âœ… Issue #{issue_number} æ— éœ€åŒæ­¥")
            return True

        print(f"ğŸ“‹ å‘ç° {len(all_changes)} ä¸ªæ›´æ”¹:")
        for change in all_changes:
            print(f"   - {change['description']}")

        # åº”ç”¨æ›´æ”¹
        success_count = 0
        for change in all_changes:
            if change["type"] == "basic":
                if self._apply_basic_change(change):
                    success_count += 1
                    print(f"âœ… {change['description']}")
                else:
                    print(f"âŒ {change['description']}")
            elif change["type"] == "project":
                if self._apply_project_changes([change]):
                    success_count += 1
                    print(f"âœ… {change['description']}")
                else:
                    print(f"âŒ {change['description']}")

        print(f"âœ¨ åŒæ­¥å®Œæˆ: {success_count}/{len(all_changes)} ä¸ªæ›´æ”¹æˆåŠŸ")
        return success_count == len(all_changes)

    def show_sync_status(self):
        """æ˜¾ç¤ºåŒæ­¥çŠ¶æ€æ¦‚è§ˆ"""
        print("\nğŸ” æ£€æŸ¥åŒæ­¥çŠ¶æ€...")

        changes = self.detect_all_changes()

        if not changes:
            print("âœ… æ‰€æœ‰issueséƒ½å·²åŒæ­¥")
            return

        # æŒ‰ç±»å‹åˆ†ç»„ç»Ÿè®¡
        basic_changes = [c for c in changes if c["type"] == "basic"]
        project_changes = [c for c in changes if c["type"] == "project"]

        print("\nğŸ“Š åŒæ­¥çŠ¶æ€æ¦‚è§ˆ:")
        print(f"   æ€»å…±éœ€è¦åŒæ­¥: {len(changes)} ä¸ªæ›´æ”¹")

        if basic_changes:
            print(f"   åŸºæœ¬å±æ€§æ›´æ”¹: {len(basic_changes)} ä¸ª")
            # æŒ‰å±æ€§ç±»å‹åˆ†ç»„
            attr_count = {}
            for change in basic_changes:
                for attr in change.get("changed_attributes", []):
                    attr_count[attr] = attr_count.get(attr, 0) + 1

            for attr, count in attr_count.items():
                print(f"      - {attr}: {count} ä¸ª")

        if project_changes:
            print(f"   é¡¹ç›®æ¿æ›´æ”¹: {len(project_changes)} ä¸ª")
            # æŒ‰ç›®æ ‡é¡¹ç›®åˆ†ç»„
            project_count = {}
            for change in project_changes:
                target = change.get("target_project", "æœªçŸ¥")
                project_count[target] = project_count.get(target, 0) + 1

            for project, count in project_count.items():
                print(f"      - {project}: {count} ä¸ª")

        print("\nğŸ’¡ è¿è¡Œ 'sync_issues.py sync' æ¥åŒæ­¥æ‰€æœ‰æ›´æ”¹")
        print("ğŸ’¡ è¿è¡Œ 'sync_issues.py sync <issue_number>' æ¥åŒæ­¥å•ä¸ªissue")

    def detect_basic_changes(self):
        """æ£€æµ‹åŸºæœ¬å±æ€§æ›´æ”¹ (assignee, labels, title, body, milestone)"""
        changes = []

        # ä½¿ç”¨æ–°æ¶æ„ï¼šè¯»å–dataç›®å½•ä¸‹çš„JSONæ–‡ä»¶
        data_dir = self.workspace_dir / "data"
        if not data_dir.exists():
            print("âŒ dataç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½issuesæ•°æ®")
            return changes

        files = list(data_dir.glob("issue_*.json"))
        print(f"ğŸ” scanning {len(files)} JSON files for basic changes...")

        for i, f in enumerate(files):
            if i % 50 == 0:
                print(f"ğŸ” scanning files... progress: {i}/{len(files)}")

            try:
                # ä½¿ç”¨æ•°æ®ç®¡ç†å™¨è¯»å–issue
                issue_number = int(f.stem.split("_")[1])
                local_data = self.data_manager.get_issue(issue_number)
                if not local_data:
                    continue

                # è·å–è¿œç«¯æ•°æ®
                remote_data = self._get_remote_issue(issue_number)
                if not remote_data:
                    continue

                # æ¯”è¾ƒå¹¶æ£€æµ‹æ›´æ”¹
                changes_detected = self._compare_basic_attributes_json(
                    local_data, remote_data, issue_number, str(f)
                )
                changes.extend(changes_detected)

            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {f} æ—¶å‡ºé”™: {e}")
                continue

        return changes

    def check_outdated_timestamps(self, limit=50, recent_only=False):
        """è¶…å¿«é€Ÿæ£€æŸ¥ï¼šåªæ¯”è¾ƒæ—¶é—´æˆ³ï¼Œä¸è°ƒç”¨GitHub APIè·å–è¯¦ç»†æ•°æ®"""
        from datetime import datetime, timedelta

        outdated_issues = []

        # ä½¿ç”¨æ–°æ¶æ„ï¼šè¯»å–dataç›®å½•ä¸‹çš„JSONæ–‡ä»¶
        data_dir = self.workspace_dir / "data"
        if not data_dir.exists():
            print("âŒ dataç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½issuesæ•°æ®")
            return outdated_issues

        files = list(data_dir.glob("issue_*.json"))

        # å¦‚æœåªæ£€æŸ¥æœ€è¿‘æ›´æ–°çš„issues
        if recent_only:
            cutoff_date = datetime.now() - timedelta(days=7)
            filtered_files = []

            for f in files:
                try:
                    issue_data = self.data_manager.get_issue(int(f.stem.split("_")[1]))
                    if issue_data:
                        updated_str = issue_data["metadata"].get("updated_at", "")
                        if updated_str:
                            updated_date = datetime.fromisoformat(
                                updated_str.replace("Z", "+00:00")
                            )
                            if updated_date.replace(tzinfo=None) > cutoff_date:
                                filtered_files.append(f)
                except Exception:
                    continue

            files = filtered_files
            print(f"ğŸ” è¿‡æ»¤åˆ°æœ€è¿‘7å¤©æ›´æ–°çš„issues: {len(files)} ä¸ª")

        # é™åˆ¶æ£€æŸ¥æ•°é‡
        files = files[:limit]
        print(f"ğŸ” æ£€æŸ¥ {len(files)} ä¸ªJSONæ–‡ä»¶çš„æ—¶é—´æˆ³...")

        for i, f in enumerate(files):
            if i % 10 == 0:
                print(f"ğŸ” è¿›åº¦: {i + 1}/{len(files)}")

            try:
                # è¯»å–æœ¬åœ°æ•°æ®
                issue_number = int(f.stem.split("_")[1])
                local_data = self.data_manager.get_issue(issue_number)
                if not local_data:
                    continue

                # è·å–æœ¬åœ°è®°å½•çš„GitHubæ›´æ–°æ—¶é—´
                local_github_time = local_data["metadata"].get("updated_at", "")
                local_sync_time = local_data["tracking"].get("last_synced", "")

                if not local_github_time:
                    continue

                # ç®€å•çš„å¯å‘å¼æ£€æŸ¥ï¼šå¦‚æœæœ¬åœ°æœ‰æœªåŒæ­¥çš„ä¿®æ”¹æ—¶é—´æ™šäºGitHubæ—¶é—´ï¼Œå¯èƒ½éœ€è¦åŒæ­¥
                try:
                    github_time = datetime.fromisoformat(
                        local_github_time.replace("Z", "+00:00")
                    )
                    sync_time = (
                        datetime.fromisoformat(local_sync_time)
                        if local_sync_time
                        else github_time
                    )

                    # å¦‚æœåŒæ­¥æ—¶é—´æ—©äºGitHubæ—¶é—´ï¼Œè¯´æ˜GitHubä¸Šæœ‰æ–°çš„æ›´æ–°
                    if sync_time < github_time:
                        outdated_issues.append(
                            {
                                "number": issue_number,
                                "local_time": sync_time.strftime("%Y-%m-%d %H:%M:%S"),
                                "github_time": github_time.strftime(
                                    "%Y-%m-%d %H:%M:%S"
                                ),
                            }
                        )

                except Exception as e:
                    continue

            except Exception as e:
                continue

        return outdated_issues

    def detect_project_changes(self):
        """æ£€æµ‹é¡¹ç›®æ¿æ›´æ”¹"""
        changes = []

        # ä½¿ç”¨æ–°æ¶æ„ï¼šè¯»å–dataç›®å½•ä¸‹çš„JSONæ–‡ä»¶
        data_dir = self.workspace_dir / "data"
        if not data_dir.exists():
            print("âŒ dataç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½issuesæ•°æ®")
            return changes

        files = list(data_dir.glob("issue_*.json"))
        print(f"ğŸ” scanning {len(files)} JSON files for project changes...")

        # æ‰¹é‡è·å–æ‰€æœ‰é¡¹ç›®æ•°æ®ï¼Œé¿å…é‡å¤APIè°ƒç”¨
        print("ğŸ“¥ é¢„åŠ è½½é¡¹ç›®æ¿æ•°æ®...")
        project_items_cache = {}
        for project_num in [
            6,
            12,
            13,
            14,
        ]:  # intellistream, sage-kernel, sage-middleware, sage-apps
            try:
                items = self.project_manager.get_project_items(project_num)
                if items:
                    project_items_cache[project_num] = items
                    print(f"  âœ… é¡¹ç›®#{project_num}: {len(items)} ä¸ªitems")
                else:
                    project_items_cache[project_num] = []
            except Exception as e:
                print(f"  âš ï¸ è·å–é¡¹ç›®#{project_num}æ•°æ®å¤±è´¥: {e}")
                project_items_cache[project_num] = []

        for i, f in enumerate(files):
            if i % 50 == 0:
                print(f"ğŸ” scanning files... progress: {i}/{len(files)}")

            try:
                # ä½¿ç”¨æ•°æ®ç®¡ç†å™¨è¯»å–issue
                issue_number = int(f.stem.split("_")[1])
                local_data = self.data_manager.get_issue(issue_number)
                if not local_data:
                    continue

                # ä»JSONæ•°æ®ä¸­è·å–é¡¹ç›®ä¿¡æ¯
                local_projects = local_data.get("metadata", {}).get("projects", [])
                if local_projects:
                    # å–ç¬¬ä¸€ä¸ªé¡¹ç›®çš„teamä¿¡æ¯
                    local_project_team = local_projects[0].get("team")

                    if local_project_team:
                        # ä½¿ç”¨ç¼“å­˜æ•°æ®æ£€æŸ¥issueå½“å‰æ‰€åœ¨çš„é¡¹ç›®
                        current_projects = self._get_issue_current_projects_from_cache(
                            issue_number, project_items_cache
                        )

                        expected_project_num = self.team_to_project.get(
                            local_project_team
                        )
                        if (
                            expected_project_num
                            and expected_project_num not in current_projects
                        ):
                            changes.append(
                                {
                                    "type": "project",
                                    "description": f"Issue #{issue_number} - ç§»åŠ¨åˆ°é¡¹ç›® {local_project_team}",
                                    "issue_number": issue_number,
                                    "current_projects": current_projects,
                                    "target_project": local_project_team,
                                    "target_project_number": expected_project_num,
                                    "file": str(f),
                                }
                            )

            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {f} æ—¶å‡ºé”™: {e}")
                continue

        return changes

    def _extract_original_body(self, text, include_update_history=None):
        """
        Extracts the main body content from a local issue file, with optional inclusion of the update history section.

        This method processes the issue file text, skipping metadata and extracting the main body content.
        The extraction logic handles several edge cases:
        - Skips metadata and title at the top of the file to find the start of the body.
        - If `include_update_history` is True, extraction stops at the first separator line (`---`), or at lines starting with
          "**GitHubé“¾æ¥**:" or "**ä¸‹è½½æ—¶é—´**:".
        - If `include_update_history` is False, extraction also stops at the "## æ›´æ–°è®°å½•" section in addition to the above markers.
        - Trailing empty lines are removed from the extracted body.

        Args:
            text (str): The full content of the issue file.
            include_update_history (bool or None): Whether to include the update history section. If None, uses the config setting.

        Returns:
            str: The extracted body content.
        """
        if include_update_history is None:
            include_update_history = self.config.sync_update_history

        lines = text.splitlines()

        # è·³è¿‡å…ƒæ•°æ®éƒ¨åˆ†ï¼Œä»ç¬¬ä¸€ä¸ªéå…ƒæ•°æ®å†…å®¹å¼€å§‹æå–
        content_start = -1

        # æŸ¥æ‰¾å†…å®¹å¼€å§‹ä½ç½®ï¼Œè·³è¿‡æ ‡é¢˜å’Œå…ƒæ•°æ®éƒ¨åˆ†
        for i, line in enumerate(lines):
            stripped = line.strip()

            # è·³è¿‡æ ‡é¢˜è¡Œï¼ˆä»¥ # å¼€å¤´ï¼‰
            if stripped.startswith("# "):
                continue

            # è·³è¿‡å…ƒæ•°æ®éƒ¨åˆ†ï¼ˆIssue #, çŠ¶æ€, åˆ›å»ºæ—¶é—´ç­‰ï¼‰
            if (
                stripped.startswith("**Issue #**:")
                or stripped.startswith("**çŠ¶æ€**:")
                or stripped.startswith("**åˆ›å»ºæ—¶é—´**:")
                or stripped.startswith("**æ›´æ–°æ—¶é—´**:")
                or stripped.startswith("**åˆ›å»ºè€…**:")
            ):
                continue

            # è·³è¿‡Projectå½’å±ã€æ ‡ç­¾ã€åˆ†é…ç»™ç­‰sectionæ ‡é¢˜å’Œå†…å®¹ï¼Œä»¥åŠæˆ‘ä»¬æ·»åŠ çš„"## æè¿°"æ ‡é¢˜
            if (
                stripped in ["## Projectå½’å±", "## æ ‡ç­¾", "## åˆ†é…ç»™", "## æè¿°"]
                or stripped.startswith("- **")
                or (
                    stripped
                    and not stripped.startswith("##")
                    and i > 0
                    and lines[i - 1].strip()
                    in ["## Projectå½’å±", "## æ ‡ç­¾", "## åˆ†é…ç»™"]
                )
            ):
                continue

            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéå…ƒæ•°æ®çš„å†…å®¹è¡Œ
            if stripped and not stripped.startswith("**"):
                content_start = i
                break

        if content_start == -1:
            return ""

        # æå–å†…å®¹
        body_lines = []
        for i in range(content_start, len(lines)):
            line = lines[i]
            stripped = line.strip()

            # åœæ­¢æ¡ä»¶çš„åˆ¤æ–­
            if include_update_history:
                # å¦‚æœè¦åŒ…å«æ›´æ–°è®°å½•ï¼Œåªåœ¨é‡åˆ°åˆ†éš”çº¿æˆ–GitHubé“¾æ¥æ—¶åœæ­¢
                if (
                    stripped == "---"
                    or stripped.startswith("**GitHubé“¾æ¥**:")
                    or stripped.startswith("**ä¸‹è½½æ—¶é—´**:")
                ):
                    break
            else:
                # å¦‚æœä¸åŒ…å«æ›´æ–°è®°å½•ï¼Œé‡åˆ°æ›´æ–°è®°å½•éƒ¨åˆ†ä¹Ÿè¦åœæ­¢
                if (
                    stripped == "## æ›´æ–°è®°å½•"
                    or stripped == "---"
                    or stripped.startswith("**GitHubé“¾æ¥**:")
                    or stripped.startswith("**ä¸‹è½½æ—¶é—´**:")
                ):
                    break

            body_lines.append(line)

        # å»é™¤æœ«å°¾çš„ç©ºè¡Œ
        while body_lines and not body_lines[-1].strip():
            body_lines.pop()

        return "\n".join(body_lines)

    def _parse_local_issue(self, text):
        """è§£ææœ¬åœ°issueæ–‡ä»¶çš„æ‰€æœ‰å±æ€§"""
        data = {
            "title": None,
            "body": self._extract_original_body(
                text, include_update_history=False
            ),  # è§£æå…ƒæ•°æ®æ—¶ä¸åŒ…å«æ›´æ–°è®°å½•
            "labels": [],
            "assignee": None,
            "milestone": None,
            "project": None,
        }

        lines = text.splitlines()

        # è§£ææ ‡é¢˜
        for line in lines:
            if line.strip().startswith("# "):
                data["title"] = line.strip().lstrip("# ").strip()
                break

        # è§£æå„ä¸ªsection
        current_section = None
        for i, line in enumerate(lines):
            line = line.strip()

            if line.startswith("## "):
                current_section = line[3:].strip()
                continue

            if current_section == "æ ‡ç­¾" and line and not line.startswith("##"):
                # å¤„ç†æ ‡ç­¾
                for part in line.split(","):
                    label = part.strip()
                    if label:
                        data["labels"].append(label)

            elif (
                current_section == "åˆ†é…ç»™"
                and line
                and not line.startswith("##")
                and line != "æœªåˆ†é…"
            ):
                data["assignee"] = line

            elif (
                current_section == "Projectå½’å±"
                and line.startswith("- **")
                and "**" in line
            ):
                # æ ¼å¼: - **sage-apps** (Project Board ID: 14: SAGE-Apps)
                team_match = re.search(r"\*\*(.+?)\*\*", line)
                if team_match:
                    data["project"] = team_match.group(1)

        return data

    def _parse_local_project(self, text):
        """å•ç‹¬è§£æé¡¹ç›®å½’å±"""
        lines = text.splitlines()

        for i, line in enumerate(lines):
            if line.strip() == "## Projectå½’å±":
                # æŸ¥æ‰¾ä¸‹ä¸€è¡Œçš„é¡¹ç›®ä¿¡æ¯
                for j in range(i + 1, min(i + 5, len(lines))):
                    l_strip = lines[j].strip()
                    if l_strip.startswith("- **") and "**" in l_strip:
                        team_match = re.search(r"\*\*(.+?)\*\*", l_strip)
                        if team_match:
                            return team_match.group(1)
                break

        return None

    def _get_remote_issue(self, issue_number):
        """è·å–è¿œç«¯issueæ•°æ®"""
        url = f"https://api.github.com/repos/{self.config.GITHUB_OWNER}/{self.config.GITHUB_REPO}/issues/{issue_number}"
        try:
            resp = self.github_client.session.get(url, timeout=20)
            if resp.status_code == 200:
                return resp.json()
        except Exception:
            pass
        return None

    def _get_issue_current_projects(self, issue_number):
        """è·å–issueå½“å‰æ‰€åœ¨çš„é¡¹ç›®æ¿"""
        current_projects = []

        # æ£€æŸ¥æ‰€æœ‰ç›¸å…³é¡¹ç›®æ¿
        projects_to_check = [
            6,
            12,
            13,
            14,
        ]  # intellistream, sage-kernel, sage-middleware, sage-apps

        for project_num in projects_to_check:
            try:
                items = self.project_manager.get_project_items(project_num)
                if items:
                    # æ£€æŸ¥è¿™ä¸ªissueæ˜¯å¦åœ¨å½“å‰é¡¹ç›®ä¸­
                    for item in items:
                        content = item.get("content", {})
                        if content.get("number") == issue_number:
                            current_projects.append(project_num)
                            break
            except Exception as e:
                print(f"âš ï¸ æ£€æŸ¥é¡¹ç›®#{project_num}æ—¶å‡ºé”™: {e}")

        return current_projects

    def _get_issue_current_projects_from_cache(self, issue_number, project_items_cache):
        """ä»ç¼“å­˜æ•°æ®ä¸­è·å–issueå½“å‰æ‰€åœ¨çš„é¡¹ç›®æ¿"""
        current_projects = []

        for project_num, items in project_items_cache.items():
            for item in items:
                content = item.get("content", {})
                if content.get("number") == issue_number:
                    current_projects.append(project_num)
                    break

        return current_projects

    def _compare_basic_attributes(
        self, local_data, remote_data, issue_number, file_path
    ):
        """æ¯”è¾ƒåŸºæœ¬å±æ€§å¹¶ç”Ÿæˆæ›´æ”¹åˆ—è¡¨"""
        changes = []

        # è·å–è¿œç«¯æ•°æ®
        remote_title = remote_data.get("title", "")
        remote_body = remote_data.get("body", "")
        remote_labels = [label.get("name") for label in remote_data.get("labels", [])]
        remote_assignee = None
        if remote_data.get("assignee"):
            remote_assignee = remote_data["assignee"]["login"]
        remote_milestone = None
        if remote_data.get("milestone"):
            remote_milestone = remote_data["milestone"]["title"]

        # æ¯”è¾ƒå„ä¸ªå±æ€§
        changed_attrs = []

        if local_data["title"] and local_data["title"] != remote_title:
            changed_attrs.append("æ ‡é¢˜")

        if local_data["body"] and local_data["body"] != remote_body:
            changed_attrs.append("å†…å®¹")

        if set(local_data["labels"]) != set(remote_labels):
            changed_attrs.append("æ ‡ç­¾")

        if local_data["assignee"] != remote_assignee:
            changed_attrs.append("åˆ†é…ç»™")

        if local_data["milestone"] != remote_milestone:
            changed_attrs.append("é‡Œç¨‹ç¢‘")

        if changed_attrs:
            changes.append(
                {
                    "type": "basic",
                    "description": f"Issue #{issue_number} - æ›´æ–°{'/'.join(changed_attrs)}",
                    "issue_number": issue_number,
                    "file": file_path,
                    "local_data": local_data,
                    "remote_data": {
                        "title": remote_title,
                        "body": remote_body,
                        "labels": remote_labels,
                        "assignee": remote_assignee,
                        "milestone": remote_milestone,
                    },
                    "remote_updated_at": remote_data.get("updated_at"),
                    "changed_attributes": changed_attrs,
                }
            )

        return changes

    def _compare_basic_attributes_json(
        self, local_data, remote_data, issue_number, file_path
    ):
        """æ¯”è¾ƒåŸºæœ¬å±æ€§å¹¶ç”Ÿæˆæ›´æ”¹åˆ—è¡¨ - JSONæ ¼å¼ç‰ˆæœ¬"""
        changes = []

        # ä»JSONæ•°æ®ä¸­æå–ä¿¡æ¯
        local_metadata = local_data.get("metadata", {})
        local_content = local_data.get("content", {})

        local_title = local_metadata.get("title", "")
        local_body = local_content.get("body", "")
        local_labels = local_metadata.get("labels", [])
        local_assignees = local_metadata.get("assignees", [])
        local_assignee = local_assignees[0] if local_assignees else None
        local_milestone = local_metadata.get("milestone", {})
        local_milestone_title = (
            local_milestone.get("title") if local_milestone else None
        )

        # è·å–è¿œç«¯æ•°æ®
        remote_title = remote_data.get("title", "")
        remote_body = remote_data.get("body", "")
        remote_labels = [label.get("name") for label in remote_data.get("labels", [])]
        remote_assignee = None
        if remote_data.get("assignee"):
            remote_assignee = remote_data["assignee"]["login"]
        remote_milestone = None
        if remote_data.get("milestone"):
            remote_milestone = remote_data["milestone"]["title"]

        # æ¯”è¾ƒå„ä¸ªå±æ€§
        changed_attrs = []

        if local_title and local_title != remote_title:
            changed_attrs.append("æ ‡é¢˜")

        if local_body and local_body != remote_body:
            changed_attrs.append("å†…å®¹")

        if set(local_labels) != set(remote_labels):
            changed_attrs.append("æ ‡ç­¾")

        if local_assignee != remote_assignee:
            changed_attrs.append("åˆ†é…ç»™")

        if local_milestone_title != remote_milestone:
            changed_attrs.append("é‡Œç¨‹ç¢‘")

        if changed_attrs:
            changes.append(
                {
                    "type": "basic",
                    "description": f"Issue #{issue_number} - æ›´æ–°{'/'.join(changed_attrs)}",
                    "issue_number": issue_number,
                    "file": file_path,
                    "local_data": {
                        "title": local_title,
                        "body": local_body,
                        "labels": local_labels,
                        "assignee": local_assignee,
                        "milestone": local_milestone_title,
                    },
                    "remote_data": {
                        "title": remote_title,
                        "body": remote_body,
                        "labels": remote_labels,
                        "assignee": remote_assignee,
                        "milestone": remote_milestone,
                    },
                    "remote_updated_at": remote_data.get("updated_at"),
                    "changed_attributes": changed_attrs,
                }
            )

        return changes

    def sync_label_changes(self):
        label_changes = self.detect_label_changes()
        if not label_changes:
            print("âœ… æ²¡æœ‰æ£€æµ‹åˆ°æ ‡ç­¾æ›´æ”¹")
            return True
        return self.execute_sync(label_changes)

    def sync_status_changes(self):
        status_changes = self.detect_status_changes()
        if not status_changes:
            print("âœ… æ²¡æœ‰æ£€æµ‹åˆ°çŠ¶æ€æ›´æ”¹")
            return True
        return self.execute_sync(status_changes)

    def preview_changes(self):
        all_changes = self.detect_all_changes()
        if not all_changes:
            print("âœ… æ²¡æœ‰æ£€æµ‹åˆ°éœ€è¦åŒæ­¥çš„æ›´æ”¹")
            return True

        print(f"\nâš¡ æ£€æµ‹åˆ° {len(all_changes)} ä¸ªå¾…åŒæ­¥æ›´æ”¹:\n")
        for change in all_changes:
            print(f" - [{change['type']}] {change['description']}")

        report_file = (
            self.output_dir
            / f"sync_preview_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        )
        self.save_preview_report(all_changes, report_file)
        print(f"ğŸ“„ è¯¦ç»†é¢„è§ˆæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        return True

    def find_latest_plan(self):
        plans = sorted(self.output_dir.glob("project_move_plan_*.json"), reverse=True)
        if plans:
            return plans[0]
        return None

    def load_plan(self, path=None):
        if path:
            p = Path(path)
            print(f"ğŸ” ä½¿ç”¨æŒ‡å®šçš„è®¡åˆ’æ–‡ä»¶: {p}")
        else:
            p = self.find_latest_plan()
            if p:
                print(f"ğŸ” ä½¿ç”¨æœ€æ–°çš„è®¡åˆ’æ–‡ä»¶: {p}")
            else:
                print("ğŸ” æœªæ‰¾åˆ°ä»»ä½•è®¡åˆ’æ–‡ä»¶")
        if not p or not p.exists():
            print("âŒ æœªæ‰¾åˆ° plan æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ helpers/fix_misplaced_issues.py")
            return []
        try:
            data = json.loads(p.read_text(encoding="utf-8"))
            print(f"âœ… å·²åŠ è½½è®¡åˆ’: {p.name}ï¼Œ{len(data)} é¡¹")
            return data
        except Exception as e:
            print(f"âŒ è§£æ plan å¤±è´¥: {e}")
            return []

    def preview_plan(self, plan):
        if not plan:
            print("âœ… è®¡åˆ’ä¸ºç©º")
            return True
        print(f"\nğŸ” è®¡åˆ’é¢„è§ˆ ({len(plan)} é¡¹):")
        for i, act in enumerate(plan, 1):
            print(
                f" [{i}/{len(plan)}] #{act.get('issue_number')} -> project {act.get('to_project')} ({act.get('to_project_number')}) staged={act.get('staged')}"
            )
        return True

    def apply_plan(self, plan, dry_run=True, batch_size=5):
        session = self.github_client.session
        logs = []
        total = len(plan)
        for idx, act in enumerate(plan, 1):
            issue_number = act.get("issue_number")
            issue_node_id = act.get("issue_node_id")
            item_id = act.get("item_id")
            project_id = act.get("to_project_id")
            project_number = act.get("to_project_number")
            entry = {"issue_number": issue_number, "project_number": project_number}
            print(
                f"[{idx}/{total}] å¤„ç† Issue #{issue_number} -> project #{project_number}"
            )

            # Idempotency check: does project already contain this contentId?
            q_check = """query($projectId: ID!) { node(id: $projectId) { ... on ProjectV2 { items(first:100) { nodes { content { __typename ... on Issue { id } } } pageInfo { hasNextPage endCursor } } } } }"""
            ok, resp = graphql_request(
                session, q_check, {"projectId": project_id}, retries=1
            )
            already = False
            if ok:
                nodes = (
                    resp.get("data", {})
                    .get("node", {})
                    .get("items", {})
                    .get("nodes", [])
                )
                for n in nodes:
                    c = n.get("content") or {}
                    if c.get("id") == issue_node_id:
                        already = True
                        break

            if already:
                print("  â­ï¸ ç›®æ ‡ project å·²åŒ…å«æ­¤ issueï¼Œè·³è¿‡ add")
                entry["added"] = False
            else:
                if dry_run:
                    print(
                        f"  [dry-run] ä¼šæ‰§è¡Œ addProjectV2ItemById(projectId={project_id}, contentId={issue_node_id})"
                    )
                    entry["added"] = "dry-run"
                else:
                    mut = """mutation($projectId: ID!, $contentId: ID!) { addProjectV2ItemById(input:{projectId:$projectId, contentId:$contentId}) { item { id } } }"""
                    ok2, resp2 = graphql_request(
                        session,
                        mut,
                        {"projectId": project_id, "contentId": issue_node_id},
                        retries=2,
                    )
                    if not ok2 or "errors" in (resp2 or {}):
                        print(f"  âŒ add å¤±è´¥: {resp2}")
                        entry["added"] = False
                        entry["add_response"] = resp2
                    else:
                        print("  âœ… å·²æ·»åŠ åˆ°ç›®æ ‡ project")
                        entry["added"] = True
                        entry["add_response"] = resp2

            # If we added (or existed), we should remove the original org project item
            if dry_run:
                print(f"  [dry-run] ä¼šæ‰§è¡Œ deleteProjectV2Item(itemId={item_id})")
                entry["deleted"] = "dry-run"
            else:
                # GitHub API now requires both projectId and itemId for deleteProjectV2Item
                from_project_id = act.get("from_project_id")
                if not from_project_id:
                    print("  âŒ ç¼ºå°‘ from_project_idï¼Œæ— æ³•åˆ é™¤åŸé¡¹ç›®ä¸­çš„ item")
                    entry["deleted"] = False
                    entry["delete_response"] = {"error": "missing from_project_id"}
                else:
                    mut_del = """mutation($projectId: ID!, $itemId: ID!) { deleteProjectV2Item(input: {projectId: $projectId, itemId: $itemId}) { deletedItemId } }"""
                    ok3, resp3 = graphql_request(
                        session,
                        mut_del,
                        {"projectId": from_project_id, "itemId": item_id},
                        retries=2,
                    )
                    if not ok3 or "errors" in (resp3 or {}):
                        print(f"  âŒ delete å¤±è´¥: {resp3}")
                        entry["deleted"] = False
                        entry["delete_response"] = resp3
                    else:
                        print("  âœ… å·²ä»åŸç»„ç»‡ project åˆ é™¤ item")
                        entry["deleted"] = True
                        entry["delete_response"] = resp3

            logs.append(entry)
            # gentle rate limiting
            time.sleep(0.5)

        # write log
        log_path = self.output_dir / f"project_move_log_{int(time.time())}.json"
        log_path.write_text(
            json.dumps(logs, ensure_ascii=False, indent=2), encoding="utf-8"
        )
        print(f"\nğŸ“ æ—¥å¿—å·²å†™å…¥: {log_path}")
        return logs

    def log_sync_operation(self, changes, success, sync_type="all"):
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "sync_type": sync_type,
            "changes_count": len(changes),
            "success": success,
            "changes": changes,
        }
        log_file = (
            self.output_dir / f"sync_log_{datetime.now().strftime('%Y%m%d')}.json"
        )
        logs = []
        if log_file.exists():
            try:
                logs = json.loads(log_file.read_text(encoding="utf-8"))
            except Exception:
                logs = []
        logs.append(log_entry)
        log_file.write_text(
            json.dumps(logs, ensure_ascii=False, indent=2), encoding="utf-8"
        )

    def save_preview_report(self, changes, report_file):
        content = f"""# IssuesåŒæ­¥é¢„è§ˆæŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**å¾…åŒæ­¥æ›´æ”¹æ€»æ•°**: {len(changes)}

## æ›´æ”¹è¯¦æƒ…

"""
        for i, change in enumerate(changes, 1):
            content += f"### {i}. {change['type'].upper()} æ›´æ”¹\n- **æè¿°**: {change['description']}\n\n"
        content += "\n---\n*æ­¤æŠ¥å‘Šç”±SAGE Issuesç®¡ç†å·¥å…·ç”Ÿæˆ*\n"
        report_file.write_text(content, encoding="utf-8")


def main():
    parser = argparse.ArgumentParser(description="ç»Ÿä¸€çš„IssuesåŒæ­¥å·¥å…·")

    # æ·»åŠ æ–°çš„ç»Ÿä¸€å‘½ä»¤
    parser.add_argument(
        "command",
        nargs="?",
        choices=["sync", "status", "preview", "quick-preview", "timestamp-check"],
        help="æ“ä½œå‘½ä»¤: sync (åŒæ­¥), status (çŠ¶æ€), preview (é¢„è§ˆ), quick-preview (å¿«é€Ÿé¢„è§ˆ), timestamp-check (æ—¶é—´æˆ³æ£€æŸ¥)",
    )
    parser.add_argument(
        "issue_number",
        nargs="?",
        type=int,
        help="è¦åŒæ­¥çš„ç‰¹å®šissueç¼–å· (ä¸syncå‘½ä»¤ä¸€èµ·ä½¿ç”¨)",
    )

    # é¢„è§ˆä¼˜åŒ–å‚æ•°
    parser.add_argument(
        "--limit", type=int, default=50, help="é™åˆ¶æ£€æŸ¥çš„issuesæ•°é‡ (é»˜è®¤50)"
    )
    parser.add_argument(
        "--recent-only", action="store_true", help="åªæ£€æŸ¥æœ€è¿‘7å¤©æ›´æ–°çš„issues"
    )

    # é¡¹ç›®æ¿åŒæ­¥ä¼˜åŒ–å‚æ•°
    parser.add_argument(
        "--apply-projects", action="store_true", help="è‡ªåŠ¨åº”ç”¨é¡¹ç›®æ¿æ›´æ”¹è€Œä¸é¢„è§ˆ"
    )
    parser.add_argument(
        "--auto-confirm", action="store_true", help="è‡ªåŠ¨ç¡®è®¤æ‰€æœ‰æ“ä½œè€Œæ— éœ€ç”¨æˆ·è¾“å…¥"
    )

    # ä¿ç•™æ—§çš„å‘½ä»¤è¡Œé€‰é¡¹ä»¥ä¿æŒå…¼å®¹æ€§
    parser.add_argument("--all", action="store_true", help="åŒæ­¥æ‰€æœ‰æ›´æ”¹")
    parser.add_argument("--labels-only", action="store_true", help="ä»…åŒæ­¥æ ‡ç­¾æ›´æ”¹")
    parser.add_argument("--status-only", action="store_true", help="ä»…åŒæ­¥çŠ¶æ€æ›´æ”¹")
    parser.add_argument("--preview", action="store_true", help="é¢„è§ˆå¾…åŒæ­¥æ›´æ”¹")
    parser.add_argument(
        "--plan-preview",
        action="store_true",
        help="é¢„è§ˆ project_move_plan_*.json ä¸­çš„è®¡åˆ’",
    )
    parser.add_argument(
        "--apply-plan",
        action="store_true",
        help="å¯¹ plan æ‰§è¡Œè¿œç«¯å˜æ›´ï¼ˆéœ€ --confirm æ‰ä¼šçœŸæ­£ applyï¼‰",
    )
    parser.add_argument(
        "--plan-file",
        type=str,
        help="æŒ‡å®š plan æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤å–æœ€æ–°çš„ project_move_plan_*.jsonï¼‰",
    )
    parser.add_argument(
        "--confirm",
        action="store_true",
        help="ç¡®è®¤æ‰§è¡Œï¼ˆä¸ --apply-plan ä¸€èµ·ä½¿ç”¨ä»¥å®é™… applyï¼‰",
    )
    parser.add_argument(
        "--batch-size", type=int, default=5, help="æ¯æ‰¹å¤„ç†æ•°é‡ï¼ˆé»˜è®¤ 5ï¼‰"
    )
    parser.add_argument(
        "--content-preview",
        action="store_true",
        help="é¢„è§ˆæœ¬åœ° content æ›´æ”¹ï¼ˆtitle/body/labelsï¼‰",
    )
    parser.add_argument(
        "--apply-content",
        action="store_true",
        help="å¯¹æœ¬åœ° content æ›´æ”¹æ‰§è¡Œè¿œç«¯æ›´æ–°ï¼ˆéœ€ --confirm ï¼‰",
    )
    parser.add_argument(
        "--force-content", action="store_true", help="å¼ºåˆ¶è¦†ç›–è¿œç«¯ï¼ˆå¿½ç•¥è¿œç«¯æ›´æ–°æ—¶é—´ï¼‰"
    )
    parser.add_argument(
        "--content-limit",
        type=int,
        default=None,
        help="åªå¤„ç†å‰ N ä¸ª content æ›´æ”¹ï¼ˆç”¨äºè¯•ç‚¹ï¼‰",
    )

    args = parser.parse_args()

    syncer = IssuesSyncer()
    success = False

    # å¤„ç†æ–°çš„ç»Ÿä¸€å‘½ä»¤
    if args.command == "sync":
        if args.issue_number:
            # åŒæ­¥å•ä¸ªissue
            success = syncer.sync_one_issue(args.issue_number)
        else:
            # åŒæ­¥æ‰€æœ‰æ›´æ”¹ï¼Œä¼ é€’æ–°å‚æ•°
            success = syncer.sync_all_changes(
                apply_projects=args.apply_projects, auto_confirm=args.auto_confirm
            )
    elif args.command == "status":
        # æ˜¾ç¤ºåŒæ­¥çŠ¶æ€
        syncer.show_sync_status()
        success = True
    elif args.command == "preview":
        # é¢„è§ˆæ‰€æœ‰æ›´æ”¹
        changes = syncer.detect_all_changes()
        if not changes:
            print("âœ… æ²¡æœ‰æ£€æµ‹åˆ°éœ€è¦åŒæ­¥çš„æ›´æ”¹")
        else:
            print(f"ğŸ“‹ æ£€æµ‹åˆ° {len(changes)} ä¸ªå¾…åŒæ­¥æ›´æ”¹:")
            for change in changes[:50]:  # æœ€å¤šæ˜¾ç¤º50ä¸ª
                print(f"   - {change['description']}")
            if len(changes) > 50:
                print(f"   ... ä»¥åŠå…¶ä»– {len(changes) - 50} ä¸ªæ›´æ”¹")
        success = True
    elif args.command == "quick-preview":
        # å¿«é€Ÿé¢„è§ˆï¼ˆåªæ£€æŸ¥å°‘é‡issuesï¼‰
        print(f"ğŸš€ å¿«é€Ÿé¢„è§ˆæ¨¡å¼ï¼ˆæœ€å¤šæ£€æŸ¥ {args.limit} ä¸ªissuesï¼‰")
        changes = syncer.detect_changes_limited(
            limit=args.limit, recent_only=args.recent_only
        )
        if not changes:
            print("âœ… æ²¡æœ‰æ£€æµ‹åˆ°éœ€è¦åŒæ­¥çš„æ›´æ”¹")
        else:
            print(f"ğŸ“‹ æ£€æµ‹åˆ° {len(changes)} ä¸ªå¾…åŒæ­¥æ›´æ”¹:")
            for change in changes:
                print(f"   - {change['description']}")
        success = True
    elif args.command == "timestamp-check":
        # è¶…å¿«é€Ÿæ£€æŸ¥ï¼ˆåªæ¯”è¾ƒæ—¶é—´æˆ³ï¼‰
        print(f"âš¡ è¶…å¿«é€Ÿæ—¶é—´æˆ³æ£€æŸ¥ï¼ˆæœ€å¤šæ£€æŸ¥ {args.limit} ä¸ªissuesï¼‰")
        outdated_issues = syncer.check_outdated_timestamps(
            limit=args.limit, recent_only=args.recent_only
        )
        if not outdated_issues:
            print("âœ… æ‰€æœ‰issuesçš„æ—¶é—´æˆ³éƒ½æ˜¯æœ€æ–°çš„")
        else:
            print(f"âš ï¸ å‘ç° {len(outdated_issues)} ä¸ªå¯èƒ½éœ€è¦åŒæ­¥çš„issues:")
            for issue_info in outdated_issues:
                print(
                    f"   - Issue #{issue_info['number']}: æœ¬åœ°={issue_info['local_time']}, GitHub={issue_info['github_time']}"
                )
        success = True
    # å¤„ç†æ—§çš„å‘½ä»¤è¡Œé€‰é¡¹ (ä¿æŒå…¼å®¹æ€§)
    elif args.all:
        success = syncer.sync_all_changes(
            apply_projects=args.apply_projects, auto_confirm=args.auto_confirm
        )
    elif args.labels_only:
        success = syncer.sync_label_changes()
    elif args.status_only:
        success = syncer.sync_status_changes()
    elif args.preview:
        success = syncer.preview_changes()
    elif args.plan_preview:
        plan = syncer.load_plan(args.plan_file)
        success = syncer.preview_plan(plan)
    elif args.apply_plan:
        plan = syncer.load_plan(args.plan_file)
        if not plan:
            sys.exit(1)
        dry = not args.confirm
        print(f"ğŸ”” apply_plan dry_run={dry} batch_size={args.batch_size}")
        syncer.apply_plan(plan, dry_run=dry, batch_size=args.batch_size)
        success = True
    elif args.content_preview:
        changes = syncer.detect_content_changes(limit=args.content_limit)
        if not changes:
            print("âœ… æœªæ£€æµ‹åˆ°å†…å®¹å·®å¼‚")
        else:
            p = syncer.save_content_plan(changes)
            print(f"é¢„è§ˆ {len(changes)} é¡¹å†…å®¹å·®å¼‚ï¼Œè®¡åˆ’å·²ä¿å­˜: {p}")
        success = True
    elif args.apply_content:
        changes = syncer.detect_content_changes(limit=args.content_limit)
        if not changes:
            print("âœ… æœªæ£€æµ‹åˆ°å†…å®¹å·®å¼‚")
            sys.exit(0)
        plan_path = syncer.save_content_plan(changes)
        dry = not args.confirm
        syncer.apply_content_plan(
            changes, dry_run=dry, force=args.force_content, limit=args.content_limit
        )
        success = True
    else:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•å‘½ä»¤ï¼Œæ˜¾ç¤ºå¸®åŠ©å’ŒçŠ¶æ€
        print("ğŸ”§ ç»Ÿä¸€çš„IssuesåŒæ­¥å·¥å…·")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  python sync_issues.py sync           # åŒæ­¥æ‰€æœ‰æ›´æ”¹")
        print("  python sync_issues.py sync 123       # åŒæ­¥issue #123")
        print("  python sync_issues.py status         # æ˜¾ç¤ºåŒæ­¥çŠ¶æ€")
        print("  python sync_issues.py preview        # é¢„è§ˆå¾…åŒæ­¥æ›´æ”¹")
        print()
        syncer.show_sync_status()
        success = True

    if success:
        if args.command in ["sync", "status", "preview"] or not args.command:
            pass  # ä¸æ˜¾ç¤ºé¢å¤–æ¶ˆæ¯
        else:
            print("ğŸ‰ æ“ä½œå®Œæˆï¼")
    else:
        print("ğŸ’¥ æ“ä½œå¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    main()
