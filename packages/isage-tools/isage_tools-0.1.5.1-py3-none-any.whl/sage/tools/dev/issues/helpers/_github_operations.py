#!/usr/bin/env python3
"""
GitHub Issuesæ“ä½œæ‰§è¡Œè„šæœ¬
åŸºäºAIåˆ†æç»“æœæ‰§è¡ŒGitHubæ“ä½œ
"""

import sys
import time
from pathlib import Path

import requests


class GitHubIssuesExecutor:
    def __init__(self):
        # ä½¿ç”¨IssuesConfigè·å–token
        sys.path.insert(0, str(Path(__file__).parent.parent))
        from ..config import IssuesConfig

        config = IssuesConfig()
        self.github_token = config.github_token

        if not self.github_token:
            print("âŒ è¯·è®¾ç½®GITHUB_TOKENç¯å¢ƒå˜é‡æˆ–é…ç½®IssuesConfig")
            sys.exit(1)

        self.repo = "intellistream/SAGE"
        self.headers = {
            "Authorization": f"token {self.github_token}",
            "Accept": "application/vnd.github.v3+json",
        }

        # ä½¿ç”¨ç»Ÿä¸€çš„.sage/issuesç›®å½•
        from sage.common.config.output_paths import get_sage_paths

        sage_paths = get_sage_paths()
        self.output_dir = sage_paths.issues_dir / "github_ops"
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.duplicate_groups = []
        self.label_recommendations = {}

        # åˆå§‹åŒ–æ ‡å‡†åŒ–æ ‡ç­¾ï¼ˆä¸ä¾èµ–AIåˆ†æç»“æœï¼‰
        self.init_standard_labels()

    def init_standard_labels(self):
        """åˆå§‹åŒ–æ ‡å‡†åŒ–æ ‡ç­¾ï¼ˆä¸ä¾èµ–AIåˆ†æç»“æœï¼‰"""
        # æ ‡å‡†åŒ–çš„æ ‡ç­¾æ˜ å°„
        self.standard_labels = {
            # ç±»å‹æ ‡ç­¾
            "bug": {"color": "d73a4a", "description": "Bug report"},
            "feature": {"color": "0075ca", "description": "New feature"},
            "enhancement": {
                "color": "a2eeef",
                "description": "Enhancement to existing feature",
            },
            "documentation": {"color": "0075ca", "description": "Documentation"},
            "refactor": {"color": "d4c5f9", "description": "Code refactoring"},
            "task": {"color": "e4e669", "description": "General task"},
            "algorithm": {"color": "7057ff", "description": "Algorithm related"},
            "dataset": {"color": "006b75", "description": "Dataset related"},
            "literature-review": {
                "color": "fbca04",
                "description": "Literature review",
            },
            # ä¼˜å…ˆçº§æ ‡ç­¾
            "priority:high": {"color": "d93f0b", "description": "High priority"},
            "priority:medium": {"color": "fbca04", "description": "Medium priority"},
            "priority:low": {"color": "0e8a16", "description": "Low priority"},
            # ç»„ä»¶æ ‡ç­¾
            "component:core": {"color": "5319e7", "description": "Core component"},
            "component:cli": {"color": "1d76db", "description": "CLI component"},
            "component:frontend": {
                "color": "0052cc",
                "description": "Frontend component",
            },
            "component:docs": {
                "color": "0075ca",
                "description": "Documentation component",
            },
            "component:testing": {
                "color": "c2e0c6",
                "description": "Testing component",
            },
            # åŠŸèƒ½æ ‡ç­¾
            "rag": {"color": "ff6b6b", "description": "RAG related"},
            "memory": {"color": "ffa500", "description": "Memory related"},
            "retrieval": {"color": "9932cc", "description": "Retrieval related"},
            "graph": {"color": "2e8b57", "description": "Graph related"},
            "embedding": {"color": "4682b4", "description": "Embedding related"},
            "distributed": {"color": "8b4513", "description": "Distributed system"},
            "engine": {"color": "ff4500", "description": "Engine related"},
            "operator": {"color": "dda0dd", "description": "Operator related"},
            "pipeline": {"color": "20b2aa", "description": "Pipeline related"},
            "job": {"color": "cd853f", "description": "Job related"},
            "api": {"color": "32cd32", "description": "API related"},
            "config": {"color": "ffd700", "description": "Configuration related"},
            "testing": {"color": "98fb98", "description": "Testing related"},
        }

    def load_ai_analysis_results(self):
        """åŠ è½½AIåˆ†æç»“æœï¼ˆå¯é€‰ï¼‰"""
        print("ğŸ” å¯»æ‰¾AIåˆ†æç»“æœ...")

        # æŸ¥æ‰¾æœ€æ–°çš„AIåˆ†ææ–‡ä»¶
        analysis_files = []

        # é‡å¤æ£€æµ‹åˆ†æ
        duplicate_files = list(self.output_dir.glob("duplicate_analysis_*.md"))
        if duplicate_files:
            latest_duplicate = max(duplicate_files, key=lambda x: x.stat().st_mtime)
            analysis_files.append(("é‡å¤æ£€æµ‹", latest_duplicate))

        # æ ‡ç­¾ä¼˜åŒ–åˆ†æ
        label_files = list(self.output_dir.glob("label_analysis_*.md"))
        if label_files:
            latest_label = max(label_files, key=lambda x: x.stat().st_mtime)
            analysis_files.append(("æ ‡ç­¾ä¼˜åŒ–", latest_label))

        # ç»¼åˆç®¡ç†åˆ†æ
        management_files = list(self.output_dir.glob("comprehensive_management_*.md"))
        if management_files:
            latest_management = max(management_files, key=lambda x: x.stat().st_mtime)
            analysis_files.append(("ç»¼åˆç®¡ç†", latest_management))

        if not analysis_files:
            print("âš ï¸ æœªæ‰¾åˆ°AIåˆ†æç»“æœæ–‡ä»¶ï¼Œä»…æ”¯æŒæ ‡ç­¾åˆ›å»ºåŠŸèƒ½")
            return

        print(f"âœ… æ‰¾åˆ° {len(analysis_files)} ä¸ªAIåˆ†ææ–‡ä»¶:")
        for analysis_type, file_path in analysis_files:
            print(f"   ğŸ“„ {analysis_type}: {file_path.name}")

        # è§£æåˆ†æç»“æœ
        self.parse_analysis_files(analysis_files)

    def parse_analysis_files(self, analysis_files):
        """è§£æAIåˆ†ææ–‡ä»¶"""
        print("\nğŸ“– è§£æAIåˆ†æç»“æœ...")

        for analysis_type, file_path in analysis_files:
            try:
                content = file_path.read_text(encoding="utf-8")

                if "é‡å¤æ£€æµ‹" in analysis_type:
                    self.parse_duplicate_analysis(content)
                elif "æ ‡ç­¾ä¼˜åŒ–" in analysis_type:
                    self.parse_label_analysis(content)
                elif "ç»¼åˆç®¡ç†" in analysis_type:
                    self.parse_management_analysis(content)

            except Exception as e:
                print(f"âŒ è§£æ {analysis_type} æ–‡ä»¶å¤±è´¥: {e}")

        print(
            f"âœ… è§£æå®Œæˆ: æ‰¾åˆ° {len(self.duplicate_groups)} ä¸ªé‡å¤ç»„, {len(self.label_recommendations)} ä¸ªæ ‡ç­¾å»ºè®®"
        )

    def parse_duplicate_analysis(self, content):
        """è§£æé‡å¤æ£€æµ‹åˆ†æç»“æœ"""
        import re

        # æŸ¥æ‰¾é‡å¤ç»„ä¿¡æ¯ - åŒ¹é… "Issue #xxx å’Œ Issue #yyy é‡å¤" è¿™æ ·çš„æ¨¡å¼
        duplicate_patterns = [
            r"Issue #(\d+) å’Œ Issue #(\d+) é‡å¤",
            r"#(\d+) å’Œ #(\d+) æ˜¯é‡å¤çš„",
            r"issues #(\d+) å’Œ #(\d+) é‡å¤",
            r"Issue (\d+) ä¸ Issue (\d+) é‡å¤",
        ]

        for pattern in duplicate_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                issue1, issue2 = int(match[0]), int(match[1])

                # æ‰¾åˆ°ç°æœ‰çš„é‡å¤ç»„æˆ–åˆ›å»ºæ–°çš„
                found_group = None
                for group in self.duplicate_groups:
                    if (
                        issue1 in [group["main"]] + group["duplicates"]
                        or issue2 in [group["main"]] + group["duplicates"]
                    ):
                        found_group = group
                        break

                if found_group:
                    # æ·»åŠ åˆ°ç°æœ‰ç»„
                    if issue1 not in [found_group["main"]] + found_group["duplicates"]:
                        found_group["duplicates"].append(issue1)
                    if issue2 not in [found_group["main"]] + found_group["duplicates"]:
                        found_group["duplicates"].append(issue2)
                else:
                    # åˆ›å»ºæ–°ç»„ï¼Œè¾ƒå°çš„å·ç ä½œä¸ºä¸»issue
                    main_issue = min(issue1, issue2)
                    duplicate_issue = max(issue1, issue2)
                    self.duplicate_groups.append(
                        {
                            "main": main_issue,
                            "duplicates": [duplicate_issue],
                            "reason": "AIæ£€æµ‹å‡ºçš„é‡å¤issues",
                        }
                    )

    def parse_label_analysis(self, content):
        """è§£ææ ‡ç­¾ä¼˜åŒ–åˆ†æç»“æœ"""
        import re

        # æŸ¥æ‰¾æ ‡ç­¾å»ºè®® - åŒ¹é… "Issue #xxx: å»ºè®®æ ‡ç­¾: tag1, tag2" è¿™æ ·çš„æ¨¡å¼
        label_patterns = [
            r"Issue #(\d+)[ï¼š:]\s*å»ºè®®æ ‡ç­¾[ï¼š:]\s*([^\n]+)",
            r"#(\d+)[ï¼š:]\s*æ ‡ç­¾å»ºè®®[ï¼š:]\s*([^\n]+)",
            r"Issue (\d+)[ï¼š:]\s*æ¨èæ ‡ç­¾[ï¼š:]\s*([^\n]+)",
        ]

        for pattern in label_patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                issue_num = int(match[0])
                labels_str = match[1].strip()

                # è§£ææ ‡ç­¾åˆ—è¡¨
                labels = [
                    label.strip() for label in labels_str.split(",") if label.strip()
                ]

                if labels:
                    self.label_recommendations[issue_num] = labels

    def parse_management_analysis(self, content):
        """è§£æç»¼åˆç®¡ç†åˆ†æç»“æœ"""
        # ç»¼åˆç®¡ç†åˆ†æå¯èƒ½åŒ…å«é‡å¤æ£€æµ‹å’Œæ ‡ç­¾å»ºè®®
        self.parse_duplicate_analysis(content)
        self.parse_label_analysis(content)

    def create_standard_labels(self):
        """åˆ›å»ºæ ‡å‡†åŒ–æ ‡ç­¾"""
        print("ğŸ·ï¸ åˆ›å»ºæ ‡å‡†åŒ–æ ‡ç­¾...")

        for label_name, label_info in self.standard_labels.items():
            self.create_or_update_label(label_name, label_info)
            time.sleep(0.1)  # é¿å…APIé™åˆ¶

    def create_or_update_label(self, name, info):
        """åˆ›å»ºæˆ–æ›´æ–°æ ‡ç­¾ï¼ˆæ™ºèƒ½åˆå¹¶ç°æœ‰æ ‡ç­¾ï¼‰"""
        url = f"https://api.github.com/repos/{self.repo}/labels/{name}"

        # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦å­˜åœ¨
        response = requests.get(url, headers=self.headers)

        data = {
            "name": name,
            "color": info["color"],
            "description": info["description"],
        }

        if response.status_code == 200:
            # æ ‡ç­¾å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
            existing_label = response.json()

            # å¦‚æœé¢œè‰²å’Œæè¿°éƒ½ç›¸åŒï¼Œè·³è¿‡æ›´æ–°
            if (
                existing_label.get("color") == info["color"]
                and existing_label.get("description") == info["description"]
            ):
                print(f"  â­ï¸ æ ‡ç­¾å·²æ˜¯æœ€æ–°: {name}")
                return

            # æ›´æ–°æ ‡ç­¾
            response = requests.patch(url, headers=self.headers, json=data)
            if response.status_code == 200:
                print(f"  âœ… æ›´æ–°æ ‡ç­¾: {name}")
            else:
                print(f"  âŒ æ›´æ–°å¤±è´¥: {name} - {response.text}")
        else:
            # åˆ›å»ºæ–°æ ‡ç­¾
            create_url = f"https://api.github.com/repos/{self.repo}/labels"
            response = requests.post(create_url, headers=self.headers, json=data)
            if response.status_code == 201:
                print(f"  âœ… åˆ›å»ºæ ‡ç­¾: {name}")
            else:
                print(f"  âŒ åˆ›å»ºå¤±è´¥: {name} - {response.text}")

    def get_issue_details(self, issue_number):
        """è·å–issueè¯¦æƒ…"""
        url = f"https://api.github.com/repos/{self.repo}/issues/{issue_number}"
        response = requests.get(url, headers=self.headers)

        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ è·å–issue #{issue_number}å¤±è´¥: {response.text}")
            return None

    def close_duplicate_issue(self, issue_number, main_issue_number, reason):
        """å…³é—­é‡å¤issue"""
        print(f"  ğŸ”„ å…³é—­é‡å¤issue #{issue_number} (åˆå¹¶åˆ° #{main_issue_number})")

        # æ·»åŠ è¯„è®ºè¯´æ˜åˆå¹¶åŸå› 
        comment_url = (
            f"https://api.github.com/repos/{self.repo}/issues/{issue_number}/comments"
        )
        comment_data = {
            "body": f"âœ¨ **Issuesåˆå¹¶é€šçŸ¥**\\n\\nè¿™ä¸ªissueä¸ #{main_issue_number} é‡å¤ï¼ŒåŸå› ï¼š{reason}\\n\\nå·²è‡ªåŠ¨åˆå¹¶åˆ°ä¸»issueä¸­ï¼Œè¯·åœ¨ #{main_issue_number} ä¸­ç»§ç»­è®¨è®ºã€‚"
        }

        comment_response = requests.post(
            comment_url, headers=self.headers, json=comment_data
        )
        if comment_response.status_code == 201:
            print("    âœ… æ·»åŠ åˆå¹¶è¯´æ˜è¯„è®º")
        else:
            print(f"    âŒ æ·»åŠ è¯„è®ºå¤±è´¥: {comment_response.text}")

        # å…³é—­issue
        url = f"https://api.github.com/repos/{self.repo}/issues/{issue_number}"
        close_data = {"state": "closed", "labels": ["duplicate"]}  # æ·»åŠ é‡å¤æ ‡ç­¾

        response = requests.patch(url, headers=self.headers, json=close_data)
        if response.status_code == 200:
            print(f"    âœ… æˆåŠŸå…³é—­issue #{issue_number}")
            return True
        else:
            print(f"    âŒ å…³é—­å¤±è´¥: {response.text}")
            return False

    def update_main_issue(self, main_issue_number, duplicates, reason):
        """æ›´æ–°ä¸»issueï¼Œæ·»åŠ åˆå¹¶ä¿¡æ¯"""
        issue = self.get_issue_details(main_issue_number)
        if not issue:
            return False

        # æ·»åŠ åˆå¹¶è¯´æ˜è¯„è®º
        duplicate_list = ", ".join([f"#{num}" for num in duplicates])
        comment_url = f"https://api.github.com/repos/{self.repo}/issues/{main_issue_number}/comments"
        comment_data = {
            "body": f"ğŸ”— **Issuesåˆå¹¶æ›´æ–°**\\n\\nä»¥ä¸‹é‡å¤issueså·²åˆå¹¶åˆ°æ­¤issueï¼š{duplicate_list}\\n\\nåˆå¹¶åŸå› ï¼š{reason}\\n\\nè¯·åœ¨æ­¤issueä¸­ç»Ÿä¸€è®¨è®ºç›¸å…³å†…å®¹ã€‚"
        }

        response = requests.post(comment_url, headers=self.headers, json=comment_data)
        if response.status_code == 201:
            print(f"    âœ… ä¸»issue #{main_issue_number} æ·»åŠ åˆå¹¶è¯´æ˜")
            return True
        else:
            print(f"    âŒ ä¸»issueæ›´æ–°å¤±è´¥: {response.text}")
            return False

    def update_issue_labels(self, issue_number, new_labels, replace=False):
        """æ™ºèƒ½æ›´æ–°issueæ ‡ç­¾ï¼ˆé»˜è®¤è¿½åŠ ï¼Œä¸æ›¿æ¢ç°æœ‰æ ‡ç­¾ï¼‰"""
        # é¦–å…ˆè·å–å½“å‰issueçš„ä¿¡æ¯
        issue = self.get_issue_details(issue_number)
        if not issue:
            return False

        # æ£€æŸ¥issueæ˜¯å¦å·²å…³é—­
        if issue.get("state") == "closed":
            print(f"  â­ï¸ è·³è¿‡å·²å…³é—­çš„issue: #{issue_number}")
            return False

        # è·å–ç°æœ‰æ ‡ç­¾
        existing_labels = [label["name"] for label in issue.get("labels", [])]

        if replace:
            # æ›¿æ¢æ¨¡å¼ï¼šå®Œå…¨æ›¿æ¢ç°æœ‰æ ‡ç­¾
            final_labels = new_labels
        else:
            # è¿½åŠ æ¨¡å¼ï¼šä¿ç•™ç°æœ‰æ ‡ç­¾ï¼Œæ·»åŠ æ–°æ ‡ç­¾
            final_labels = list(set(existing_labels + new_labels))

        # å¦‚æœæ ‡ç­¾æ²¡æœ‰å˜åŒ–ï¼Œè·³è¿‡æ›´æ–°
        if set(final_labels) == set(existing_labels):
            print(f"  â­ï¸ æ ‡ç­¾æ— éœ€æ›´æ–°: #{issue_number}")
            return True

        url = f"https://api.github.com/repos/{self.repo}/issues/{issue_number}"
        data = {"labels": final_labels}

        response = requests.patch(url, headers=self.headers, json=data)
        if response.status_code == 200:
            added_labels = set(final_labels) - set(existing_labels)
            if added_labels:
                print(f"  âœ… æ·»åŠ æ ‡ç­¾: #{issue_number} -> {', '.join(added_labels)}")
            return True
        else:
            print(f"  âŒ æ ‡ç­¾æ›´æ–°å¤±è´¥: #{issue_number} - {response.text}")
            return False

    def process_duplicates(self):
        """å¤„ç†é‡å¤issuesï¼ˆè·³è¿‡å·²å…³é—­çš„issuesï¼‰"""
        print("ğŸ”„ å¤„ç†é‡å¤issues...")

        if not self.duplicate_groups:
            print("âš ï¸ æ²¡æœ‰å‘ç°é‡å¤çš„issues")
            return

        for group in self.duplicate_groups:
            main_issue = group["main"]
            duplicates = group["duplicates"]
            reason = group["reason"]

            # æ£€æŸ¥ä¸»issueæ˜¯å¦å·²å…³é—­
            main_issue_details = self.get_issue_details(main_issue)
            if main_issue_details and main_issue_details.get("state") == "closed":
                print(f"â­ï¸ è·³è¿‡å·²å…³é—­çš„ä¸»issue #{main_issue}")
                continue

            print(f"\\nğŸ“‹ å¤„ç†é‡å¤ç»„: ä¸»issue #{main_issue}")
            print(f"   é‡å¤issues: {', '.join([f'#{num}' for num in duplicates])}")
            print(f"   åˆå¹¶åŸå› : {reason}")

            # æ£€æŸ¥é‡å¤issuesæ˜¯å¦å·²å…³é—­
            active_duplicates = []
            for duplicate in duplicates:
                duplicate_details = self.get_issue_details(duplicate)
                if duplicate_details and duplicate_details.get("state") == "open":
                    active_duplicates.append(duplicate)
                else:
                    print(f"   â­ï¸ è·³è¿‡å·²å…³é—­çš„é‡å¤issue #{duplicate}")

            if not active_duplicates:
                print("   âš ï¸ æ‰€æœ‰é‡å¤issueséƒ½å·²å…³é—­ï¼Œè·³è¿‡å¤„ç†")
                continue

            # æ›´æ–°ä¸»issue
            if self.update_main_issue(main_issue, active_duplicates, reason):
                # å…³é—­é‡å¤issues
                for duplicate in active_duplicates:
                    self.close_duplicate_issue(duplicate, main_issue, reason)
                    time.sleep(1)  # é¿å…APIé™åˆ¶

        print("\\nâœ… é‡å¤issueså¤„ç†å®Œæˆ!")

    def generate_labels_update_plan(self):
        """åŸºäºAIåˆ†æç»“æœç”Ÿæˆæ ‡ç­¾æ›´æ–°è®¡åˆ’"""
        # å¦‚æœæœ‰AIåˆ†æçš„æ ‡ç­¾å»ºè®®ï¼Œä½¿ç”¨AIåˆ†æç»“æœ
        if self.label_recommendations:
            print(
                f"ğŸ“‹ ä½¿ç”¨AIåˆ†æçš„æ ‡ç­¾å»ºè®®: {len(self.label_recommendations)} ä¸ªissues"
            )
            return self.label_recommendations

        # å¦‚æœæ²¡æœ‰AIåˆ†æç»“æœï¼Œè¿”å›ç©ºè®¡åˆ’
        print("âš ï¸ æ²¡æœ‰AIåˆ†æçš„æ ‡ç­¾å»ºè®®ï¼Œè·³è¿‡æ ‡ç­¾æ›´æ–°")
        return {}

    def update_all_labels(self):
        """åŸºäºAIåˆ†ææ‰¹é‡æ›´æ–°issuesæ ‡ç­¾"""
        print("ğŸ·ï¸ åŸºäºAIåˆ†ææ‰¹é‡æ›´æ–°issuesæ ‡ç­¾...")

        label_updates = self.generate_labels_update_plan()

        if not label_updates:
            print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„æ ‡ç­¾æ›´æ–°è®¡åˆ’")
            return

        for issue_number, labels in label_updates.items():
            print(f"\nğŸ“‹ æ›´æ–°issue #{issue_number}")
            if self.update_issue_labels(issue_number, labels, replace=False):
                time.sleep(0.5)  # é¿å…APIé™åˆ¶

        print("\nâœ… æ ‡ç­¾æ›´æ–°å®Œæˆ!")

    def generate_summary_report(self):
        """ç”Ÿæˆå¤„ç†æ€»ç»“æŠ¥å‘Š"""
        report_content = f"""# Issuesæ•´ç†å¤„ç†æŠ¥å‘Š

**å¤„ç†æ—¶é—´**: {self.get_current_time()}
**å¤„ç†èŒƒå›´**: SAGEé¡¹ç›®å¼€æ”¾issues

## ğŸ“Š å¤„ç†ç»Ÿè®¡

### ğŸ”„ é‡å¤Issueså¤„ç†
- é‡å¤ç»„æ•°é‡: {len(self.duplicate_groups)} ç»„
- åˆå¹¶çš„issuesæ•°é‡: {sum(len(group['duplicates']) for group in self.duplicate_groups)} ä¸ª
- ä¿ç•™çš„ä¸»issues: {len(self.duplicate_groups)} ä¸ª

### ğŸ·ï¸ æ ‡ç­¾ä¼˜åŒ–
- åˆ›å»ºæ ‡å‡†åŒ–æ ‡ç­¾: {len(self.standard_labels)} ä¸ª
- æ›´æ–°issuesæ ‡ç­¾: {len(self.generate_labels_update_plan())} ä¸ª

## ğŸ“‹ é‡å¤Issuesåˆå¹¶è¯¦æƒ…

"""
        for i, group in enumerate(self.duplicate_groups, 1):
            report_content += f"""### ç»„ {i}: #{group['main']}
- **ä¸»issue**: #{group['main']}
- **åˆå¹¶çš„é‡å¤issues**: {', '.join([f"#{num}" for num in group['duplicates']])}
- **åˆå¹¶åŸå› **: {group['reason']}

"""

        report_content += """## ğŸ¯ æ ‡ç­¾ä½“ç³»

### ç±»å‹æ ‡ç­¾
- `bug`: BugæŠ¥å‘Š
- `feature`: æ–°åŠŸèƒ½
- `enhancement`: åŠŸèƒ½å¢å¼º
- `documentation`: æ–‡æ¡£ç›¸å…³
- `refactor`: ä»£ç é‡æ„
- `task`: ä¸€èˆ¬ä»»åŠ¡
- `algorithm`: ç®—æ³•ç›¸å…³
- `dataset`: æ•°æ®é›†ç›¸å…³

### ä¼˜å…ˆçº§æ ‡ç­¾
- `priority:high`: é«˜ä¼˜å…ˆçº§
- `priority:medium`: ä¸­ä¼˜å…ˆçº§
- `priority:low`: ä½ä¼˜å…ˆçº§

### ç»„ä»¶æ ‡ç­¾
- `component:core`: æ ¸å¿ƒç»„ä»¶
- `component:cli`: CLIç»„ä»¶
- `component:frontend`: å‰ç«¯ç»„ä»¶
- `component:docs`: æ–‡æ¡£ç»„ä»¶
- `component:testing`: æµ‹è¯•ç»„ä»¶

### åŠŸèƒ½æ ‡ç­¾
- `rag`: RAGç›¸å…³
- `memory`: å†…å­˜ç›¸å…³
- `retrieval`: æ£€ç´¢ç›¸å…³
- `distributed`: åˆ†å¸ƒå¼ç³»ç»Ÿ
- `engine`: å¼•æ“ç›¸å…³
- `job`: ä½œä¸šç›¸å…³
- `api`: APIç›¸å…³
- `config`: é…ç½®ç›¸å…³

## âœ… å¤„ç†ç»“æœ

1. **é‡å¤Issuesåˆå¹¶**: å°†ç›¸ä¼¼å’Œé‡å¤çš„issuesåˆå¹¶åˆ°ä¸»issueä¸­ï¼Œé¿å…åˆ†æ•£è®¨è®º
2. **æ ‡ç­¾æ ‡å‡†åŒ–**: å»ºç«‹ç»Ÿä¸€çš„æ ‡ç­¾ä½“ç³»ï¼Œä¾¿äºissuesåˆ†ç±»å’ŒæŸ¥æ‰¾
3. **ä¼˜å…ˆçº§è®¾ç½®**: æ ¹æ®issuesé‡è¦æ€§è®¾ç½®ä¼˜å…ˆçº§ï¼Œä¾¿äºå¼€å‘è®¡åˆ’å®‰æ’
4. **ç»„ä»¶åˆ†ç±»**: æŒ‰ç…§é¡¹ç›®ç»„ä»¶å¯¹issuesè¿›è¡Œåˆ†ç±»ï¼Œä¾¿äºè´£ä»»åˆ†å·¥

æ‰€æœ‰å¤„ç†éƒ½å·²åŒæ­¥åˆ°GitHubä»“åº“ï¼Œå¯ä»¥åœ¨é¡¹ç›®issuesé¡µé¢æŸ¥çœ‹æ›´æ–°ç»“æœã€‚
"""

        # ç»Ÿä¸€è¾“å‡ºåˆ°.sage/issuesç›®å½•
        from sage.common.config.output_paths import get_sage_paths

        sage_paths = get_sage_paths()
        output_dir = sage_paths.issues_dir
        output_dir.mkdir(exist_ok=True)
        report_path = output_dir / "processing_report.md"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report_content)

        print(f"âœ… å¤„ç†æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path

    def get_current_time(self):
        """è·å–å½“å‰æ—¶é—´"""
        from datetime import datetime

        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def run_full_management(self):
        """è¿è¡Œå®Œæ•´çš„issuesç®¡ç†æµç¨‹ï¼ˆåŸºäºAIåˆ†æï¼‰"""
        print("ğŸš€ å¼€å§‹åŸºäºAIåˆ†æçš„GitHub Issuesç®¡ç†...")

        # åŠ è½½AIåˆ†æç»“æœ
        self.load_ai_analysis_results()

        try:
            actions_performed = []

            # 1. åˆ›å»ºæ ‡å‡†åŒ–æ ‡ç­¾ï¼ˆæ€»æ˜¯æ‰§è¡Œï¼‰
            print("\nğŸ·ï¸ åˆ›å»º/æ›´æ–°æ ‡å‡†åŒ–æ ‡ç­¾...")
            self.create_standard_labels()
            actions_performed.append("æ ‡å‡†åŒ–æ ‡ç­¾")

            # 2. å¤„ç†é‡å¤issuesï¼ˆä»…åœ¨æœ‰AIåˆ†æç»“æœæ—¶ï¼‰
            if self.duplicate_groups:
                print("\nğŸ”„ å¤„ç†é‡å¤issues...")
                self.process_duplicates()
                actions_performed.append("é‡å¤issueså¤„ç†")
            else:
                print("\nâš ï¸ æœªå‘ç°é‡å¤issuesï¼Œè·³è¿‡åˆå¹¶æ“ä½œ")

            # 3. æ‰¹é‡æ›´æ–°æ ‡ç­¾ï¼ˆä»…åœ¨æœ‰AIåˆ†æç»“æœæ—¶ï¼‰
            if self.label_recommendations:
                print("\nğŸ·ï¸ æ‰¹é‡æ›´æ–°issuesæ ‡ç­¾...")
                self.update_all_labels()
                actions_performed.append("æ ‡ç­¾æ›´æ–°")
            else:
                print("\nâš ï¸ æ²¡æœ‰AIæ ‡ç­¾å»ºè®®ï¼Œè·³è¿‡æ ‡ç­¾æ›´æ–°")

            # 4. ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            print("\nğŸ“‹ ç”Ÿæˆå¤„ç†æŠ¥å‘Š...")
            report_path = self.generate_summary_report()
            actions_performed.append("æŠ¥å‘Šç”Ÿæˆ")

            print(
                f"""
ğŸ‰ Issuesç®¡ç†å®Œæˆï¼

ğŸ“ˆ æ‰§è¡Œçš„æ“ä½œ:
{chr(10).join([f"- {action}" for action in actions_performed])}

ğŸ“Š å¤„ç†ç»Ÿè®¡:
- æ ‡å‡†åŒ–æ ‡ç­¾: {len(self.standard_labels)} ä¸ª
- é‡å¤ç»„å¤„ç†: {len(self.duplicate_groups)} ç»„
- æ ‡ç­¾æ›´æ–°: {len(self.label_recommendations)} ä¸ªissues
- å¤„ç†æŠ¥å‘Š: {report_path}

ğŸ”— åœ¨GitHubä¸ŠæŸ¥çœ‹æ›´æ–°ç»“æœ:
https://github.com/{self.repo}/issues

âœ¨ å»ºè®®åç»­æ“ä½œ:
1. æ£€æŸ¥GitHub issuesé¡µé¢ç¡®è®¤æ›´æ–°ç»“æœ
2. ä½¿ç”¨æ–°çš„æ ‡ç­¾ä½“ç³»æ¥ç®¡ç†future issues
3. è¿è¡ŒAIåˆ†æç”Ÿæˆæ›´å¤šç®¡ç†å»ºè®®
"""
            )

        except Exception as e:
            print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback

            traceback.print_exc()


if __name__ == "__main__":
    manager = GitHubIssuesExecutor()

    # æ£€æŸ¥å‚æ•°
    if len(sys.argv) > 1:
        command = sys.argv[1]
        if command == "labels":
            manager.create_standard_labels()
        elif command == "duplicates":
            manager.process_duplicates()
        elif command == "update-labels":
            manager.update_all_labels()
        elif command == "report":
            manager.generate_summary_report()
        else:
            print(
                "ç”¨æ³•: python3 manage_github_issues.py [labels|duplicates|update-labels|report]"
            )
    else:
        # è¿è¡Œå®Œæ•´æµç¨‹
        manager.run_full_management()
