#!/usr/bin/env python3
"""
SAGE Issues æ•°æ®ç®¡ç†å™¨
å®ç°å•ä¸€æ•°æ®æº + è§†å›¾åˆ†ç¦»çš„æ–°æ¶æ„
"""

import json
import os
import re
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional


class IssueDataManager:
    """ç»Ÿä¸€çš„Issueæ•°æ®ç®¡ç†å™¨"""

    def __init__(self, workspace_path: Path):
        self.workspace_path = Path(workspace_path)

        # æ–°æ¶æ„ç›®å½•
        self.data_dir = self.workspace_path / "data"
        self.views_dir = self.workspace_path / "views"
        self.cache_dir = self.workspace_path / "cache"

        # è§†å›¾å­ç›®å½•
        self.markdown_dir = self.views_dir / "markdown"
        self.metadata_dir = self.views_dir / "metadata"
        self.summaries_dir = self.views_dir / "summaries"

        # æ—§æ¶æ„ç›®å½•ï¼ˆç”¨äºè¿ç§»ï¼‰
        self.old_issues_dir = self.workspace_path / "issues"
        self.old_metadata_dir = self.workspace_path / "metadata"

        # åˆ›å»ºç›®å½•ç»“æ„
        self._ensure_directories()

    def _ensure_directories(self):
        """ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        for directory in [
            self.data_dir,
            self.views_dir,
            self.cache_dir,
            self.markdown_dir,
            self.metadata_dir,
            self.summaries_dir,
        ]:
            directory.mkdir(parents=True, exist_ok=True)

    def save_issue(
        self, issue_data: Dict[str, Any], comments: List[Dict] = None
    ) -> bool:
        """ä¿å­˜issueåˆ°å•ä¸€æ•°æ®æº

        Args:
            issue_data: ä»GitHub APIè·å–çš„issueæ•°æ®
            comments: issueçš„è¯„è®ºåˆ—è¡¨

        Returns:
            bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            issue_number = issue_data.get("number")
            if not issue_number:
                print("âŒ Issueæ•°æ®ç¼ºå°‘ç¼–å·")
                return False

            # å¤„ç†milestoneä¿¡æ¯
            milestone_info = None
            if issue_data.get("milestone"):
                milestone = issue_data["milestone"]
                milestone_info = {
                    "number": milestone.get("number"),
                    "title": milestone.get("title"),
                    "description": milestone.get("description"),
                    "state": milestone.get("state"),
                    "due_on": milestone.get("due_on"),
                    "html_url": milestone.get("html_url"),
                    "created_at": milestone.get("created_at"),
                    "updated_at": milestone.get("updated_at"),
                }

            # å¤„ç†reactionsä¿¡æ¯
            reactions_info = None
            if issue_data.get("reactions"):
                reactions = issue_data["reactions"]
                reactions_info = {
                    "total_count": reactions.get("total_count", 0),
                    "+1": reactions.get("+1", 0),
                    "-1": reactions.get("-1", 0),
                    "laugh": reactions.get("laugh", 0),
                    "hooray": reactions.get("hooray", 0),
                    "confused": reactions.get("confused", 0),
                    "heart": reactions.get("heart", 0),
                    "rocket": reactions.get("rocket", 0),
                    "eyes": reactions.get("eyes", 0),
                }

            # å¤„ç†é¡¹ç›®ä¿¡æ¯ï¼ˆè¿™é‡Œå‡è®¾å·²ç»é€šè¿‡å…¶ä»–æ–¹å¼è·å–ï¼‰
            projects_info = issue_data.get("projects", [])

            # æ„å»ºç»Ÿä¸€çš„æ•°æ®ç»“æ„
            unified_data = {
                "metadata": {
                    "number": issue_number,
                    "title": issue_data.get("title", ""),
                    "state": issue_data.get("state", "open"),
                    "state_reason": issue_data.get("state_reason"),
                    "labels": [
                        l_strip.get("name") if isinstance(l_strip, dict) else l_strip
                        for l_strip in issue_data.get("labels", [])
                    ],
                    "assignees": [
                        a.get("login") if isinstance(a, dict) else a
                        for a in issue_data.get("assignees", [])
                    ],
                    "assignee": (
                        issue_data.get("assignee", {}).get("login")
                        if issue_data.get("assignee")
                        else None
                    ),
                    "milestone": milestone_info,
                    "reactions": reactions_info,
                    "comments_count": issue_data.get("comments", 0),
                    "locked": issue_data.get("locked", False),
                    "active_lock_reason": issue_data.get("active_lock_reason"),
                    "created_at": issue_data.get("created_at"),
                    "updated_at": issue_data.get("updated_at"),
                    "closed_at": issue_data.get("closed_at"),
                    "closed_by": (
                        issue_data.get("closed_by", {}).get("login")
                        if issue_data.get("closed_by")
                        else None
                    ),
                    "html_url": issue_data.get("html_url"),
                    "url": issue_data.get("url"),
                    "comments_url": issue_data.get("comments_url"),
                    "events_url": issue_data.get("events_url"),
                    "labels_url": issue_data.get("labels_url"),
                    "repository_url": issue_data.get("repository_url"),
                    "timeline_url": issue_data.get("timeline_url"),
                    "node_id": issue_data.get("node_id"),
                    "id": issue_data.get("id"),
                    "user": (
                        issue_data.get("user", {}).get("login")
                        if isinstance(issue_data.get("user"), dict)
                        else issue_data.get("user")
                    ),
                    "user_info": (
                        {
                            "login": issue_data.get("user", {}).get("login"),
                            "id": issue_data.get("user", {}).get("id"),
                            "node_id": issue_data.get("user", {}).get("node_id"),
                            "avatar_url": issue_data.get("user", {}).get("avatar_url"),
                            "html_url": issue_data.get("user", {}).get("html_url"),
                            "type": issue_data.get("user", {}).get("type"),
                            "site_admin": issue_data.get("user", {}).get("site_admin"),
                        }
                        if isinstance(issue_data.get("user"), dict)
                        else None
                    ),
                    "author_association": issue_data.get("author_association"),
                    "performed_via_github_app": issue_data.get(
                        "performed_via_github_app"
                    ),
                    "type": issue_data.get("type"),
                    "projects": projects_info,
                    # æ–°å¢ï¼šå…³ç³»å’Œä¾èµ–ä¿¡æ¯
                    "issue_dependencies_summary": issue_data.get(
                        "issue_dependencies_summary",
                        {
                            "blocked_by": 0,
                            "total_blocked_by": 0,
                            "blocking": 0,
                            "total_blocking": 0,
                        },
                    ),
                    "sub_issues_summary": issue_data.get(
                        "sub_issues_summary",
                        {"total": 0, "completed": 0, "percent_completed": 0},
                    ),
                    # æ–°å¢ï¼šçˆ¶å­å…³ç³»ä¿¡æ¯
                    "parent_issue_url": issue_data.get("parent_issue_url"),
                },
                "content": {
                    "body": issue_data.get("body", ""),
                    "comments": comments or [],
                },
                "tracking": {
                    "downloaded_at": datetime.now().isoformat(),
                    "last_synced": datetime.now().isoformat(),
                    "update_history": [
                        {
                            "timestamp": datetime.now().isoformat(),
                            "action": "data_save",
                            "github_updated": issue_data.get("updated_at"),
                        }
                    ],
                },
            }

            # ä¿å­˜åˆ°æ•°æ®æ–‡ä»¶
            data_file = self.data_dir / f"issue_{issue_number}.json"
            with open(data_file, "w", encoding="utf-8") as f:
                json.dump(unified_data, f, ensure_ascii=False, indent=2)

            print(f"âœ… Issue #{issue_number} æ•°æ®å·²ä¿å­˜")
            return True

        except Exception as e:
            print(f"âŒ ä¿å­˜Issueæ•°æ®å¤±è´¥: {e}")
            return False

    def get_issue(self, issue_number: int) -> Optional[Dict[str, Any]]:
        """è·å–å®Œæ•´çš„issueæ•°æ®

        Args:
            issue_number: Issueç¼–å·

        Returns:
            Dict: Issueçš„å®Œæ•´æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        try:
            data_file = self.data_dir / f"issue_{issue_number}.json"
            if not data_file.exists():
                return None

            with open(data_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ è¯»å–Issue #{issue_number} æ•°æ®å¤±è´¥: {e}")
            return None

    def list_all_issues(self) -> List[int]:
        """è·å–æ‰€æœ‰issueç¼–å·åˆ—è¡¨"""
        issue_numbers = []
        for data_file in self.data_dir.glob("issue_*.json"):
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æ–‡ä»¶åä¸­æå–issueç¼–å·
            match = re.match(r"issue_(\d+)$", data_file.stem)
            if match:
                number = int(match.group(1))
                issue_numbers.append(number)
            else:
                continue
        return sorted(issue_numbers)

    def generate_markdown_view(self, issue_number: int) -> bool:
        """ç”Ÿæˆmarkdownè§†å›¾

        Args:
            issue_number: Issueç¼–å·

        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        try:
            issue_data = self.get_issue(issue_number)
            if not issue_data:
                print(f"âŒ Issue #{issue_number} æ•°æ®ä¸å­˜åœ¨")
                return False

            metadata = issue_data["metadata"]
            content = issue_data["content"]
            tracking = issue_data["tracking"]

            # ç”Ÿæˆæ–‡ä»¶å
            safe_title = self._sanitize_filename(metadata["title"])
            filename = f"{metadata['state']}_{issue_number}_{safe_title}.md"

            # å¤„ç†é¡¹ç›®ä¿¡æ¯
            project_section = ""
            if metadata.get("projects"):
                project_section = "\n## Projectå½’å±\n"
                for proj in metadata["projects"]:
                    project_section += f"- **{proj['team']}** (Project Board ID: {proj['number']}: {proj['title']})\n"
            else:
                project_section = "\n## Projectå½’å±\næœªå½’å±åˆ°ä»»ä½•Project\n"

            # å¤„ç†milestoneä¿¡æ¯
            milestone_section = ""
            if metadata.get("milestone"):
                milestone = metadata["milestone"]
                milestone_section = f"""
## Milestone
**{milestone.get('title', 'N/A')}** ({milestone.get('state', 'unknown')})
- æè¿°: {milestone.get('description', 'æ— æè¿°')}
- æˆªæ­¢æ—¥æœŸ: {milestone.get('due_on', 'æœªè®¾å®š')}
- [æŸ¥çœ‹è¯¦æƒ…]({milestone.get('html_url', '#')})
"""

            # å¤„ç†ç»Ÿè®¡ä¿¡æ¯
            stats_section = ""
            comments_count = metadata.get("comments_count", 0)
            reactions = metadata.get("reactions", {})
            total_reactions = reactions.get("total_count", 0) if reactions else 0
            is_locked = metadata.get("locked", False)

            if comments_count > 0 or total_reactions > 0 or is_locked:
                stats_section = "\n## ç»Ÿè®¡ä¿¡æ¯\n"
                if comments_count > 0:
                    stats_section += f"- è¯„è®ºæ•°: {comments_count}\n"
                if total_reactions > 0:
                    stats_section += f"- ååº”æ•°: {total_reactions}\n"
                    if reactions:
                        reaction_details = []
                        for emoji, count in reactions.items():
                            if emoji != "total_count" and count > 0:
                                reaction_details.append(f"{emoji}: {count}")
                        if reaction_details:
                            stats_section += (
                                f"  - è¯¦æƒ…: {', '.join(reaction_details)}\n"
                            )
                if is_locked:
                    stats_section += "- çŠ¶æ€: å·²é”å®š\n"

            # å¤„ç†åˆ†é…ä¿¡æ¯
            assignees_text = "æœªåˆ†é…"
            if metadata.get("assignees"):
                assignees_text = "\n".join(metadata["assignees"])

            # å¤„ç†æ›´æ–°è®°å½•
            update_history_section = ""
            if tracking.get("update_history"):
                update_history_section = "\n## æ›´æ–°è®°å½•\n\n"
                for record in tracking["update_history"]:
                    timestamp = record.get("timestamp", "")
                    action = record.get("action", "")
                    github_updated = record.get("github_updated", "")

                    if timestamp:
                        try:
                            dt = datetime.fromisoformat(
                                timestamp.replace("Z", "+00:00")
                            )
                            time_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                        except Exception:
                            time_str = timestamp

                        update_history_section += f"- **{time_str}**: {action}\n"
                        if github_updated:
                            try:
                                dt = datetime.fromisoformat(
                                    github_updated.replace("Z", "+00:00")
                                )
                                github_time_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                                update_history_section += (
                                    f"  - GitHubæœ€åæ›´æ–°: {github_time_str}\n"
                                )
                            except Exception:
                                pass
                update_history_section += "\n"

            # ç”Ÿæˆmarkdownå†…å®¹
            markdown_content = f"""# {metadata['title']}

**Issue #**: {metadata['number']}
**çŠ¶æ€**: {metadata['state']}
**åˆ›å»ºæ—¶é—´**: {metadata['created_at']}
**æ›´æ–°æ—¶é—´**: {metadata['updated_at']}
**åˆ›å»ºè€…**: {metadata['user']}
{project_section}{milestone_section}{stats_section}
## æ ‡ç­¾
{', '.join(metadata.get('labels', []))}

## åˆ†é…ç»™
{assignees_text}

## æè¿°

{content.get('body', 'æ— æè¿°')}
{update_history_section}
---
**GitHubé“¾æ¥**: {metadata['html_url']}
**ä¸‹è½½æ—¶é—´**: {tracking.get('downloaded_at', '')}
"""

            # ä¿å­˜markdownæ–‡ä»¶
            markdown_file = self.markdown_dir / filename
            with open(markdown_file, "w", encoding="utf-8") as f:
                f.write(markdown_content)

            return True

        except Exception as e:
            print(f"âŒ ç”ŸæˆIssue #{issue_number} markdownè§†å›¾å¤±è´¥: {e}")
            return False

    def generate_metadata_view(self, issue_number: int) -> bool:
        """ç”Ÿæˆå…ƒæ•°æ®è§†å›¾ï¼ˆå‘åå…¼å®¹ï¼‰

        Args:
            issue_number: Issueç¼–å·

        Returns:
            bool: ç”Ÿæˆæ˜¯å¦æˆåŠŸ
        """
        try:
            issue_data = self.get_issue(issue_number)
            if not issue_data:
                return False

            metadata = issue_data["metadata"]

            # æ„å»ºå‘åå…¼å®¹çš„å…ƒæ•°æ®æ ¼å¼
            compat_metadata = {
                "number": metadata["number"],
                "title": metadata["title"],
                "state": metadata["state"],
                "labels": metadata.get("labels", []),
                "assignees": metadata.get("assignees", []),
                "milestone": metadata.get("milestone"),
                "reactions": metadata.get("reactions"),
                "comments_count": metadata.get("comments_count", 0),
                "locked": metadata.get("locked", False),
                "created_at": metadata.get("created_at"),
                "updated_at": metadata.get("updated_at"),
                "closed_at": metadata.get("closed_at"),
                "html_url": metadata.get("html_url"),
                "user": metadata.get("user"),
                "projects": metadata.get("projects", []),
            }

            # ä¿å­˜å…ƒæ•°æ®æ–‡ä»¶
            metadata_file = self.metadata_dir / f"issue_{issue_number}_metadata.json"
            with open(metadata_file, "w", encoding="utf-8") as f:
                json.dump(compat_metadata, f, ensure_ascii=False, indent=2)

            return True

        except Exception as e:
            print(f"âŒ ç”ŸæˆIssue #{issue_number} å…ƒæ•°æ®è§†å›¾å¤±è´¥: {e}")
            return False

    def generate_all_views(self) -> Dict[str, int]:
        """ç”Ÿæˆæ‰€æœ‰è§†å›¾

        Returns:
            Dict: ç”Ÿæˆç»“æœç»Ÿè®¡
        """
        issue_numbers = self.list_all_issues()

        results = {
            "total": len(issue_numbers),
            "markdown_success": 0,
            "metadata_success": 0,
            "failed": 0,
        }

        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {results['total']} ä¸ªIssueçš„è§†å›¾...")

        for issue_number in issue_numbers:
            try:
                markdown_ok = self.generate_markdown_view(issue_number)
                metadata_ok = self.generate_metadata_view(issue_number)

                if markdown_ok:
                    results["markdown_success"] += 1
                if metadata_ok:
                    results["metadata_success"] += 1
                if not (markdown_ok and metadata_ok):
                    results["failed"] += 1

                if (results["markdown_success"] + results["failed"]) % 10 == 0:
                    print(
                        f"ğŸ“Š å·²å¤„ç† {results['markdown_success'] + results['failed']}/{results['total']} ä¸ªIssue"
                    )

            except Exception as e:
                print(f"âŒ å¤„ç†Issue #{issue_number} å¤±è´¥: {e}")
                results["failed"] += 1

        # ç”Ÿæˆæ±‡æ€»è§†å›¾
        self.generate_summary_views()

        return results

    def generate_summary_views(self):
        """ç”Ÿæˆæ±‡æ€»è§†å›¾"""
        try:
            print("ğŸ“Š ç”Ÿæˆæ±‡æ€»è§†å›¾...")

            # æŒ‰å›¢é˜Ÿæ±‡æ€»
            issues_by_team = {}
            # æŒ‰milestoneæ±‡æ€»
            issues_by_milestone = {}
            # æŒ‰çŠ¶æ€æ±‡æ€»
            issues_by_state = {"open": 0, "closed": 0}

            for issue_number in self.list_all_issues():
                issue_data = self.get_issue(issue_number)
                if not issue_data:
                    continue

                metadata = issue_data["metadata"]

                # æŒ‰çŠ¶æ€ç»Ÿè®¡
                state = metadata.get("state", "unknown")
                issues_by_state[state] = issues_by_state.get(state, 0) + 1

                # æŒ‰å›¢é˜Ÿç»Ÿè®¡
                projects = metadata.get("projects", [])
                for project in projects:
                    team = project.get("team", "unknown")
                    if team not in issues_by_team:
                        issues_by_team[team] = []
                    issues_by_team[team].append(
                        {
                            "number": metadata["number"],
                            "title": metadata["title"],
                            "state": metadata["state"],
                        }
                    )

                # æŒ‰milestoneç»Ÿè®¡
                milestone = metadata.get("milestone")
                if milestone:
                    milestone_title = milestone.get("title", "unknown")
                    if milestone_title not in issues_by_milestone:
                        issues_by_milestone[milestone_title] = []
                    issues_by_milestone[milestone_title].append(
                        {
                            "number": metadata["number"],
                            "title": metadata["title"],
                            "state": metadata["state"],
                        }
                    )

            # ä¿å­˜æ±‡æ€»æ–‡ä»¶
            with open(
                self.summaries_dir / "issues_by_team.json", "w", encoding="utf-8"
            ) as f:
                json.dump(issues_by_team, f, ensure_ascii=False, indent=2)

            with open(
                self.summaries_dir / "issues_by_milestone.json", "w", encoding="utf-8"
            ) as f:
                json.dump(issues_by_milestone, f, ensure_ascii=False, indent=2)

            with open(
                self.summaries_dir / "issues_by_state.json", "w", encoding="utf-8"
            ) as f:
                json.dump(issues_by_state, f, ensure_ascii=False, indent=2)

            print("âœ… æ±‡æ€»è§†å›¾ç”Ÿæˆå®Œæˆ")

        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ±‡æ€»è§†å›¾å¤±è´¥: {e}")

    def migrate_from_old_format(self) -> Dict[str, int]:
        """ä»æ—§æ ¼å¼è¿ç§»æ•°æ®

        Returns:
            Dict: è¿ç§»ç»“æœç»Ÿè®¡
        """
        print("ğŸ”„ å¼€å§‹ä»æ—§æ ¼å¼è¿ç§»æ•°æ®...")

        results = {
            "markdown_processed": 0,
            "metadata_processed": 0,
            "data_created": 0,
            "failed": 0,
        }

        # å¤„ç†æ—§çš„markdownæ–‡ä»¶
        if self.old_issues_dir.exists():
            for md_file in self.old_issues_dir.glob("*.md"):
                try:
                    results["markdown_processed"] += 1
                    issue_data = self._parse_old_markdown_file(md_file)
                    if issue_data:
                        # å°è¯•åŠ è½½å¯¹åº”çš„metadataæ–‡ä»¶
                        issue_number = issue_data["number"]
                        metadata_file = (
                            self.old_metadata_dir
                            / f"issue_{issue_number}_metadata.json"
                        )
                        if metadata_file.exists():
                            with open(metadata_file, "r", encoding="utf-8") as f:
                                old_metadata = json.load(f)
                            # åˆå¹¶æ•°æ®
                            issue_data.update(old_metadata)
                            results["metadata_processed"] += 1

                        # ä¿å­˜åˆ°æ–°æ ¼å¼
                        if self.save_issue(issue_data):
                            results["data_created"] += 1

                except Exception as e:
                    print(f"âŒ è¿ç§»æ–‡ä»¶ {md_file} å¤±è´¥: {e}")
                    results["failed"] += 1

        print(f"ğŸ“Š è¿ç§»å®Œæˆ: å¤„ç†äº† {results['markdown_processed']} ä¸ªmarkdownæ–‡ä»¶")
        print(f"ğŸ“Š åˆ›å»ºäº† {results['data_created']} ä¸ªæ•°æ®æ–‡ä»¶")

        return results

    def _parse_old_markdown_file(self, md_file: Path) -> Optional[Dict]:
        """è§£ææ—§æ ¼å¼çš„markdownæ–‡ä»¶"""
        try:
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read()

            lines = content.split("\n")
            issue_data = {}

            # ä»æ–‡ä»¶åæå–ä¿¡æ¯
            filename = md_file.name
            if filename.startswith(("open_", "closed_")):
                parts = filename.split("_")
                if len(parts) >= 2:
                    try:
                        issue_data["number"] = int(parts[1])
                        issue_data["state"] = parts[0]
                    except ValueError:
                        pass

            # è§£æå†…å®¹
            for line in lines:
                line = line.strip()
                if line.startswith("# "):
                    issue_data["title"] = line[2:].strip()
                elif line.startswith("**Issue #**:"):
                    try:
                        issue_data["number"] = int(line.split(":")[1].strip())
                    except Exception:
                        pass
                elif line.startswith("**çŠ¶æ€**:"):
                    issue_data["state"] = line.split(":")[1].strip()
                elif line.startswith("**åˆ›å»ºæ—¶é—´**:"):
                    issue_data["created_at"] = line.split(":", 1)[1].strip()
                elif line.startswith("**æ›´æ–°æ—¶é—´**:"):
                    issue_data["updated_at"] = line.split(":", 1)[1].strip()
                elif line.startswith("**åˆ›å»ºè€…**:"):
                    issue_data["user"] = line.split(":")[1].strip()
                elif line.startswith("**GitHubé“¾æ¥**:"):
                    issue_data["html_url"] = line.split(":", 1)[1].strip()

            # æå–bodyå†…å®¹
            body_start = content.find("## æè¿°")
            if body_start != -1:
                body_content = content[
                    body_start
                    + len("## æè¿°") : (
                        content.find("## æ›´æ–°è®°å½•")
                        if "## æ›´æ–°è®°å½•" in content
                        else content.find("---")
                    )
                ]
                issue_data["body"] = body_content.strip()

            return issue_data

        except Exception as e:
            print(f"âŒ è§£ææ–‡ä»¶ {md_file} å¤±è´¥: {e}")
            return None

    def _sanitize_filename(self, text: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸åˆæ³•å­—ç¬¦"""
        text = re.sub(r'[<>:"/\\|?*]', "", text)
        text = re.sub(r"\s+", "_", text)
        return text[:50]

    def create_backward_compatibility_links(self):
        """åˆ›å»ºå‘åå…¼å®¹çš„ç¬¦å·é“¾æ¥"""
        try:
            # åˆ›å»ºæŒ‡å‘markdownè§†å›¾çš„ç¬¦å·é“¾æ¥
            issues_link = self.workspace_path / "issues"
            if not issues_link.exists():
                issues_link.symlink_to(self.markdown_dir, target_is_directory=True)
                print("âœ… åˆ›å»ºissuesç›®å½•çš„å‘åå…¼å®¹é“¾æ¥")

            # åˆ›å»ºæŒ‡å‘metadataè§†å›¾çš„ç¬¦å·é“¾æ¥
            metadata_link = self.workspace_path / "metadata"
            if not metadata_link.exists():
                metadata_link.symlink_to(self.metadata_dir, target_is_directory=True)
                print("âœ… åˆ›å»ºmetadataç›®å½•çš„å‘åå…¼å®¹é“¾æ¥")

        except Exception as e:
            print(f"âš ï¸ åˆ›å»ºå‘åå…¼å®¹é“¾æ¥å¤±è´¥: {e}")


def main():
    """æµ‹è¯•æ–°æ¶æ„"""
    import argparse

    parser = argparse.ArgumentParser(description="Issueæ•°æ®ç®¡ç†å™¨")
    parser.add_argument(
        "--workspace",
        default=os.path.expanduser("~/SAGE/output/issues-workspace"),
        help="å·¥ä½œç›®å½•è·¯å¾„",
    )
    parser.add_argument("--migrate", action="store_true", help="ä»æ—§æ ¼å¼è¿ç§»æ•°æ®")
    parser.add_argument("--generate-views", action="store_true", help="ç”Ÿæˆæ‰€æœ‰è§†å›¾")
    parser.add_argument("--create-links", action="store_true", help="åˆ›å»ºå‘åå…¼å®¹é“¾æ¥")

    args = parser.parse_args()

    manager = IssueDataManager(args.workspace)

    if args.migrate:
        results = manager.migrate_from_old_format()
        print(f"ğŸ“Š è¿ç§»ç»“æœ: {results}")

    if args.generate_views:
        results = manager.generate_all_views()
        print(f"ğŸ“Š è§†å›¾ç”Ÿæˆç»“æœ: {results}")

    if args.create_links:
        manager.create_backward_compatibility_links()


if __name__ == "__main__":
    main()
