{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import urllib.request\n",
    "\n",
    "from codetiming import Timer\n",
    "from polars import col\n",
    "from polars_tdigest import estimate_quantile, tdigest, tdigest_cast\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "\n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(\n",
    "        unit=\"B\", unit_scale=True, miniters=1, desc=url.split(\"/\")[-1]\n",
    "    ) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset yellow_tripdata_2024-02.parquet has 3007526 rows\n",
      "TDigest took: 119 ms\n",
      "TDigest took: 108 ms\n",
      "TDigest took: 108 ms\n",
      "TDigest took: 109 ms\n",
      "TDigest took: 108 ms\n",
      "TDigest with cast took: 109 ms\n",
      "TDigest with cast took: 108 ms\n",
      "TDigest with cast took: 108 ms\n",
      "TDigest with cast took: 109 ms\n",
      "TDigest with cast took: 107 ms\n",
      "Dataset yellow_tripdata_2024-03.parquet has 3582628 rows\n",
      "TDigest took: 136 ms\n",
      "TDigest took: 116 ms\n",
      "TDigest took: 113 ms\n",
      "TDigest took: 112 ms\n",
      "TDigest took: 112 ms\n",
      "TDigest with cast took: 111 ms\n",
      "TDigest with cast took: 111 ms\n",
      "TDigest with cast took: 111 ms\n",
      "TDigest with cast took: 112 ms\n",
      "TDigest with cast took: 112 ms\n",
      "Estimate median took: 0 ms\n",
      "Estimate median took: 0 ms\n",
      "Estimate median took: 0 ms\n",
      "Estimate median took: 0 ms\n",
      "Estimate median took: 0 ms\n",
      "Estimated median = 1.7201926614756424\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/\"\n",
    "dataset_files = [\"yellow_tripdata_2024-02.parquet\", \"yellow_tripdata_2024-03.parquet\"]\n",
    "local_folder = \"/tmp/\"\n",
    "datasets = []\n",
    "tdigests = []\n",
    "run_performance_test = True\n",
    "numeric_col = \"trip_distance\"\n",
    "max_size = 100\n",
    "\n",
    "for dataset in dataset_files:\n",
    "    local_file = f\"{local_folder}{dataset}\"\n",
    "    if not os.path.exists(local_file):\n",
    "        download_url(f\"{base_url}{dataset}\", f\"{local_folder}{dataset}\")\n",
    "    df = pl.scan_parquet(local_file)\n",
    "    datasets.append(df)\n",
    "\n",
    "    print(f\"Dataset {dataset} has {df.select(pl.len()).collect().item()} rows\")\n",
    "\n",
    "    query = df.select(tdigest(numeric_col, max_size))\n",
    "    query_cast = df.select(tdigest_cast(numeric_col, max_size))\n",
    "    if run_performance_test:\n",
    "        for _ in range(5):\n",
    "            with Timer(text=\"TDigest took: {milliseconds:.0f} ms\"):\n",
    "                query.collect()\n",
    "\n",
    "        for _ in range(5):\n",
    "            with Timer(text=\"TDigest with cast took: {milliseconds:.0f} ms\"):\n",
    "                query_cast.collect()\n",
    "\n",
    "    tdigests.append(query.collect())\n",
    "\n",
    "df = pl.concat(tdigests)\n",
    "if run_performance_test:\n",
    "    for _ in range(5):\n",
    "        with Timer(text=\"Estimate median took: {milliseconds:.0f} ms\"):\n",
    "            df.select(estimate_quantile(numeric_col, 0.5))\n",
    "\n",
    "print(\"Estimated median =\", df.select(estimate_quantile(numeric_col, 0.5)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median took: 36 ms\n",
      "Median took: 28 ms\n",
      "Median took: 28 ms\n",
      "Median took: 30 ms\n",
      "Median took: 29 ms\n",
      "Median = 1.71\n"
     ]
    }
   ],
   "source": [
    "median_query = pl.concat(datasets).select(col(numeric_col).median())\n",
    "\n",
    "for _ in range(5):\n",
    "    with Timer(text=\"Median took: {milliseconds:.0f} ms\"):\n",
    "        median_query.collect()\n",
    "\n",
    "print(\n",
    "    \"Median =\",\n",
    "    median_query.collect().item(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median on partition took: 20 ms\n",
      "Median on partition took: 20 ms\n",
      "Median on partition took: 19 ms\n",
      "Median on partition took: 19 ms\n",
      "Median on partition took: 19 ms\n",
      "Median on partition took: 21 ms\n",
      "Median on partition took: 21 ms\n",
      "Median on partition took: 20 ms\n",
      "Median on partition took: 20 ms\n",
      "Median on partition took: 20 ms\n"
     ]
    }
   ],
   "source": [
    "for partition in datasets:\n",
    "    for _ in range(5):\n",
    "        with Timer(text=\"Median on partition took: {milliseconds:.0f} ms\"):\n",
    "            partition.select(col(numeric_col).median()).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
