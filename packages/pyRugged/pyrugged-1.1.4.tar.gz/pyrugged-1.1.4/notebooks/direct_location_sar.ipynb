{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48f1cf9",
   "metadata": {},
   "source": [
    "# Direct location SAR\n",
    "\n",
    "## PyRugged API - tutorial 5\n",
    "\n",
    "\n",
    "This tutorial explains how to initialize `PyRugged` and use it to geolocate a satellite SAR image. The antenna will be modeled by the SAR sensor and will be pointing right for the example. GPS and AOCS auxiliary data are available and provide us with a list of positions, velocities and attitude quaternions recorded during the acquisition. By passing all this information to `PyRugged`, we will be able to precisely locate each point of the image on the Earth. We will locate the image on an constant elevation ellipsoid above Earth surface. The objective here is limited to explain how to initialize everything `PyRugged` needs to know about the SAR sensor and the acquisition. This notebook is based on RADASAT example.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af8b703",
   "metadata": {},
   "source": [
    "### Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bec6976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orekit\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from org.hipparchus.geometry.euclidean.threed import Vector3D\n",
    "from org.orekit.frames import Frame\n",
    "from org.orekit.frames import FramesFactory\n",
    "from org.orekit.frames import Transform\n",
    "from org.orekit.time import AbsoluteDate, TimeScalesFactory\n",
    "from org.orekit.utils import (\n",
    "    CartesianDerivativesFilter,\n",
    "    PVCoordinates,\n",
    "    TimeStampedPVCoordinates,\n",
    ")\n",
    "\n",
    "from pyrugged.bodies.body_rotating_frame_id import BodyRotatingFrameId\n",
    "from pyrugged.bodies.ellipsoid_id import EllipsoidId\n",
    "from pyrugged.configuration.init_orekit import init_orekit\n",
    "from pyrugged.intersection.algorithm_id import AlgorithmId\n",
    "from pyrugged.intersection.constant_elevation_algorithm import ConstantElevationAlgorithm\n",
    "from pyrugged.location.sar import SARLocation\n",
    "from pyrugged.model.pyrugged_builder import PyRuggedBuilder\n",
    "from pyrugged.sar_sensor.doppler_model import DopplerModel\n",
    "from pyrugged.sar_sensor.range_from_pixel import RangeFromPixel, RangeGridCreation\n",
    "from pyrugged.sar_sensor.sar_line_datation import SARLineDatation\n",
    "from pyrugged.sar_sensor.sar_sensor import SARSensor\n",
    "from pyrugged.utils.constants import Constants\n",
    "from pyrugged.utils.coordinates_reader import extract_pv_from_txt\n",
    "from pyrugged.utils.spacecraft_to_observed_body_sar import SpacecraftToObservedBodySAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa8244",
   "metadata": {},
   "source": [
    "### Initialization \n",
    "\n",
    "initialize JVM or GraalVM subtrat VM and Orekit, internal orekit data is used here. See configuration section of user manual for further information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59fa5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_orekit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc172e43",
   "metadata": {},
   "source": [
    "## 1 - Sensor's definition\n",
    "\n",
    "Let’s start by defining the SAR sensor. The sensor model is described by its datation model, range model and doppler model (which will be zero doppler as it's the only one implemented for now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756384dd",
   "metadata": {},
   "source": [
    "### Datation Model\n",
    "\n",
    "We need to define the datation model for each pixel (col, line) of the image. In order to construct this model, will we construct a grid containing dates which will be interpolated to compute the date for each pixel. For RADARSAT the date will be constant along lines that is to say that 2 pixels in the same line will have the same date. Here for the example line 0.5 was acquired at 2016-06-05T06:02:08.226323 and line 27193.5 at 2016-06-05T06:02:16.108620. We used pixel halves here as ESA RADARSAT products use this convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1b0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_date = AbsoluteDate(\"2016-06-05T06:02:08.226323\", TimeScalesFactory.getUTC())\n",
    "\n",
    "lines = [0.5, 27193.5]\n",
    "pixels = [0, 20576]\n",
    "corresponding_date_gap = [\n",
    "        [0, -reference_date.durationFrom(AbsoluteDate(\"2016-06-05T06:02:16.108620\", TimeScalesFactory.getUTC()))],\n",
    "        [0, -reference_date.durationFrom(AbsoluteDate(\"2016-06-05T06:02:16.108620\", TimeScalesFactory.getUTC()))],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee7bef",
   "metadata": {},
   "source": [
    "The SARLineDatation model is instanciated with 4 arguments: the first is the pixel numbers used to initialise the grid, the second is the line numbers used to initialise the grid, the third a reference date with which a difference will be done to compute a grid of durations compared to this reference date and the last argument is the grid of time differences between (pixel,line) date and reference date.\n",
    "\n",
    "1st arg : pixel column\n",
    "\n",
    "2nd arg : pixel line\n",
    "\n",
    "3rd arg : reference date\n",
    "\n",
    "4th arg : date offset with reference date grid for each (pixel column, pixel line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e904690",
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_datation = SARLineDatation(np.array(pixels), np.array(lines), reference_date, np.array(corresponding_date_gap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605c7c0",
   "metadata": {},
   "source": [
    "### Range Model\n",
    "\n",
    "We need to define the range model for each pixel (col, line) of the image. In order to construct this model, will we construct a grid containing range which will be interpolated to compute the range for each pixel. For RADARSAT the range is given by a polynom applied to the pixel column. The polynom will be very simple if the SAR product is given in SLC (basically order 1) and will be much more complex if the SAR product is given in GRD. For each col, the polynom expression is :\n",
    "\n",
    "$distSR_{col} = \\sum_{i=0}^{n} coeff_i * (col ∗ sampledPixelSpacing – groundRangeOrigin)^i$\n",
    "\n",
    "Where polynome coefficients are given in RADARSAT product.\n",
    "\n",
    "**Warning n°1** : the col value in the previous formula varies from 1 to total pixel number, but to be compatible with the code and python starting at 0, you must have pixel number varying from 0 to total pixel number - 1 when you construct the range model.\n",
    "\n",
    "**Warning n°2** : a parameter available in the RADARSAT product will tell you if the pixel ordering time is increasing or decreasing. If increasing distSR_col correspond to column col, if decreasing distSR_col correspond to total_col - col + 1. This is handle by the range_model implementation when calling ground_range_to_slant_range_polynom_application.\n",
    "\n",
    "**Warning n°3** : RADARSAT product use a convention for which location are given for pixel halves, this is taken into account into the range_model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a57cb",
   "metadata": {},
   "source": [
    "For an image with 20577 pixels and 27194 lines and for which pixel ordering time is decreasing, we use the class RangeGridCreation which take polynome coefficient and total number of pixels to be able to compute distSR polynome for given column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715f4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel time ordering : decreasing\n",
    "pixel_time_increasing = False\n",
    "\n",
    "# Polynome coefficient for RADARSAT SLC product\n",
    "sr_coefficient = np.array([9.738835958311997e05, 1.0, 0.0, 0.0, 0.0, 0.0])[::-1]\n",
    "\n",
    "# Pixel number and ground range origin\n",
    "total_pixel_number = 20577\n",
    "ground_range_or = 0.0\n",
    "\n",
    "# Pixel size = sampled pixel spacing\n",
    "pixel_size_slc = 1.33117902\n",
    "\n",
    "# Range Grid Creation class to construct and compute distSR for given column. Only useable for RADARSAT data\n",
    "# not useful for Sentinal data\n",
    "range_grid_construction = RangeGridCreation(total_pixel_number, sr_coefficient)\n",
    "ranges = [\n",
    "    [\n",
    "        range_grid_construction.ground_range_to_slant_range_polynom_application(\n",
    "            pixel_size_slc, ground_range_or, 0, pixel_time_increasing\n",
    "        ),\n",
    "        range_grid_construction.ground_range_to_slant_range_polynom_application(\n",
    "            pixel_size_slc, ground_range_or, 0, pixel_time_increasing\n",
    "        ),\n",
    "    ],\n",
    "    [\n",
    "        range_grid_construction.ground_range_to_slant_range_polynom_application(\n",
    "            pixel_size_slc, ground_range_or, 20576, pixel_time_increasing\n",
    "        ),\n",
    "        range_grid_construction.ground_range_to_slant_range_polynom_application(\n",
    "            pixel_size_slc, ground_range_or, 20576, pixel_time_increasing\n",
    "        ),\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909cd07b",
   "metadata": {},
   "source": [
    "The RangeFromPixel model is instanciated with 3 arguments: the first is the pixel numbers used to initialise the grid, the second is the line numbers used to initialise the grid and the last argument is the grid of range for (pixel,line).\n",
    "\n",
    "1st arg : pixel column\n",
    "\n",
    "2nd arg : pixel line\n",
    "\n",
    "4th arg : range corresponding to each (pixel column, pixel line) computed with the distSR polynome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c82fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_pix_correspondance = RangeFromPixel(np.array(pixels), np.array(lines), np.array(ranges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87aa0e",
   "metadata": {},
   "source": [
    "### Doppler Model\n",
    "\n",
    "For now only the zero doppler model as been implemented, that is to say that doppler contribution will always be zero and is easy to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "302f692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doppler = DopplerModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c6001",
   "metadata": {},
   "source": [
    "### SAR Sensor\n",
    "\n",
    "Now that datation model, range model and doppler model have been defined, we can construct our SAR Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b2d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our example the SAR antenna is pointing right\n",
    "antenna_pointing_right = True\n",
    "\n",
    "sensor = SARSensor('sar_sensor', sar_datation, range_pix_correspondance, doppler, antenna_pointing_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d502b",
   "metadata": {},
   "source": [
    "The first parameter is the nickname of the sensor. It is necessary because we can define multiple sensors. The last argument is to say if the antenna is poiting right or left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af3fbdf",
   "metadata": {},
   "source": [
    "## 2 - Satellite position, velocity and attitude\n",
    "\n",
    "As input to Rugged, we will need to pass sufficient information to describe the position of the platform during the acquisition, for SAR images the attitude of the satellite as no importance that is why we will consider all quaternion nul. In our example, the list of positions and velocities are hard-coded. In real life, we would extract GPS data from the satellite auxiliary telemetry.\n",
    "\n",
    "Note that for simulation purpose, we could also use Orekit to simulate the orbit. It offers very convenient functions to propagate sun-synchronous orbits with yaw steering compensation (typical orbits for Earth Observation satellites)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b148a",
   "metadata": {},
   "source": [
    "### Reference frames\n",
    "\n",
    "In our application, we simply need to know the name of the frames we are working with. Positions (unit: m) and velocities (unit: m/s) are given in the ITRF terrestrial frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2e08e",
   "metadata": {},
   "source": [
    "### Satellite attitude\n",
    "\n",
    "As said before, for SAR image satellite attitude is not important that is why no quaternion needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da2c03",
   "metadata": {},
   "source": [
    "### Positions and velocities\n",
    "\n",
    "Positions and velocities will be set in a list of TimeStampedPVCoordinates expressed in ITRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b75976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_satellite_pv(satellite_pv_list, abs_date, p_x, p_y, p_z, v_x, v_y, v_z):\n",
    "    \"\"\"Add element to satellite_pv_list\"\"\"\n",
    "\n",
    "    date = AbsoluteDate(abs_date, TimeScalesFactory.getUTC())\n",
    "    position = Vector3D(p_x, p_y, p_z)\n",
    "    velocity = Vector3D(v_x, v_y, v_z)    \n",
    "    satellite_pv_list.append(TimeStampedPVCoordinates(date, position, velocity))\n",
    "\n",
    "\n",
    "satellite_pv_list = []\n",
    "\n",
    "add_satellite_pv(satellite_pv_list, \"2016-06-05T06:02:08.226323\", 4.730625771849658e+06, 7.802107170901060e+05, 5.324424000376088e+06, 5.664882718527716e+03, -1.104946622266712e+03, -4.859206922710340e+03)\n",
    "add_satellite_pv(satellite_pv_list, \"2016-06-05T06:02:10.196897\", 4.741778639440039e+06, 7.780301064799653e+05, 5.314837373988666e+06, 5.654523249054796e+03, -1.108225130750053e+03, -4.870570311536359e+03)\n",
    "add_satellite_pv(satellite_pv_list, \"2016-06-05T06:02:12.167472\", 4.752911074320325e+06, 7.758430417126168e+05, 5.305228370472910e+06, 5.644139150101179e+03, -1.111496038016211e+03, -4.881913263246337e+03)\n",
    "add_satellite_pv(satellite_pv_list, \"2016-06-05T06:02:14.138046\", 4.764023016689875e+06, 7.736495399943315e+05, 5.295597039874533e+06, 5.633730482873204e+03, -1.114759321316162e+03, -4.893235722740817e+03)\n",
    "add_satellite_pv(satellite_pv_list, \"2016-06-05T06:02:16.108620\", 4.775114423833228e+06, 7.714496152625930e+05, 5.285943417785262e+06, 5.623297282833151e+03, -1.118014960336563e+03, -4.904537643655130e+03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60300659",
   "metadata": {},
   "source": [
    "## 3 - PyRugged initialization\n",
    "\n",
    "`PyRugged` object contains platform (frame transform between spacecraft,inertial and body frame), instrument and body elements.\n",
    "As the Rugged top level object that will be used for all user interaction is quite involved and can be built in several different ways, a builder pattern approach has been adopted. The builder itself is configured by calling dedicated setters for each concept (Intersection algorithm, trajectory, …). As all these concepts can be chained together, the setters themselves implement the fluent interface pattern, which implies each setter returns the builder instance, and therefore another setter can be called directly.\n",
    "\n",
    "__Setters__\n",
    "\n",
    "\n",
    "- The `set_ellipsoid` setter defines the shape and orientation of the ellipsoid. We use simple predefined enumerates: `EllipsoidId.WGS84`, `InertialFrameId.EME2000`, but could also use a custom ellipsoid if needed.\n",
    "\n",
    "- The `set_time_span` setter is used to define the global time span of the search algorithms (direct and inverse location). Four parameters are used for this: `acquisition_start_date`, `acquisition_stop_date`, `t_step` (step at which the pre-computed frames transforms cache will be filled), `time_tolerance` (margin allowed for extrapolation during inverse location, in seconds. The `t_step` parameter is a key parameter to achieve good performances as frames transforms will be precomputed throughout the time span using this time step. These computation are costly because they involve Earth precession/nutation models to be evaluated. So the transformed are precomputed and cached instead of being recomputed for each pixel. However, if direct and inverse location are expected to be performed over a reduced time span (say a few tens of seconds), precomputing the transforms over half an orbit at one millisecond rate would be a waste of computing power. Typical values are therefore to restrict the time span as much as possible to properly cover the expected direct and inverse location calls, and to use a step between one millisecond and one second, depending on the required accuracy. The exact value to use is mission-dependent. The final `time_tolerance` parameter is simply a margin used before and after the final precomputed transforms to allow a slight extrapolation if during a search the interval is slightly overshoot. A typical value is to allow a few images lines so for example a 5 lines tolerance would imply computing the tolerance as: `time_tolerance = 5 / line_sensor.get_rate(0))`.\n",
    "\n",
    "- The `set_trajectory` setter defines the spacecraft evolution. The arguments are the list of time-stamped positions and velocities as well as the inertial frame with respect to which they are defined and options for interpolation: number of points to use and type of filter for derivatives. The interpolation polynomials for `nb_pv_points` without any derivatives (case of `CartesianDerivativesFilter.USE_P`: only positions are used, without velocities) have a degree `nb_pv_points - 1`. In case of computation with velocities included (case of `CartesianDerivativesFilter.USE_PV`), the interpolation polynomials have a degree `2 * nb_pv_points - 1`. If the positions/velocities data are of good quality and separated by a few seconds, one may choose only a few points but interpolate with both positions and velocities; in other cases, one may choose more points but interpolate only with positions. We find similar arguments for the attitude quaternions.\n",
    "\n",
    "__Sensors__\n",
    "\n",
    "The last setter used, `add_sensor`, registers a sensor (rather line_sensor or sar_sensor). As can be deduced from its prefix (add instead of set), it can be called several time to register several sensors that will all be available in the built Rugged instance. We have called the method only once here, so we will use only one sar sensor.\n",
    "\n",
    "__Building PyRugged instance__\n",
    "\n",
    "After the last setter has been called, we call the `build()` method which really build the `PyRugged` instance (and not a `PyRuggedBuilder` instance has the setter did).\n",
    "\n",
    "The various setters can be called in any order. The only important thing is that once a `PyRugged` instance has been created by calling the `build()` method, it is independent from the builder so later calls to setters will not change the build instance. In fact, it is possible to create a builder, then call its `build()` method to create a first `PyRugged` instance, and then to modify the builder configuration by calling again some of the setters and building a second `PyRugged` instance from the new configuration. This allows to perform comparisons between two different configurations in the same program and without having to recreate everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf6cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = PyRuggedBuilder()\n",
    "\n",
    "\n",
    "builder.set_ellipsoid(\n",
    "    new_ellipsoid = None,\n",
    "    ellipsoid_id = EllipsoidId.WGS84,\n",
    "    body_rotating_frame_id = BodyRotatingFrameId.ITRF,\n",
    ")\n",
    "\n",
    "builder.set_time_span(\n",
    "    AbsoluteDate(\"2016-06-05T06:02:08.226323\", TimeScalesFactory.getUTC()),\n",
    "    AbsoluteDate(\"2016-06-05T06:02:16.108620\", TimeScalesFactory.getUTC()),\n",
    "    0.01, 5.0\n",
    ")\n",
    "\n",
    "builder.set_trajectory(\n",
    "    satellite_pv_list,\n",
    "    5, CartesianDerivativesFilter.USE_PV\n",
    ")\n",
    "\n",
    "builder.add_sensor(sensor)\n",
    "\n",
    "rugged = builder.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab4670",
   "metadata": {},
   "source": [
    "## 5 - Direct location of a single pixel\n",
    "\n",
    "We now construct the SARLocation class to be able to locate our pixel on a altitude of 200m let's say\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ebfe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = ConstantElevationAlgorithm(200)\n",
    "sar_location = SARLocation(rugged, algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba57244",
   "metadata": {},
   "source": [
    "Finally everything is set to do some real work. Let’s try to locate a point on Earth for upper left point (first line, first pixel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f49f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude 1.80822026° latitude 49.30171247° altitude 200.00m\n"
     ]
    }
   ],
   "source": [
    "coord_image = [0, 0]\n",
    "direct_loc = sar_location.direct_location([0], [0], 'sar_sensor')\n",
    "\n",
    "print(\"longitude {:.8f}° latitude {:.8f}° altitude {:.2f}m\".format(np.degrees(direct_loc[0][0]), np.degrees(direct_loc[1][0]),direct_loc[2][0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
