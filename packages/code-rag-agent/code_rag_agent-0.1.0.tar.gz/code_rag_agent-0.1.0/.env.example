# Vector Store Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=your_index_name

# LLM Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Embedding Model (must match code-ingestion-service)
EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5

# Optional: LLM Model Selection
OPENAI_QUERY_MODEL=gpt-4o-mini  # For query translation (cheap)
OPENAI_ANSWER_MODEL=gpt-4o      # For answer generation (quality)

# Optional: Retrieval Configuration
RETRIEVAL_TOP_K=10
RETRIEVAL_MIN_SCORE=0.7