---
title: "Slurmã‚¸ãƒ§ãƒ–ç®¡ç†ã‚’æ¥½ã«ã™ã‚‹ã€Œsrunxã€"
emoji: "ğŸ‘»"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["python", "hpc", "slurm", "cli"]
published: true
---
## å•é¡Œï¼šSlurmã®ã‚¸ãƒ§ãƒ–ä¾å­˜é–¢ä¿‚ç®¡ç†ãŒé¢å€’ã™ãã‚‹

æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’HPCã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¸Šã§å®Ÿè¡Œã™ã‚‹éš›ã€Slurmã®ã‚¸ãƒ§ãƒ–ä¾å­˜é–¢ä¿‚ç®¡ç†ã§ä»¥ä¸‹ã®ã‚ˆã†ãªèª²é¡Œã«ç›´é¢ã—ã¦ã„ã¾ã›ã‚“ã‹ï¼Ÿ

```bash
# æ¯å›ã“ã‚“ãªæ„Ÿã˜ã§ä¾å­˜é–¢ä¿‚ã‚’æ‰‹å‹•ç®¡ç†...
$ sbatch preprocess.sh
Submitted batch job 12345

# ã‚¸ãƒ§ãƒ–IDã‚’ãƒ¡ãƒ¢ã—ã¦...
$ sbatch --dependency=afterok:12345 train.sh
Submitted batch job 12346

# ã¾ãŸæ‰‹å‹•ã§æ¬¡ã®ã‚¸ãƒ§ãƒ–ã‚’...
$ sbatch --dependency=afterok:12346 evaluate.sh
Submitted batch job 12347
```

å‰å‡¦ç†ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€è©•ä¾¡ã€ã•ã‚‰ã«ç´°ã‹ã„ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆSFTã€DPO...ï¼‰ãŒå¢—ãˆã‚‹ã¨ã€æ‰‹å‹•ã§ã®ç®¡ç†ã¯è¤‡é›‘ã•ã‚’å¢—ã—ã€ã‚¨ãƒ©ãƒ¼ã®å…ƒã«ã‚‚ãªã‚Šã¾ã™ã€‚

ã“ã®ç…©é›‘ã•ã‚’ä¸€æ°—ã«è§£æ±ºã™ã‚‹ãƒ„ãƒ¼ãƒ«ãŒ **srunx** ã§ã™ã€‚

## srunxã¨ã¯ï¼Ÿ

srunxã¯ã€Slurmã®è¤‡é›‘ãªã‚¸ãƒ§ãƒ–ä¾å­˜é–¢ä¿‚ã‚’ç°¡å˜ãªYAMLãƒ•ã‚¡ã‚¤ãƒ«ã§ç›´æ„Ÿçš„ã«ç®¡ç†ã§ãã‚‹CLIãƒ„ãƒ¼ãƒ«/Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã§ã™ã€‚

- **ç›´æ„Ÿçš„ãªYAMLã«ã‚ˆã‚‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©**
- **ä¾å­˜é–¢ä¿‚ã«åŸºã¥ãè‡ªå‹•ä¸¦åˆ—å®Ÿè¡Œ**
- **Slackã‚’ä½¿ã£ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ­»æ´»ç›£è¦–**

## srunxã®å§‹ã‚æ–¹

```bash
# uv
uv add srunx

# pypi
pip install srunx
```

## YAMLã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®šç¾©

srunxã®æœ€å¤§ã®ç‰¹å¾´ã¯ã€è¤‡é›‘ãªä¾å­˜é–¢ä¿‚ã‚’æŒã¤ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’YAMLã§ç›´æ„Ÿçš„ã«å®šç¾©ã§ãã‚‹ã“ã¨ã§ã™ã€‚

### åŸºæœ¬çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```yaml
name: ml_pipeline
jobs:
  - name: preprocess
    command: ["python", "preprocess.py", "--input", "raw_data.csv"]
    resources:
      nodes: 1
      memory_per_node: "16GB"
    environment:
      conda: pytorch_env

  - name: train
    command: ["python", "train.py", "--data", "processed_data.csv"]
    depends_on:
      - preprocess
    resources:
      nodes: 2
      gpus_per_node: 2
    environment:
      conda: pytorch_env

  - name: evaluate
    command: ["python", "evaluate.py", "--model", "trained_model.pt"]
    depends_on:
      - train
    resources:
      nodes: 1
    environment:
      venv: /home/user/xxx/.venv
```

ã“ã‚Œã§`preprocess â†’ train â†’ evaluate`ãŒç°¡æ½”ã«å®šç¾©ã•ã‚Œã¾ã™ã€‚

### ä¸¦åˆ—å®Ÿè¡Œã®å¨åŠ›

srunxã®æœ€å¤§ã®å¼·ã¿ã¯ã€ä¾å­˜é–¢ä¿‚ã‚’è‡ªå‹•è§£æã—ã¦ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚¸ãƒ§ãƒ–ã‚’åŒæ™‚å®Ÿè¡Œã—ã¦ãã‚Œã‚‹ã“ã¨ã§ã™ã€‚

```yaml
name: parallel_ml_pipeline
jobs:
  # åˆæœŸãƒ‡ãƒ¼ã‚¿æº–å‚™
  - name: job_a
    command: ["python", "download_data.py", "--dataset", "imagenet"]
    resources:
      nodes: 1
      memory_per_node: "8GB"
    environment:
      conda: ml_env

  # ä¸¦åˆ—å®Ÿè¡Œã•ã‚Œã‚‹2ã¤ã®ã‚¿ã‚¹ã‚¯
  - name: job_b1
    command: ["python", "preprocess.py", "--stage", "1"]
    depends_on:
      - job_a
    resources:
      nodes: 1
      memory_per_node: "16GB"
    environment:
      conda: ml_env

  - name: job_c
    command: ["python", "validate_data.py", "--check", "quality"]
    depends_on:
      - job_a
    resources:
      nodes: 1
    environment:
      conda: ml_env

  # B1ã®å¾Œã«å®Ÿè¡Œ
  - name: job_b2
    command: ["python", "feature_engineering.py"]
    depends_on:
      - job_b1
    resources:
      nodes: 2
      memory_per_node: "32GB"
    environment:
      conda: ml_env

  # B2ã¨Cã®ä¸¡æ–¹ãŒå®Œäº†ã—ã¦ã‹ã‚‰å®Ÿè¡Œ
  - name: job_d
    command: ["python", "train_model.py", "--final"]
    depends_on:
      - job_b2
      - job_c
    resources:
      nodes: 4
      gpus_per_node: 2
    environment:
      conda: pytorch_env
```

ã“ã®ä¸¦åˆ—å®Ÿè¡Œã®æµã‚Œã‚’ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–ã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š

```mermaid
graph TD
    A["Job A<br/>ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"]
    B1["Job B1<br/>å‰å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¸1"]
    B2["Job B2<br/>ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ç”Ÿæˆ"]
    C["Job C<br/>ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼"]
    D["Job D<br/>ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"]

    A --> B1
    A --> C
    B1 --> B2
    B2 --> D
    C --> D

    %% ã‚¹ã‚¿ã‚¤ãƒ«
    classDef initial fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef parallel fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef sequential fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef final fill:#fff3e0,stroke:#f57c00,stroke-width:2px

    class A initial
    class B1,C parallel
    class B2 sequential
    class D final
```

ã‚¸ãƒ§ãƒ–ã¯æº–å‚™ãŒæ•´ã„æ¬¡ç¬¬ã€å³åº§ã«å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®ç„¡é§„ã‚’æœ€å°é™ã«æŠ‘ãˆã¾ã™ã€‚ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¯ç´°ç²’åº¦ã®ä¾å­˜é–¢ä¿‚åˆ¶å¾¡ã‚’æä¾›ã—ã¾ã™ã€‚

- **Job A** å®Œäº†æ™‚ â†’ **Job B1** ã¨ **Job C** ãŒå³åº§ã«ä¸¦åˆ—ã«æŠ•å…¥ã•ã‚Œã‚‹
- **Job B1** å®Œäº†æ™‚ â†’ **Job C** ã®çŠ¶æ…‹ã«é–¢ä¿‚ãªã **Job B2** ãŒå³åº§ã«æŠ•å…¥ã•ã‚Œã‚‹
- **Job D** ã¯ **Job B2** ã¨ **Job C** ã®ä¸¡æ–¹ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿã—ã¦ã‹ã‚‰æŠ•å…¥ã•ã‚Œã‚‹

ã“ã®ä»•çµ„ã¿ã«ã‚ˆã‚Šã€æœ€å¤§é™ã®ä¸¦åˆ—åŒ–ã‚’å®Ÿç¾ã—ã€å…¨ä½“ã®å®Ÿè¡Œæ™‚é–“ã‚’å¤§å¹…ã«çŸ­ç¸®ã§ãã¾ã™ã€‚

## ãƒ¯ãƒ³ã‚³ãƒãƒ³ãƒ‰ã§ã®ç°¡å˜å®Ÿè¡Œ

```bash
$ srunx flow run ml_pipeline.yaml

ğŸš€ Starting Workflow test with 5 jobs
ğŸŒ‹ SUBMITTED    Job a
ğŸ‘€ MONITORING   Job a            (ID: 12232)
âœ… COMPLETED    Job a            (ID: 12232)

...

âœ… Workflow completed successfully!

   Workflow test Summary
â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ Job â”ƒ Status    â”ƒ ID    â”ƒ
â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ a   â”‚ COMPLETED â”‚ 12232 â”‚
â”‚ b1  â”‚ COMPLETED â”‚ 12233 â”‚
â”‚ c   â”‚ COMPLETED â”‚ 12234 â”‚
â”‚ b2  â”‚ COMPLETED â”‚ 12235 â”‚
â”‚ d   â”‚ COMPLETED â”‚ 12236 â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Slackã§ã®æ­»æ´»ç›£è¦–

Slackã‚’ä½¿ç”¨ã—ãŸç°¡å˜ãªæ­»æ´»ç›£è¦–æ©Ÿèƒ½ã‚‚ã‚ã‚Šã¾ã™ã€‚

```bash
export SLACK_WEBHOOK_URL=xxx # è‡ªåˆ†ã®Slackã®Webhook URLã‚’è¨­å®š

# Slacké€šçŸ¥ä»˜ãã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
srunx flow run ml_pipeline.yaml --slack
```

ã‚‚ã—ãã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ï¼š

```python
from srunx.callbacks import SlackCallback
from srunx.workflows import WorkflowRunner

slack_callback = SlackCallback(webhook_url="your_webhook_url")
runner = WorkflowRunner.from_yaml("workflow.yaml", callbacks=[slack_callback])
results = runner.run()
```

å®Ÿéš›ã®é€šçŸ¥ç”»é¢ï¼š

![Slacké€šçŸ¥ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ](/images/slack_screenshot.png =500x)

## ã¾ã¨ã‚

srunxã®YAMLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚Šï¼š

- **ä¾å­˜é–¢ä¿‚ãŒæ˜ç¢º**: è¦–è¦šçš„ã«ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒç†è§£ã§ãã‚‹
- **è‡ªå‹•ä¸¦åˆ—å®Ÿè¡Œ**: æ‰‹å‹•ç®¡ç†ä¸è¦ã§æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿè¡Œ
- **å†åˆ©ç”¨æ€§**: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ã„å›ã—å¯èƒ½
- **ã‚¨ãƒ©ãƒ¼å‰Šæ¸›**: æ‰‹å‹•ä¾å­˜é–¢ä¿‚ç®¡ç†ã®ãƒŸã‚¹ãŒãªããªã‚‹

srunxã‚’ä½¿ã†ã“ã¨ã§ã€Slurmã®ç…©é›‘ãªã‚¸ãƒ§ãƒ–ç®¡ç†ã‹ã‚‰è§£æ”¾ã•ã‚Œã¾ã™ã€‚ã‚¸ãƒ§ãƒ–ã®ä¾å­˜é–¢ä¿‚ãŒè¦–è¦šçš„ã«ç†è§£ã—ã‚„ã™ããªã‚Šã€æ‰‹å‹•ç®¡ç†ã§ç”Ÿã˜ã‚‹ãƒŸã‚¹ã‚’é˜²ãã¾ã™ã€‚ã¾ãŸã€ä¾å­˜é–¢ä¿‚ã‚’è‡ªå‹•ã§è§£æã—ã€æœ€å¤§é™ã®ä¸¦åˆ—åŒ–ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®åŠ¹ç‡åŒ–ã¨å…¨ä½“ã®å®Ÿè¡Œæ™‚é–“ã‚’åŠ‡çš„ã«çŸ­ç¸®ã§ãã¾ã™ã€‚

è¤‡é›‘ãªSLURMã‚¸ãƒ§ãƒ–ç®¡ç†ã«æ‚©ã‚“ã§ã„ã‚‹æ–¹ã¯ã€ãœã²è©¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼

ä»Šå›ç´¹ä»‹ã—ãŸãƒ¬ãƒã‚¸ãƒˆãƒª

https://github.com/ksterx/srunx
