{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hosting of Large Knowledge Graphs with Neo4j Community Edition.\n",
    "We provided 2 ways to host neo4j server\n",
    "1. From OneDrive zip\n",
    "    - Download the zipped server with data from OneDrive\n",
    "    - Unzip and run neo4j-server-{dataset-name}/bin/neo4j start to host the server\n",
    "2. From Source\n",
    "    - We provided Nodes, Edges, Texts csv files for you to generate embeddings and numeric id, building from source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From OneDrive \n",
    "You can simply download the zipped server from our one-drive [link](https://hkustconnect-my.sharepoint.com/:f:/g/personal/jbai_connect_ust_hk/EgJCqoU91KpAlSSOi6dzgccB6SCL4YBpsCyEtGiRBV4WNg): ATLAS Neo4j Server Zip. \n",
    "\n",
    "Unzip and run\n",
    "```shell\n",
    "run neo4j-server-{dataset-name}/bin/neo4j start\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build From Source\n",
    "\n",
    "This notebook demonstrates how to host and work with large knowledge graphs using Neo4j Community Edition.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. Download and install Neo4j Community Edition (CE) using the provided script:\n",
    "   - Run `cd neo4j_scripts` and `sh get_neo4j_cc.sh` which will:\n",
    "     - Download Neo4j CE\n",
    "     - Install required plugins (APOC, GDS)\n",
    "     - Configure ports and passwords\n",
    "     - Initialize the database\n",
    "\n",
    "Meanwhile, run `sh get_neo4j_pes2o.sh` and `sh get_neo4j_wiki.sh` as well\n",
    "\n",
    "2. Key Configuration Details:\n",
    "   - Default credentials:\n",
    "     - Username: neo4j\n",
    "     - Password: admin2024\n",
    "\n",
    "\n",
    "\n",
    "Copy the ```AutoschemaKG/neo4j_scripts/neo4j.conf``` file to the conf directory of the Neo4j server (```neo4j-server-dulce/conf```). Then, update the following settings as needed: 1.Set dbms.default_database to the desired dataset name, such as ```wiki-csv-json-text```, ```pes2o-csv-json-text```, or ```cc-csv-json-text```. \n",
    "\n",
    "2.Configure the Bolt, HTTP, and HTTPS connectors according to your requirements. If you want to run them together, you must set the port differently to avoid port confliction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "We use the admin import method to import data, which is the fastest way. Other methods are too slow for large graphs. You need to download the data from our one-drive [link](https://hkustconnect-my.sharepoint.com/:f:/g/personal/jbai_connect_ust_hk/EgJCqoU91KpAlSSOi6dzgccB6SCL4YBpsCyEtGiRBV4WNg): ATLAS Neo4j Dump. Please download all the zip files. You can run the `decompress_csv_files.sh` to decompress all the zips in parallel. decompress them to the ```decompressed``` directory. [Here](https://sushantag9.medium.com/download-data-from-onedrive-using-command-line-d27196a676d9) is the tutorial for downloading large files using onedrive. Suppose you have download the data into the following dir. You need to have enough disk to import the databases for these servers. \n",
    "\n",
    "Here is the space needed for the servers after import. Put the decompressed files into ```./import```\n",
    "```\n",
    "342G    ./neo4j-server-wiki\n",
    "907G    ./neo4j-server-cc\n",
    "249G    ./neo4j-server-pes2o\n",
    "2.3T    ./import \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can SKIP this part, which can takes several hours. We have also added the CSVs with numeric ids in the zips\n",
    "\n",
    "# We need to add numeric ids to these csv files before loading them into database.\n",
    "# We need to use this because we will use an externam faiss index. We do not use the built-in vector index in neo4j\n",
    "# because it cannot support billion level vectors well.\n",
    "\n",
    "from atlas_rag.kg_construction.utils.csv_processing.csv_add_numeric_id import add_csv_columns\n",
    "\n",
    "decompressed_dir = \"/data/jbai/autoschema_servers/import\" \n",
    "for filename_pattern in [\"cc_en\", \"en_simple_wiki_v0\", \"pes2o_abstract\"]:     \n",
    "    add_csv_columns(\n",
    "                node_csv=f\"{decompressed_dir}/triple_nodes_{filename_pattern}_from_json_without_emb.csv\",\n",
    "                edge_csv=f\"{decompressed_dir}/triple_edges_{filename_pattern}_from_json_without_emb_full_concept.csv\",\n",
    "                text_csv=f\"{decompressed_dir}/text_nodes_{filename_pattern}_from_json.csv\",\n",
    "                node_with_numeric_id=f\"{decompressed_dir}/triple_nodes_{filename_pattern}_from_json_without_emb_with_numeric_id.csv\",\n",
    "                edge_with_numeric_id=f\"{decompressed_dir}/triple_edges_{filename_pattern}_from_json_without_emb_full_concept_with_numeric_id.csv\",\n",
    "                text_with_numeric_id=f\"{decompressed_dir}/text_nodes_{filename_pattern}_from_json_with_numeric_id.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the wiki\n",
    "\n",
    "``` shell\n",
    "./neo4j-server-wiki/bin/neo4j-admin database import full wiki-csv-json-text \\\n",
    "    --nodes=./import/text_nodes_en_simple_wiki_v0_from_json_with_numeric_id.csv \\\n",
    "    ./import/triple_nodes_en_simple_wiki_v0_from_json_without_emb_with_numeric_id.csv \\\n",
    "    ./import/concept_nodes_en_simple_wiki_v0_from_json_without_emb.csv \\\n",
    "    --relationships=./import/text_edges_en_simple_wiki_v0_from_json.csv \\\n",
    "    ./import/triple_edges_en_simple_wiki_v0_from_json_without_emb_full_concept_with_numeric_id.csv \\\n",
    "    ./import/concept_edges_en_simple_wiki_v0_from_json_without_emb.csv \\\n",
    "    --overwrite-destination \\\n",
    "    --multiline-fields=true \\\n",
    "    --id-type=string \\\n",
    "    --verbose --skip-bad-relationships=true\n",
    "```\n",
    "\n",
    "For the pes2o\n",
    "``` shell\n",
    "\n",
    "./neo4j-server-pes2o/bin/neo4j-admin database import full pes2o-csv-json-text \\\n",
    "    --nodes=./import/text_nodes_pes2o_abstract_from_json_with_numeric_id.csv \\\n",
    "    ./import/triple_nodes_pes2o_abstract_from_json_without_emb_with_numeric_id.csv \\\n",
    "    ./import/concept_nodes_pes2o_abstract_from_json_without_emb.csv \\\n",
    "    --relationships=./import/text_edges_pes2o_abstract_from_json.csv  \\\n",
    "    ./import/triple_edges_pes2o_abstract_from_json_without_emb_full_concept_with_numeric_id.csv \\\n",
    "     ./import/concept_edges_pes2o_abstract_from_json_without_emb.csv  \\\n",
    "    --overwrite-destination \\\n",
    "    --multiline-fields=true \\\n",
    "    --verbose --skip-bad-relationships=true --bad-tolerance=100000\n",
    "```\n",
    "\n",
    "For the cc\n",
    "``` shell\n",
    "./neo4j-server-cc/bin/neo4j-admin database import full cc-csv-json-text \\\n",
    "    --nodes=./import/text_nodes_cc_en_from_json_with_numeric_id.csv \\\n",
    "    ./import/triple_nodes_cc_en_from_json_without_emb_with_numeric_id.csv \\\n",
    "    ./import/concept_nodes_cc_en_from_json_without_emb.csv \\\n",
    "    --relationships=./import/text_edges_cc_en_from_json.csv \\\n",
    "    ./import/triple_edges_cc_en_from_json_without_emb_full_concept_with_numeric_id.csv \\\n",
    "    ./import/concept_edges_cc_en_from_json_without_emb.csv\\\n",
    "    --overwrite-destination \\\n",
    "    --multiline-fields=true \\\n",
    "    --verbose --skip-bad-relationships=true\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATLAS RAG API hosting\n",
    "After hosting the neo4j server and obtaining the uri, user name and password of the neo4j database, you can proceed to host the ATLAS RAG API, with our provided package.\n",
    "\n",
    "For FastAPI, by passing different LargeKGConfig configurations and using different ports, you can host different RAG APIs.\n",
    "\n",
    "To host one, run:\n",
    "```shell\n",
    "python neo4j_api_host/atlas_api.py\n",
    "```\n",
    "\n",
    "You can modify the `keyword = 'cc_en'` to other keywords to host other two graphs with the correct pre-built corresponding faiss indeces: `node_index` and `text_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "base_url =\"http://0.0.0.0:10089/v1/\"\n",
    "client = OpenAI(api_key=\"EMPTY\", base_url=base_url)\n",
    "\n",
    "# knowledge graph en_simple_wiki_v0\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that answers questions based on the knowledge graph.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Question: Who is Alex Mercer?\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama\",\n",
    "    messages=message,\n",
    "    max_tokens=2048,\n",
    "    temperature=0.5,\n",
    "    extra_body = {\n",
    "        \"retriever_config\":{ # configure based on the size of your knowledge graph\n",
    "            \"topN\": 5,\n",
    "            \"number_of_source_nodes_per_ner\": 1,\n",
    "            \"sampling_area\": 10 \n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoschemakg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
