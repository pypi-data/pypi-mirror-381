# sage/libs/agents/planning/llm_planner.py
from __future__ import annotations

import json
import re
from typing import Any, Dict, List, Optional, Tuple

from sage.core.api.function.map_function import MapFunction

PlanStep = Dict[
    str, Any
]  # MCPé£æ ¼ï¼š{"type":"tool","name":"...","arguments":{...}} | {"type":"reply","text":"..."}


def _top_k_tools(
    user_query: str, tools: Dict[str, Dict[str, Any]], k: int = 6
) -> Dict[str, Dict[str, Any]]:
    """åŸºäº name/description çš„åŒ¹é…."""
    uq = user_query.lower()
    scored: List[Tuple[str, float]] = []
    for name, meta in tools.items():
        txt = (name + " " + str(meta.get("description", ""))).lower()
        score = 0.0
        for token in re.findall(r"[a-zA-Z0-9_]+", uq):
            if token in txt:
                score += 1.0
        if name.lower() in uq:
            score += 1.5
        scored.append((name, score))
    scored.sort(key=lambda x: x[1], reverse=True)
    keep = [n for n, s in scored[:k] if s > 0] or list(tools.keys())[
        : min(k, len(tools))
    ]
    return {n: tools[n] for n in keep}


def _build_prompt(
    profile_system_prompt: str, user_query: str, tools_subset: Dict[str, Dict[str, Any]]
) -> str:
    """
    æŠŠ Profile + ç”¨æˆ·é—®é¢˜ + å·¥å…·æ¸…å• æ‹¼æˆä¸€ä¸ªå¼ºçº¦æŸæç¤ºè¯ï¼Œåªå…è®¸è¾“å‡º JSONã€‚
    å·¥å…·æ¸…å•éœ€åŒ…å« MCP ä¸‰è¦ç´ ï¼šname/description/input_schema
    """
    tool_list = [
        {
            "name": name,
            "description": meta.get("description", ""),
            "input_schema": meta.get("input_schema", {}),
        }
        for name, meta in tools_subset.items()
    ]
    # åªè¾“å‡º JSONï¼Œä¸”å¿…é¡»æ˜¯æ•°ç»„
    return f"""<SYSTEM>
You are a planning module. Produce a plan as a JSON array of steps.
Each step is EITHER:
  1) A tool call: {{"type":"tool","name":"<tool_name>","arguments":{{...}}}}
  2) A final reply: {{"type":"reply","text":"..."}}

Rules:
- Always call at least one tool before replying when tools are provided.
- Use ONLY the provided tools (names & schemas below).
- Arguments MUST follow the JSON Schema of the selected tool.
- Return ONLY the JSON array. Do NOT include extra text, code fences, or explanations.
- Keep steps concise. Conclude with a reply step once done.

</SYSTEM>

<PROFILE>
{profile_system_prompt}
</PROFILE>

<USER_QUERY>
{user_query}
</USER_QUERY>

<AVAILABLE_TOOLS>
{json.dumps(tool_list, ensure_ascii=False)}
</AVAILABLE_TOOLS>

Output: JSON array only.
"""


def _strip_code_fences(text: str) -> str:
    t = text.strip()
    if t.startswith("```"):
        # ```json ... ``` or ``` ...
        t = t[3:]
        # å»æ‰è¯­è¨€æ ‡è®°
        if "\n" in t:
            t = t.split("\n", 1)[1]
        if t.endswith("```"):
            t = t[:-3]
    return t.strip()


def _coerce_json_array(text: str) -> Optional[List[Any]]:
    """
    å®¹é”™è§£æï¼šä¼˜å…ˆç›´æ¥ loadsï¼›å¤±è´¥æ—¶å°è¯•æˆªå–ç¬¬ä¸€ä¸ª '[' åˆ°æœ€åä¸€ä¸ª ']' ä¹‹é—´çš„å†…å®¹ã€‚
    """
    t = _strip_code_fences(text)

    # æ–¹æ³•1ï¼šç›´æ¥è§£æ
    try:
        data = json.loads(t)
        if isinstance(data, list):
            return data
    except Exception:
        pass

    # æ–¹æ³•2ï¼šå°è¯•åœ¨æ–‡æœ¬ä¸­æ•æ‰ä¸€ä¸ª JSON æ•°ç»„
    try:
        start = t.find("[")
        end = t.rfind("]")
        if start != -1 and end != -1 and end > start:
            snippet = t[start : end + 1]
            data = json.loads(snippet)
            if isinstance(data, list):
                return data
    except Exception:
        pass

    # æ–¹æ³•3ï¼šå°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– JSON
    try:
        import re

        json_pattern = r"\[(?:[^[\]]*|\[[^\]]*\])*\]"
        matches = re.findall(json_pattern, t, re.DOTALL)
        for match in matches:
            try:
                data = json.loads(match)
                if isinstance(data, list):
                    return data
            except Exception:
                continue
    except Exception:
        pass

    return None


def _validate_steps(
    steps: List[Dict[str, Any]], tools: Dict[str, Dict[str, Any]]
) -> List[PlanStep]:
    """
    è½»é‡æ ¡éªŒï¼šç»“æ„æ­£ç¡®æ€§ + å·¥å…·æ˜¯å¦å­˜åœ¨ + å¿…å¡«å‚æ•°æ˜¯å¦é½å…¨ï¼ˆåŸºäº schema.requiredï¼‰ã€‚
    ä¸é€šè¿‡æ—¶ï¼Œç›´æ¥è¿‡æ»¤æ‰é”™è¯¯æ­¥ï¼›
    """
    valid: List[PlanStep] = []
    for step in steps:
        if not isinstance(step, dict) or "type" not in step:
            continue

        if step["type"] == "reply":
            if isinstance(step.get("text"), str) and step["text"].strip():
                valid.append({"type": "reply", "text": step["text"].strip()})
            continue

        if step["type"] == "tool":
            name = step.get("name")
            args = step.get("arguments", {})
            if (
                not isinstance(name, str)
                or name not in tools
                or not isinstance(args, dict)
            ):
                continue

            # åŸºäº MCP input_schema çš„å¿…å¡«é¡¹æ£€æŸ¥
            schema = tools[name].get("input_schema") or {}
            req = schema.get("required") or []
            if all(k in args for k in req):
                valid.append({"type": "tool", "name": name, "arguments": args})
            # è‹¥ç¼ºå°‘å¿…å¡«å‚æ•°ï¼Œä¸¢å¼ƒè¯¥æ­¥ï¼ˆå¯æ‰©å±•ä¸ºâ€œè¡¥é½å‚æ•°â€çš„å¯¹è¯æ­¥éª¤ï¼‰
            continue
    # ä¿åº•ï¼šæ²¡æœ‰å¯æ‰§è¡Œæ­¥æ—¶ï¼ŒåŠ ä¸€ä¸ª reply
    if not valid:
        valid = [{"type": "reply", "text": "ï¼ˆè®¡åˆ’ä¸å¯ç”¨ï¼‰"}]
    return valid


class LLMPlanner(MapFunction):
    """
    ç”¨.rag.generator ä¸­çš„ Generatorï¼ˆOpenAIGenerator / HFGeneratorï¼‰äº§å‡º MCP é£æ ¼è®¡åˆ’ã€‚
    ç»Ÿä¸€æ¥å£ï¼šplan(profile_prompt, user_query, tools) -> List[PlanStep]
    """

    def __init__(
        self,
        generator,
        max_steps: int = 6,
        enable_repair: bool = True,
        topk_tools: int = 6,
    ):
        """
        :param generator: ä½ çš„ OpenAIGenerator æˆ– HFGenerator å®ä¾‹ï¼ˆå…·å¤‡ .execute([user_query, prompt])ï¼‰
        :param max_steps: è¿”å›çš„æœ€å¤§æ­¥éª¤æ•°
        :param enable_repair: å½“ JSON è§£æå¤±è´¥æ—¶ï¼Œæ˜¯å¦è‡ªåŠ¨ä¿®å¤ä¸€æ¬¡
        :param topk_tools: ä¼ ç»™æ¨¡å‹çš„å·¥å…·å­é›†å¤§å°ï¼ˆå‡å°æç¤ºé•¿åº¦ä¸è·‘åç‡ï¼‰
        """
        self.generator = generator
        self.max_steps = max_steps
        self.enable_repair = enable_repair
        self.topk_tools = topk_tools

    def _ask_llm(self, prompt: str, user_query: str) -> str:
        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": user_query},
        ]
        _, out = self.generator.execute([user_query, messages])
        return out

    def plan(
        self,
        profile_system_prompt: str,
        user_query: str,
        tools: Dict[str, Dict[str, Any]],
    ) -> List[PlanStep]:
        # 1) ç¼©å°å·¥å…·é›†åˆï¼Œå‡å°‘ä¸Šä¸‹æ–‡
        tools_subset = _top_k_tools(user_query, tools, k=self.topk_tools)

        # 2) é¦–æ¬¡è¯·æ±‚
        prompt = _build_prompt(profile_system_prompt, user_query, tools_subset)
        out = self._ask_llm(prompt, user_query)
        steps = _coerce_json_array(out)

        # è°ƒè¯•ä¿¡æ¯ï¼šè®°å½•åŸå§‹è¾“å‡º
        if steps is None:
            print(f"ğŸ› Debug: æ— æ³•è§£æè®¡åˆ’ JSONã€‚åŸå§‹è¾“å‡º:\n{out[:500]}...")

        # 3) è‡ªåŠ¨ä¿®å¤ï¼ˆä»…ä¸€æ¬¡ï¼‰
        if steps is None and self.enable_repair:
            repair_prompt = (
                "Your output was invalid. Return ONLY a JSON array of steps. No prose, no fences.\n"
                'Example: [{"type":"tool","name":"...","arguments":{...}}, {"type":"reply","text":"..."}]'
            )
            _, out2 = self.generator.execute(
                [user_query, repair_prompt + "\n\nPrevious output:\n" + out]
            )
            steps = _coerce_json_array(out2)

            # è°ƒè¯•ä¿¡æ¯ï¼šè®°å½•ä¿®å¤åçš„è¾“å‡º
            if steps is None:
                print(f"ğŸ› Debug: ä¿®å¤åä»æ— æ³•è§£æ JSONã€‚ä¿®å¤è¾“å‡º:\n{out2[:500]}...")

        # 4) å…œåº•ï¼šè‹¥ä»æ— æ³•è§£æï¼Œç›´æ¥æŠŠåŸæ–‡ä½œä¸º reply
        if steps is None:
            print("ğŸ› Debug: ä½¿ç”¨å…œåº•ç­–ç•¥ï¼Œè¿”å›åŸæ–‡ä½œä¸ºå›å¤")
            return [{"type": "reply", "text": out.strip()[:2000]}][: self.max_steps]

        # 5) è½»é‡åˆæ³•åŒ–ï¼ˆç»“æ„+å¿…å¡«å‚æ•°ï¼‰
        steps = _validate_steps(steps, tools_subset)

        # 6) æˆªæ–­å¹¶è¿”å›
        return steps[: self.max_steps]

    def _tools_to_manifest(self, tools_like: Any) -> Dict[str, Dict[str, Any]]:
        """
        æ”¯æŒï¼š
        - ç›´æ¥ä¼ å·¥å…·æ¸…å• dict[str, {description,input_schema}]
        - ä¼  MCPRegistry å®ä¾‹ï¼ˆå…·å¤‡ .describe()ï¼‰
        """
        if isinstance(tools_like, dict):
            return tools_like
        if hasattr(tools_like, "describe") and callable(
            getattr(tools_like, "describe")
        ):
            return tools_like.describe()
        raise TypeError(
            "LLMPlanner expects `tools` as a dict manifest or an object with .describe()."
        )

    def execute(self, data: Any) -> List[PlanStep]:
        """
        ç»Ÿä¸€å…¥å£ï¼Œæ”¯æŒä»¥ä¸‹è¾“å…¥å½¢æ€ï¼ˆä»»é€‰å…¶ä¸€ï¼‰ï¼š
        1) dictï¼š
           {
             "profile_prompt" | "profile_system_prompt": str,
             "user_query" | "query": str,
             "tools" | "registry": dict æˆ– å…·å¤‡ .describe() çš„å¯¹è±¡,
             # å¯é€‰ï¼š "topk": int    # ä»…æœ¬æ¬¡è°ƒç”¨çš„ä¸´æ—¶ top-k è¦†å†™
           }

        2) ä¸‰å…ƒç»„ï¼š(profile_prompt: str, user_query: str, tools_or_registry)

        è¿”å›ï¼šList[PlanStep]
        """
        # --- å½¢æ€ 1ï¼šdict ---
        if isinstance(data, dict):
            profile_prompt = data.get("profile_prompt") or data.get(
                "profile_system_prompt"
            )
            user_query = data.get("user_query") or data.get("query")
            tools_like = data.get("tools") or data.get("registry")
            if (
                not isinstance(profile_prompt, str)
                or not isinstance(user_query, str)
                or tools_like is None
            ):
                raise ValueError(
                    "LLMPlanner.execute(dict) requires 'profile_prompt' (or 'profile_system_prompt'), "
                    "'user_query' (or 'query'), and 'tools' (or 'registry')."
                )

            # ä¸´æ—¶ top-k è¦†å†™ï¼ˆä¸ä¿®æ”¹å®ä¾‹å­—æ®µï¼‰
            original_topk = self.topk_tools
            if "topk" in data:
                if not isinstance(data["topk"], int) or data["topk"] <= 0:
                    raise ValueError("'topk' must be a positive int.")
                self.topk_tools = data["topk"]

            try:
                tools_manifest = self._tools_to_manifest(tools_like)
                return self.plan(profile_prompt, user_query, tools_manifest)
            finally:
                # è¿˜åŸ
                self.topk_tools = original_topk

        # --- å½¢æ€ 2ï¼šä¸‰å…ƒç»„ ---
        if isinstance(data, tuple) and len(data) == 3:
            profile_prompt, user_query, tools_like = data
            if not isinstance(profile_prompt, str) or not isinstance(user_query, str):
                raise TypeError("Tuple form must be (str, str, tools_or_registry).")
            tools_manifest = self._tools_to_manifest(tools_like)
            return self.plan(profile_prompt, user_query, tools_manifest)

        raise TypeError(
            "LLMPlanner.execute expects either a dict with keys "
            "('profile_prompt'/'profile_system_prompt', 'user_query'/'query', 'tools'/'registry') "
            "or a tuple (profile_prompt, user_query, tools_or_registry)."
        )
