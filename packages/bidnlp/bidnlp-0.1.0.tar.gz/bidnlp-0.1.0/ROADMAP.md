# BidNLP Development Roadmap & Onboarding

**Persian (Farsi) Natural Language Processing Library**

Last Updated: 2025-10-02

---

## üìã Table of Contents

1. [Project Overview](#project-overview)
2. [Current Status](#current-status)
3. [Completed Modules](#completed-modules)
4. [Module Details](#module-details)
5. [Known Issues & Fixes](#known-issues--fixes)
6. [Next Steps](#next-steps)
7. [Development Notes](#development-notes)
8. [Testing](#testing)

---

## üéØ Project Overview

BidNLP is a comprehensive Persian (Farsi) NLP library designed to handle the unique challenges of Persian language processing, including:
- ZWNJ (zero-width non-joiner) handling
- Arabic to Persian normalization
- Compound words
- Mixed script text
- Complex morphology

### Project Structure

```
bidnlp/
‚îú‚îÄ‚îÄ bidnlp/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/       ‚úÖ COMPLETE
‚îÇ   ‚îú‚îÄ‚îÄ tokenization/        ‚úÖ COMPLETE
‚îÇ   ‚îú‚îÄ‚îÄ stemming/           ‚ö†Ô∏è PARTIAL (needs refinement)
‚îÇ   ‚îú‚îÄ‚îÄ lemmatization/      ‚ö†Ô∏è PARTIAL (needs refinement)
‚îÇ   ‚îú‚îÄ‚îÄ classification/     ‚ùå TODO
‚îÇ   ‚îî‚îÄ‚îÄ utils/              ‚ùå TODO
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/      ‚úÖ 58 tests passing
‚îÇ   ‚îú‚îÄ‚îÄ tokenization/       ‚úÖ 64 tests passing
‚îÇ   ‚îú‚îÄ‚îÄ stemming/          ‚ö†Ô∏è 7/14 tests passing
‚îÇ   ‚îî‚îÄ‚îÄ lemmatization/     ‚ö†Ô∏è 9/20 tests passing
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing_example.py  ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ tokenization_example.py   ‚úÖ
‚îú‚îÄ‚îÄ docs/                   ‚ùå TODO
‚îú‚îÄ‚îÄ setup.py               ‚úÖ
‚îî‚îÄ‚îÄ README.md              ‚úÖ
```

---

## ‚úÖ Current Status

### Fully Completed & Production-Ready Modules

#### 1. **Preprocessing Module** üü¢
- **Status**: 100% Complete
- **Tests**: 58/58 passing
- **Files**:
  - `bidnlp/preprocessing/normalizer.py`
  - `bidnlp/preprocessing/cleaner.py`
  - `bidnlp/preprocessing/number_normalizer.py`
  - `bidnlp/preprocessing/punctuation.py`

#### 2. **Tokenization Module** üü¢
- **Status**: 100% Complete
- **Tests**: 64/64 passing
- **Files**:
  - `bidnlp/tokenization/word_tokenizer.py`
  - `bidnlp/tokenization/sentence_tokenizer.py`
  - `bidnlp/tokenization/subword_tokenizer.py`

### Partially Complete Modules

#### 3. **Stemming Module** üü°
- **Status**: ~50% Complete
- **Tests**: 7/14 passing
- **Issues**:
  - Over-aggressive single-character suffix removal (€å, ÿØ, ŸÖ)
  - Some test expectations need updating
  - Works correctly for Arabic broken plurals (e.g., ÿ≥ÿ®ÿ≤€åÿ¨ÿßÿ™ ‚Üí ÿ≥ÿ®ÿ≤€å)

#### 4. **Lemmatization Module** üü°
- **Status**: ~45% Complete
- **Tests**: 9/20 passing
- **Issues**:
  - Verb lemmatization needs refinement
  - False positives in verb prefix detection
  - Some irregular forms need better handling

### Fully Complete Modules

#### 5. **Classification Module** üü¢
- **Status**: 100% Complete
- **Tests**: 46/46 passing
- **Files**:
  - `bidnlp/classification/base_classifier.py`
  - `bidnlp/classification/sentiment_analyzer.py`
  - `bidnlp/classification/keyword_classifier.py`
  - `bidnlp/classification/feature_extraction.py`

#### 6. **Utils Module** üü¢
- **Status**: 100% Complete
- **Tests**: 117/117 passing
- **Files**:
  - `bidnlp/utils/characters.py`
  - `bidnlp/utils/statistics.py`
  - `bidnlp/utils/stopwords.py`
  - `bidnlp/utils/validators.py`
  - `bidnlp/utils/metrics.py`

---

## üì¶ Completed Modules

### 1. Preprocessing Module

#### Components:

**PersianNormalizer**
- ‚úÖ Arabic to Persian character conversion (ŸÉ‚Üí⁄©, Ÿä‚Üí€å)
- ‚úÖ Arabic-Indic to Persian digits (Ÿ†‚Üí€∞)
- ‚úÖ Diacritic removal (ÿ™ÿ¥⁄©€åŸÑ)
- ‚úÖ Kashida removal (ŸÄ)
- ‚úÖ ZWNJ normalization
- ‚úÖ Whitespace normalization
- ‚úÖ Unicode normalization (NFKC)
- ‚úÖ Invisible character removal
- ‚úÖ Spacing around punctuation

**PersianTextCleaner**
- ‚úÖ URL removal/replacement
- ‚úÖ Email removal/replacement
- ‚úÖ Mention (@) handling
- ‚úÖ Hashtag (#) handling
- ‚úÖ HTML tag removal
- ‚úÖ Emoji removal/replacement
- ‚úÖ Special character removal
- ‚úÖ Punctuation removal
- ‚úÖ Number removal
- ‚úÖ Non-Persian text removal
- ‚úÖ Repeated character normalization

**PersianNumberNormalizer**
- ‚úÖ Persian ‚Üî English digit conversion
- ‚úÖ Arabic-Indic ‚Üî Persian conversion
- ‚úÖ Number word to digit (€å⁄© ‚Üí 1)
- ‚úÖ Digit to word (25 ‚Üí ÿ®€åÿ≥ÿ™ Ÿà ŸæŸÜÿ¨)
- ‚úÖ Phone number formatting
- ‚úÖ Currency normalization
- ‚úÖ Number extraction

**PersianDateNormalizer**
- ‚úÖ Jalali date normalization
- ‚úÖ Date format standardization
- ‚úÖ Month name mapping
- ‚úÖ Date extraction

**PersianPunctuationNormalizer**
- ‚úÖ Persian ‚Üî Latin punctuation
- ‚úÖ Quotation mark normalization
- ‚úÖ Spacing fixes
- ‚úÖ Ellipsis normalization
- ‚úÖ Duplicate removal

### 2. Tokenization Module

#### Components:

**PersianWordTokenizer**
- ‚úÖ ZWNJ-aware word tokenization
- ‚úÖ Compound word handling
- ‚úÖ Mixed script support (Persian/English/Numbers)
- ‚úÖ Punctuation separation
- ‚úÖ Position tracking
- ‚úÖ Token type detection
- ‚úÖ Decimal number preservation
- ‚úÖ Detokenization support

**PersianSentenceTokenizer**
- ‚úÖ Persian & Latin punctuation handling
- ‚úÖ Abbreviation detection
- ‚úÖ Decimal number awareness
- ‚úÖ Quotation support
- ‚úÖ Position tracking
- ‚úÖ Sentence counting

**PersianCharacterTokenizer**
- ‚úÖ Character-level tokenization
- ‚úÖ Diacritic handling

**PersianMorphemeTokenizer**
- ‚úÖ Prefix detection (ŸÖ€åÿå ŸÜŸÖ€åÿå ÿ®€åÿå etc.)
- ‚úÖ Suffix detection (Ÿáÿßÿå ÿ™ÿ±ÿå ÿ™ÿ±€åŸÜÿå etc.)
- ‚úÖ Morphological tagging
- ‚úÖ Stem extraction

**PersianSyllableTokenizer**
- ‚úÖ Syllable segmentation
- ‚úÖ Syllable counting

---

## üîç Module Details

### Preprocessing Usage

```python
from bidnlp.preprocessing import (
    PersianNormalizer,
    PersianTextCleaner,
    PersianNumberNormalizer
)

# Normalize text
normalizer = PersianNormalizer()
text = normalizer.normalize("ŸÉÿ™ÿßÿ® Ÿä⁄© ŸÖÿØÿ±ÿ≥ÿ©")
# Output: "⁄©ÿ™ÿßÿ® €å⁄© ŸÖÿØÿ±ÿ≥Ÿá"

# Clean text
cleaner = PersianTextCleaner(
    remove_urls=True,
    remove_emojis=True
)
clean_text = cleaner.clean("ÿ≥ŸÑÿßŸÖ üòä https://test.com")
# Output: "ÿ≥ŸÑÿßŸÖ"

# Normalize numbers
num_normalizer = PersianNumberNormalizer()
result = num_normalizer.normalize_digits("€±€≤€≥", 'english')
# Output: "123"
```

### Tokenization Usage

```python
from bidnlp.tokenization import (
    PersianWordTokenizer,
    PersianSentenceTokenizer,
    PersianMorphemeTokenizer
)

# Word tokenization
word_tokenizer = PersianWordTokenizer()
tokens = word_tokenizer.tokenize("ŸÖŸÜ ⁄©ÿ™ÿßÿ® ŸÖ€å‚ÄåÿÆŸàÿßŸÜŸÖ")
# Output: ['ŸÖŸÜ', '⁄©ÿ™ÿßÿ®', 'ŸÖ€å', 'ÿÆŸàÿßŸÜŸÖ']

# Sentence tokenization
sent_tokenizer = PersianSentenceTokenizer()
sentences = sent_tokenizer.tokenize("ÿ¨ŸÖŸÑŸá ÿßŸàŸÑ. ÿ¨ŸÖŸÑŸá ÿØŸàŸÖÿü")
# Output: ['ÿ¨ŸÖŸÑŸá ÿßŸàŸÑ.', 'ÿ¨ŸÖŸÑŸá ÿØŸàŸÖÿü']

# Morpheme analysis
morph_tokenizer = PersianMorphemeTokenizer()
morphemes = morph_tokenizer.tokenize_with_tags("ŸÖ€åÿ±ŸàŸÖ")
# Output: [('ŸÖ€å', 'PRES'), ('ÿ±Ÿà', 'STEM'), ('ŸÖ', 'POSS_1S')]
```

### Classification Usage

```python
from bidnlp.classification import (
    PersianSentimentAnalyzer,
    KeywordClassifier,
    TfidfVectorizer
)

# Sentiment analysis
analyzer = PersianSentimentAnalyzer()
sentiment = analyzer.predict("ÿß€åŸÜ ⁄©ÿ™ÿßÿ® ÿÆ€åŸÑ€å ÿÆŸàÿ® ÿßÿ≥ÿ™")
# Output: 'positive'

# Text classification
classifier = KeywordClassifier()
classifier.add_category('Ÿàÿ±ÿ≤ÿ¥', {'ŸÅŸàÿ™ÿ®ÿßŸÑ', 'ÿ®ÿßÿ≤€å⁄©ŸÜ', 'ÿ™€åŸÖ'})
category = classifier.predict("ÿ™€åŸÖ ŸÅŸàÿ™ÿ®ÿßŸÑ ÿ®ÿ±ÿØ")
# Output: 'Ÿàÿ±ÿ≤ÿ¥'

# Feature extraction
tfidf = TfidfVectorizer(max_features=100)
vectors = tfidf.fit_transform(documents)
```

### Utils Usage

```python
from bidnlp.utils import (
    PersianCharacters,
    PersianTextStatistics,
    PersianStopWords,
    PersianTextValidator,
    PersianTextMetrics
)

# Character utilities
chars = PersianCharacters()
is_persian = chars.is_persian_text("ÿ≥ŸÑÿßŸÖ ÿØŸÜ€åÿß")

# Statistics
stats = PersianTextStatistics()
statistics = stats.get_statistics("ŸÖŸÜ ÿ®Ÿá ÿØÿßŸÜÿ¥⁄ØÿßŸá ŸÖ€å‚Äåÿ±ŸàŸÖ")

# Stop words
stopwords = PersianStopWords()
filtered = stopwords.remove_stopwords("ŸÖŸÜ ÿßÿ≤ ÿØÿßŸÜÿ¥⁄ØÿßŸá ŸÖ€å ÿ±ŸàŸÖ")

# Validation
validator = PersianTextValidator()
quality = validator.get_quality_score("ÿ≥ŸÑÿßŸÖ ÿØŸÜ€åÿß")

# Metrics
metrics = PersianTextMetrics()
f1 = metrics.f1_score({'a', 'b'}, {'a', 'c'})
```

---

## ‚ö†Ô∏è Known Issues & Fixes

### Stemming/Lemmatization Issues

**Issue #1: Arabic Broken Plurals**
- **Problem**: ÿ≥ÿ®ÿ≤€åÿ¨ÿßÿ™ was stemming to ÿ≥ÿ®ÿ≤€åÿ¨ instead of ÿ≥ÿ®ÿ≤€å
- **Solution**: ‚úÖ FIXED
  - Added `arabic_broken_plurals` patterns
  - Moved broken plural handling before regular plural removal
  - Pattern: €åÿ¨ÿßÿ™ ‚Üí €å, ÿ¨ÿßÿ™ ‚Üí ''

**Issue #2: Over-aggressive Single Character Removal**
- **Problem**: Single letters like €å, ÿØ, ŸÖ were being removed too aggressively
- **Solution**: ‚úÖ PARTIALLY FIXED
  - Removed €å from verb_suffixes and adjectival_suffixes
  - Made 'Ÿá' removal more conservative (only for words > 4 chars)
  - **Still needs**: Context-aware suffix removal

**Issue #3: Verb Prefix False Positives**
- **Problem**: Words like ŸÖ€åŸàŸá being treated as verbs (ŸÖ€å + ŸàŸá)
- **Solution**: ‚úÖ FIXED
  - Added minimum stem length check (> 2 chars) after prefix removal
  - Prevents short words from being misidentified as verbs

**Issue #4: Test Failures**
- **Stemming**: 7 tests failing (mostly due to conservative suffix removal changes)
- **Lemmatization**: 11 tests failing (verb lemmatization needs work)
- **Action Needed**: Review test expectations vs actual behavior
  - Some may need test updates
  - Some need algorithm refinement

---

## üöÄ Next Steps

### Immediate Priorities

1. **Fix Stemming/Lemmatization Tests** (High Priority)
   - Review failing tests
   - Decide: update tests or fix algorithms
   - Document expected behavior
   - Consider adding confidence scores

2. **Improve Verb Handling** (High Priority)
   - Better irregular verb dictionary
   - More sophisticated verb stem recognition
   - Handle compound verbs (e.g., ÿ∫ÿ∞ÿß ÿÆŸàÿ±ÿØŸÜ)

3. **Add More Test Cases** (Medium Priority)
   - Real-world text examples
   - Edge cases
   - Performance benchmarks

### Future Development

4. **Classification Module** (Not Started)
   - Text classification framework
   - Sentiment analysis
   - Named Entity Recognition
   - Part-of-speech tagging

5. **Utils Module** (Not Started)
   - Common text utilities
   - Evaluation metrics
   - Data loaders
   - Visualization tools

6. **Documentation** (Low Priority)
   - API documentation
   - User guide
   - Examples and tutorials
   - Contributing guide

7. **Performance Optimization**
   - Caching for repeated operations
   - Parallel processing for batch operations
   - Memory optimization

8. **Additional Features**
   - Stop word removal
   - N-gram generation
   - Collocation detection
   - Text similarity

---

## üí° Development Notes

### Important Decisions Made

1. **ZWNJ Handling**:
   - Decided to normalize ZWNJ usage by default
   - Insert ZWNJ after prefixes (ŸÖ€åÿå ŸÜŸÖ€åÿå ÿ®€å)
   - Critical for Persian compound words

2. **Number Format**:
   - Support both Persian (€∞-€π) and English (0-9) digits
   - Default to English for internal processing
   - Allow user to specify output format

3. **Suffix Removal Strategy**:
   - Moved from aggressive to conservative
   - Prefer precision over recall
   - Added minimum stem length constraints

4. **Test Philosophy**:
   - Comprehensive test coverage
   - Real-world examples
   - Both positive and negative cases

### Code Style

- **Imports**: Use explicit imports
- **Docstrings**: Google style
- **Type Hints**: Used where beneficial
- **Error Handling**: Fail gracefully
- **Configuration**: Boolean flags for flexibility

### Persian-Specific Considerations

1. **Character Normalization**:
   - Always normalize Arabic ŸÉ‚Üí⁄©, Ÿä‚Üí€å
   - Handle both Arabic-Indic and Persian digits
   - Remove diacritics by default

2. **Word Boundaries**:
   - ZWNJ (‚Äå) creates visual word boundaries but semantic unity
   - Handle compound words carefully
   - Consider both forms with/without ZWNJ

3. **Morphology**:
   - Rich prefix/suffix system
   - Verb conjugation is complex
   - Irregular forms need dictionary lookup

---

## üß™ Testing

### Running Tests

```bash
# All tests
pytest tests/

# Specific module
pytest tests/preprocessing/ -v
pytest tests/tokenization/ -v
pytest tests/stemming/ -v
pytest tests/lemmatization/ -v

# Quiet mode
pytest tests/preprocessing/ -q

# With coverage
pytest tests/ --cov=bidnlp
```

### Current Test Status

| Module | Tests | Passing | Status |
|--------|-------|---------|--------|
| Preprocessing | 58 | 58 | ‚úÖ 100% |
| Tokenization | 64 | 64 | ‚úÖ 100% |
| Utils | 117 | 117 | ‚úÖ 100% |
| Classification | 46 | 46 | ‚úÖ 100% |
| Stemming | 14 | 7 | ‚ö†Ô∏è 50% |
| Lemmatization | 20 | 9 | ‚ö†Ô∏è 45% |
| **TOTAL** | **321** | **302** | **94.1%** |

### Running Examples

```bash
# Set PYTHONPATH
export PYTHONPATH=.

# Run examples
python3 examples/preprocessing_example.py
python3 examples/tokenization_example.py
python3 examples/utils_example.py
python3 examples/classification_example.py
```

---

## üìù Quick Reference

### Key Files to Know

**Configuration & Setup**:
- `setup.py` - Package configuration
- `README.md` - User-facing documentation
- `.gitignore` - Git ignore patterns

**Core Modules**:
- `bidnlp/preprocessing/normalizer.py` - Main text normalizer
- `bidnlp/tokenization/word_tokenizer.py` - Word tokenization
- `bidnlp/stemming/persian_stemmer.py` - Stemming logic
- `bidnlp/lemmatization/persian_lemmatizer.py` - Lemmatization logic

**Tests**:
- `tests/preprocessing/` - All preprocessing tests
- `tests/tokenization/` - All tokenization tests

**Examples**:
- `examples/preprocessing_example.py` - Comprehensive preprocessing demo
- `examples/tokenization_example.py` - Comprehensive tokenization demo

### Common Commands

```bash
# Run specific test
python -m pytest tests/stemming/test_persian_stemmer.py::TestPersianStemmer::test_arabic_broken_plurals -v

# Run with specific Python path
PYTHONPATH=. python3 script.py

# Check module import
python3 -c "from bidnlp.preprocessing import PersianNormalizer; print('OK')"
```

---

## üéì Key Learnings

### Persian NLP Challenges

1. **Arabic vs Persian Characters**: Many texts mix Arabic and Persian characters (ŸÉ vs ⁄©)
2. **ZWNJ Usage**: Critical for compound words, inconsistently used in text
3. **Number Systems**: Three systems in use (Persian, Arabic-Indic, English)
4. **Morphological Complexity**: Rich prefix/suffix system requires careful handling
5. **Irregular Forms**: Many common words have irregular plurals and conjugations

### Technical Decisions

1. **Regex Unicode Escapes**: Use variables for Unicode characters in regex replacements
   ```python
   zwnj = '\u200c'
   text = re.sub(pattern, r'\1' + zwnj + r'\2', text)
   ```

2. **Punctuation in Quotes**: Use Unicode escapes for fancy quotes
   ```python
   '\u201c': '\u201d'  # Instead of: '"': '"'
   ```

3. **Conservative Stemming**: Better to understem than overstem
   - Minimum stem length: 2
   - Remove 'Ÿá' only for words > 4 characters
   - Avoid single-letter suffix removal

---

## üìß Contact & Notes

**Project**: BidNLP - Persian NLP Library
**Language**: Python 3.7+
**License**: MIT
**Last Session**: 2025-10-02

### Session Summary

**Completed**:
1. ‚úÖ Full preprocessing module with 58 passing tests
2. ‚úÖ Full tokenization module with 64 passing tests
3. ‚úÖ Fixed Arabic broken plural handling in stemming/lemmatization
4. ‚úÖ Created comprehensive examples
5. ‚úÖ Documented all modules

**Partially Complete**:
1. ‚ö†Ô∏è Stemming module (needs test review)
2. ‚ö†Ô∏è Lemmatization module (needs verb handling improvement)

**Next Session Should Focus On**:
1. Review and fix failing stemming/lemmatization tests
2. Improve verb lemmatization logic
3. Add more real-world test cases
4. Consider starting classification module

---

*This roadmap is a living document. Update it as the project evolves.*
