# This file was auto-generated by Fern from our API Definition.

import typing

from .. import core
from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.model_public import ModelPublic
from ..types.model_result_public import ModelResultPublic
from .raw_client import AsyncRawModelsClient, RawModelsClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class ModelsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawModelsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawModelsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawModelsClient
        """
        return self._raw_client

    def info(self, model: str, *, request_options: typing.Optional[RequestOptions] = None) -> ModelPublic:
        """
        Retrieves a model's details.

        Parameters
        ----------
        model : str
            The model to get information for.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ModelPublic
            Successful Response

        Examples
        --------
        from conductorquantum import ConductorQuantum

        client = ConductorQuantum(
            token="YOUR_TOKEN",
        )
        client.models.info(
            model="coulomb-blockade-peak-detector-v1",
        )
        """
        _response = self._raw_client.info(model, request_options=request_options)
        return _response.data

    def list(
        self,
        *,
        skip: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.List[ModelPublic]:
        """
        Retrieves a list of available models.

        Parameters
        ----------
        skip : typing.Optional[int]
            The number of models to skip.

        limit : typing.Optional[int]
            The number of models to include.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[ModelPublic]
            Successful Response

        Examples
        --------
        from conductorquantum import ConductorQuantum

        client = ConductorQuantum(
            token="YOUR_TOKEN",
        )
        client.models.list(
            skip=1,
            limit=1,
        )
        """
        _response = self._raw_client.list(skip=skip, limit=limit, request_options=request_options)
        return _response.data

    def execute(
        self, *, model: str, data: core.File, request_options: typing.Optional[RequestOptions] = None
    ) -> ModelResultPublic:
        """
        Analyze your input data using the specified model. For more information about available models and their capabilities, see our [overview](/models/overview).

        Parameters
        ----------
        model : str
            The model to run.

        data : core.File
            See core.File for more documentation

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ModelResultPublic
            Successful Response

        Examples
        --------
        from conductorquantum import ConductorQuantum

        client = ConductorQuantum(
            token="YOUR_TOKEN",
        )
        client.models.execute(
            model="model",
        )
        """
        _response = self._raw_client.execute(model=model, data=data, request_options=request_options)
        return _response.data


class AsyncModelsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawModelsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawModelsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawModelsClient
        """
        return self._raw_client

    async def info(self, model: str, *, request_options: typing.Optional[RequestOptions] = None) -> ModelPublic:
        """
        Retrieves a model's details.

        Parameters
        ----------
        model : str
            The model to get information for.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ModelPublic
            Successful Response

        Examples
        --------
        import asyncio

        from conductorquantum import AsyncConductorQuantum

        client = AsyncConductorQuantum(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.models.info(
                model="coulomb-blockade-peak-detector-v1",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.info(model, request_options=request_options)
        return _response.data

    async def list(
        self,
        *,
        skip: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> typing.List[ModelPublic]:
        """
        Retrieves a list of available models.

        Parameters
        ----------
        skip : typing.Optional[int]
            The number of models to skip.

        limit : typing.Optional[int]
            The number of models to include.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[ModelPublic]
            Successful Response

        Examples
        --------
        import asyncio

        from conductorquantum import AsyncConductorQuantum

        client = AsyncConductorQuantum(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.models.list(
                skip=1,
                limit=1,
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.list(skip=skip, limit=limit, request_options=request_options)
        return _response.data

    async def execute(
        self, *, model: str, data: core.File, request_options: typing.Optional[RequestOptions] = None
    ) -> ModelResultPublic:
        """
        Analyze your input data using the specified model. For more information about available models and their capabilities, see our [overview](/models/overview).

        Parameters
        ----------
        model : str
            The model to run.

        data : core.File
            See core.File for more documentation

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        ModelResultPublic
            Successful Response

        Examples
        --------
        import asyncio

        from conductorquantum import AsyncConductorQuantum

        client = AsyncConductorQuantum(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.models.execute(
                model="model",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.execute(model=model, data=data, request_options=request_options)
        return _response.data
