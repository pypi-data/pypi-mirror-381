models:
  - name: fast
    provider: openai
    model: o4-mini
    temperature: 0
    max_tokens: 16384
  - name: default
    provider: openai
    model: gpt-4o
    temperature: 0
    max_tokens: 16384
  - name: thinking
    provider: openai
    model: o3
    temperature: 0
    max_tokens: 32768
    reasoning:
      effort: medium
      summary: detailed