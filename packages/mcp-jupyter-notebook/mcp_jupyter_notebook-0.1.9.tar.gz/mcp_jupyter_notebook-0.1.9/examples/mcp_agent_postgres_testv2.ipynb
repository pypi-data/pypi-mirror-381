{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0eac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from dapr_agents import OpenAIChatClient\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from dapr_agents.tool import AgentTool\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227adcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAIChatClient(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")\n",
    "\n",
    "def to_obj(x):\n",
    "    return json.loads(x) if isinstance(x, str) else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- MCP Jupyter server env (REMOTE) ----\n",
    "NOTEBOOK_NAME = f\"mcp_{uuid.uuid4().hex[:8]}.ipynb\"\n",
    "\n",
    "ENV = {\n",
    "    **os.environ,\n",
    "    \"MCP_JUPYTER_SESSION_MODE\": \"server\",\n",
    "    \"MCP_JUPYTER_BASE_URL\": os.getenv(\"JUPYTER_BASE_URL\"),\n",
    "    \"MCP_JUPYTER_TOKEN\": os.getenv(\"JUPYTER_TOKEN\"),\n",
    "    \"MCP_JUPYTER_KERNEL_NAME\": os.getenv(\"JUPYTER_KERNEL_NAME\", \"python3\"),\n",
    "    \"MCP_JUPYTER_NOTEBOOK_PATH\": os.getenv(\"JUPYTER_NOTEBOOK_PATH\", NOTEBOOK_NAME),\n",
    "    \"MCP_JUPYTER_TOOLSETS\": \"postgresql\",\n",
    "}\n",
    "\n",
    "# Adjust path to your MCP server entrypoint (where your server.py lives)\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"uvx\",\n",
    "    #args=[ \"mcp-jupyter-notebook\", \"--transport\", \"stdio\"],\n",
    "    args = [\"--refresh\", \"mcp-jupyter-notebook\", \"--transport\", \"stdio\"],\n",
    "    #args=[\n",
    "    #    \"--refresh\",\n",
    "    #    \"--from\",\n",
    "    #    \"../\",\n",
    "    #    \"mcp-jupyter-notebook\",\n",
    "    #    \"--transport\",\n",
    "    #    \"stdio\",\n",
    "    #],\n",
    "    env=ENV,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dab763",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with stdio_client(server_params) as (read, write):\n",
    "    async with ClientSession(read, write) as s:\n",
    "        await s.initialize()\n",
    "\n",
    "        # Discover tools\n",
    "        tools = await AgentTool.from_mcp_session(s)\n",
    "\n",
    "        from dapr_agents import Agent\n",
    "\n",
    "        notebook_agent = Agent(\n",
    "            name=\"Jupyter Notebook Orchestrator\",\n",
    "            role=\"A notebook co-pilot that drives analysis inside a persistent Jupyter session, with read-only access to a PostgreSQL database via MCP tools.\",\n",
    "            goal=(\n",
    "                \"Use the active Jupyter notebook to complete tasks end-to-end: \"\n",
    "                \"add clear markdown, execute Python code, and, when necessary, install Python packages. \"\n",
    "                \"Reuse the same live session (kernel + document) so work builds on previous cells. \"\n",
    "                \"When data is needed, discover Postgres schemas/tables first, then load results into DataFrames via the provided tools.\"\n",
    "            ),\n",
    "            instructions=[\n",
    "                # Session & ordering\n",
    "                \"You are driving a live Jupyter notebook (persistent kernel + document).\",\n",
    "                \"Cell order matters. Issue exactly ONE tool call at a time and wait for its result before the next.\",\n",
    "                \"Append new cells; do not rewrite or reorder existing cells unless explicitly asked.\",\n",
    "\n",
    "                # Notebook tools\n",
    "                \"Use `notebook.markdown.add(content)` for headings and short explanations.\",\n",
    "                \"Use `notebook.code.run(content)` to append and execute Python code cells.\",\n",
    "\n",
    "                # Packages\n",
    "                \"If an import fails, call `notebook.packages.add([pip_names])` once, then retry the import.\",\n",
    "                \"Package names are pip distributions (e.g., 'matplotlib', 'plotly', 'requests').\",\n",
    "\n",
    "                # PostgreSQL tools & workflow\n",
    "                \"Before querying data, inspect metadata using schema tools:\",\n",
    "                \"• `db.postgresql.schema.list_tables(schema_name=None, include_matviews=False)` to enumerate tables/views.\",\n",
    "                \"• `db.postgresql.schema.list_columns(schema_name, table)` to view a table's columns.\",\n",
    "                \"• `db.postgresql.schema.tree(limit_per_schema=100)` for a compact overview of schemas → tables.\",\n",
    "                \"Only when you actually need rows, call `db.postgresql.query.to_df(raw_sql, limit=50)`.\",\n",
    "                \"That tool creates a DataFrame in the kernel and returns `df_name`. Capture and reuse that exact variable name in subsequent `notebook.code.run` cells.\",\n",
    "                \"Prefer small, targeted SQL with an explicit LIMIT while exploring.\",\n",
    "                \"Never print or echo credentials/DSNs; do not read environment variables into the notebook output.\",\n",
    "\n",
    "                # Notebook hygiene\n",
    "                \"Before each task, add a short markdown heading describing what you'll do.\",\n",
    "                \"Keep code cells small and focused—one idea per cell.\",\n",
    "                \"When previewing data, show concise outputs (e.g., df.head(), shapes, key metrics).\",\n",
    "                \"For Matplotlib plots, include a title and axis labels; add a legend when helpful.\",\n",
    "\n",
    "                # Robustness\n",
    "                \"If an error occurs, add a brief markdown note explaining the fix, then run a corrected code cell.\",\n",
    "                \"Reuse variables and results created earlier; reference them directly rather than reloading the same data.\",\n",
    "\n",
    "                # Closure\n",
    "                \"End a logical section with a short markdown summary of what was produced and learned.\"\n",
    "            ],\n",
    "            llm=llm,\n",
    "            tools=tools,\n",
    "            max_iterations=20,\n",
    "        )\n",
    "\n",
    "        QUESTION = \"\"\"\n",
    "A command and control behavior was blocked on host `vnevado-win10r`, which indicated an active infection by malware that could replicate and receive commands from remote attackers. This malware was active, and precautionary measures should be taken to check for residual signs of infection. The process involved had the ID 1332 and ran the command `curl http://vectorsandarrows.com`.\n",
    "\n",
    "What is the IP address associated with the Manatee Tempest activity group detected in this security incident?\n",
    "\"\"\"\n",
    "        await notebook_agent.run(QUESTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9e7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp-jupyter-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
