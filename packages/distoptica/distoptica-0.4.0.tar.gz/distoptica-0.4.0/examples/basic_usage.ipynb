{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb7f461",
   "metadata": {},
   "source": [
    "# Basic usage of the ``distoptica`` library #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d9cd7",
   "metadata": {},
   "source": [
    "## A NOTE BEFORE STARTING ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880421e9",
   "metadata": {},
   "source": [
    "Since the ``distoptica`` git repository tracks this notebook under its original\n",
    "basename ``basic_usage.ipynb``, we recommend that you copy the original notebook\n",
    "and rename it to any other basename that is not one of the original basenames\n",
    "that appear in the ``<root>/examples`` directory before executing any of the\n",
    "notebook cells below, where ``<root>`` is the root of the ``distoptica``\n",
    "repository. This way you can explore the notebook by executing and modifying\n",
    "cells without changing the original notebook, which is being tracked by git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b0d90e",
   "metadata": {},
   "source": [
    "## Import necessary modules ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For general array handling.\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# For creating hyperspy signals.\n",
    "import hyperspy.signals\n",
    "import hyperspy.axes\n",
    "\n",
    "# For creating quiver plots.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# The library that is the subject of this demonstration.\n",
    "import distoptica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d0485-cf65-478b-80c4-d5d294879c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e667d633",
   "metadata": {},
   "source": [
    "## Introduction ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f2509",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how one can use each function and class in the\n",
    "``distoptica`` library.\n",
    "\n",
    "You can find the documentation for the ``distoptica`` library\n",
    "[here](https://mrfitzpa.github.io/distoptica/_autosummary/distoptica.html).  It \n",
    "is recommended that you consult the documentation of this library as you explore\n",
    "the notebook. Moreover, users should execute the cells in the order that they\n",
    "appear, i.e. from top to bottom, as some cells reference variables that are set\n",
    "in other cells above them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9445a5e-76d1-4957-8399-c8638ab57d0c",
   "metadata": {},
   "source": [
    "## Using the ``distoptica`` library ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00854bb7-f6da-4ce5-ae4a-acca6afdb39a",
   "metadata": {},
   "source": [
    "### Creating an undistorted image set ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee60edf-b5c9-4949-ab86-3387f6fae759",
   "metadata": {},
   "source": [
    "Let's create a 2D ``hyperspy`` signal that stores a set of undistorted images\n",
    "that we will distort then resample below, and then subsequently undistort then\n",
    "resample to recover approximately the original image set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3014642-198d-4c40-ae8b-22bc182bf962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_undistorted_image_set_signal():\n",
    "    kwargs = {\"data\": generate_undistorted_image_set_signal_data(), \n",
    "              \"metadata\": generate_undistorted_image_set_signal_metadata()}\n",
    "    undistorted_image_set_signal = hyperspy.signals.Signal2D(**kwargs)\n",
    "\n",
    "    axes = generate_undistorted_image_set_signal_axes()\n",
    "\n",
    "    for axis_idx, axis in enumerate(axes):\n",
    "        undistorted_image_set_signal.axes_manager[axis_idx].update_from(axis)\n",
    "        undistorted_image_set_signal.axes_manager[axis_idx].name = axis.name\n",
    "\n",
    "    return undistorted_image_set_signal\n",
    "\n",
    "\n",
    "\n",
    "def generate_undistorted_image_set_signal_data():\n",
    "    signal_data_shape = generate_undistorted_image_set_signal_data_shape()\n",
    "    Y_dim, X_dim, v_dim, h_dim = signal_data_shape\n",
    "\n",
    "    undistorted_image_supports = generate_undistorted_image_supports(h_dim, \n",
    "                                                                     v_dim)\n",
    "\n",
    "    metadata = \\\n",
    "        generate_undistorted_image_set_signal_metadata()\n",
    "    max_pixel_vals_of_channels_of_undistorted_image = \\\n",
    "        metadata[\"max_pixel_vals_of_channels_of_undistorted_image\"]\n",
    "\n",
    "    kwargs = {\"shape\": signal_data_shape, \"dtype\": \"float\"}\n",
    "    signal_data = np.zeros(**kwargs)\n",
    "\n",
    "    for X_idx in range(X_dim):\n",
    "        max_pixel_val_of_channel = \\\n",
    "            max_pixel_vals_of_channels_of_undistorted_image[X_idx]\n",
    "        signal_data[:, X_idx] = \\\n",
    "            (undistorted_image_supports[:, X_idx] * max_pixel_val_of_channel)\n",
    "\n",
    "    undistorted_image_set_signal_data = signal_data\n",
    "\n",
    "    return undistorted_image_set_signal_data\n",
    "\n",
    "\n",
    "\n",
    "def generate_undistorted_image_set_signal_data_shape():\n",
    "    undistorted_image_set_signal_data_shape = (3, 2, 140, 140)\n",
    "    \n",
    "    return undistorted_image_set_signal_data_shape\n",
    "\n",
    "\n",
    "\n",
    "def generate_undistorted_image_supports(h_dim, v_dim):\n",
    "    signal_data_shape = generate_undistorted_image_set_signal_data_shape()\n",
    "    Y_dim, X_dim, _, _ = signal_data_shape\n",
    "\n",
    "    metadata = \\\n",
    "        generate_undistorted_image_set_signal_metadata()\n",
    "    undistorted_disk_centers = \\\n",
    "        metadata[\"undistorted_disk_centers\"]\n",
    "    undistorted_disk_radius = \\\n",
    "        metadata[\"undistorted_disk_radius\"]\n",
    "\n",
    "    kwargs = {\"shape\": (Y_dim, X_dim, v_dim, h_dim), \"dtype\": \"bool\"}\n",
    "    undistorted_image_supports = np.zeros(**kwargs)\n",
    "\n",
    "    u_x, u_y = generate_coord_meshgrid(h_dim, v_dim)\n",
    "\n",
    "    for Y_idx in range(Y_dim):\n",
    "        for X_idx in range(X_dim):\n",
    "            u_x_c, u_y_c = undistorted_disk_centers[Y_idx]\n",
    "            u_xy = np.sqrt((u_x-u_x_c)**2 + (u_y-u_y_c)**2)\n",
    "            u_R = undistorted_disk_radius\n",
    "            undistorted_image_supports[Y_idx, X_idx] = (u_xy <= u_R)\n",
    "\n",
    "    return undistorted_image_supports\n",
    "\n",
    "\n",
    "\n",
    "def generate_coord_meshgrid(h_dim, v_dim):\n",
    "    m_range = np.arange(h_dim)\n",
    "    n_range = np.arange(v_dim)\n",
    "\n",
    "    horizontal_coords_of_meshgrid = \\\n",
    "        (m_range + 0.5) / m_range.size\n",
    "    vertical_coords_of_meshgrid = \\\n",
    "        1 - (n_range + 0.5) / n_range.size\n",
    "\n",
    "    pair_of_1d_coord_arrays = (horizontal_coords_of_meshgrid,\n",
    "                               vertical_coords_of_meshgrid)\n",
    "    coord_meshgrid = np.meshgrid(*pair_of_1d_coord_arrays,\n",
    "                                 indexing=\"xy\")\n",
    "\n",
    "    return coord_meshgrid\n",
    "\n",
    "\n",
    "\n",
    "def generate_undistorted_image_set_signal_metadata():\n",
    "    metadata = {\"General\": \\\n",
    "                {\"title\": \"Undistorted Image Set\"}, \n",
    "                \"Signal\": \\\n",
    "                dict(), \n",
    "                \"undistorted_disk_centers\": \\\n",
    "                generate_undistorted_disk_centers(),\n",
    "                \"undistorted_disk_radius\": \\\n",
    "                generate_undistorted_disk_radius(), \n",
    "                \"max_pixel_vals_of_channels_of_undistorted_image\": \\\n",
    "                generate_max_pixel_vals_of_channels_of_undistorted_image()}\n",
    "\n",
    "    undistorted_image_set_signal_metadata = metadata\n",
    "\n",
    "    return undistorted_image_set_signal_metadata\n",
    "\n",
    "\n",
    "\n",
    "def generate_undistorted_disk_centers():\n",
    "    undistorted_disk_centers = ((0.5, 0.7),\n",
    "                                (0.5, 0.5),\n",
    "                                (0.5, 0.3))\n",
    "\n",
    "    return undistorted_disk_centers\n",
    "\n",
    "\n",
    "\n",
    "def generate_undistorted_disk_radius():\n",
    "    undistorted_disk_radius = 1/6\n",
    "\n",
    "    return undistorted_disk_radius\n",
    "\n",
    "\n",
    "\n",
    "def generate_max_pixel_vals_of_channels_of_undistorted_image():\n",
    "    max_pixel_vals_of_channels_of_undistorted_image = (1, 3)\n",
    "\n",
    "    return max_pixel_vals_of_channels_of_undistorted_image\n",
    "\n",
    "\n",
    "\n",
    "def generate_undistorted_image_set_signal_axes():\n",
    "    signal_data_shape = generate_undistorted_image_set_signal_data_shape()\n",
    "    Y_dim, X_dim, v_dim, h_dim = signal_data_shape\n",
    "\n",
    "    d_h = 1/h_dim\n",
    "    d_v = -1/v_dim\n",
    "\n",
    "    axes_sizes = (X_dim, Y_dim, h_dim, v_dim)\n",
    "    axes_scales = (1, 1, d_h, d_v)\n",
    "    axes_offsets = (0, 0, 0.5*d_h, 1+0.5*d_v)\n",
    "    axes_names = (\"$X$\", \n",
    "                  \"$Y$\", \n",
    "                  \"fractional horizontal coordinate\", \n",
    "                  \"fractional vertical coordinate\")\n",
    "\n",
    "    axes = tuple()\n",
    "    for axis_idx, _ in enumerate(axes_names):\n",
    "        kwargs = {\"size\": axes_sizes[axis_idx],\n",
    "                  \"scale\": axes_scales[axis_idx],\n",
    "                  \"offset\": axes_offsets[axis_idx],\n",
    "                  \"name\": axes_names[axis_idx]}\n",
    "        axis = hyperspy.axes.UniformDataAxis(**kwargs)\n",
    "        axes += (axis,)\n",
    "\n",
    "    undistorted_image_set_signal_axes = axes\n",
    "\n",
    "    return undistorted_image_set_signal_axes\n",
    "\n",
    "\n",
    "\n",
    "undistorted_image_set_signal = generate_undistorted_image_set_signal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784e637-2e1f-4dd1-9ce9-ee3e9a75f01a",
   "metadata": {},
   "source": [
    "Let's visualize the undistorted image set that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d7181-ce52-4599-be93-e0009270f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"axes_off\": False, \n",
    "          \"scalebar\": False, \n",
    "          \"colorbar\": False, \n",
    "          \"gamma\": 1,\n",
    "          \"cmap\": \"jet\"}\n",
    "undistorted_image_set_signal.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f476b-b885-4853-af9b-bfc2696271f6",
   "metadata": {},
   "source": [
    "### Specifying the distortion model ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65fa489-5997-4043-b9ec-01d5998bcac8",
   "metadata": {},
   "source": [
    "In order to distort and/or undistort images, we need to specify a distortion\n",
    "model. This entails specifying several sets of parameters.\n",
    "\n",
    "First, we need to specify the coordinate transformation that maps fractional\n",
    "coordinates of an undistorted image to those of the corresponding distorted\n",
    "image of interest. See\n",
    "[here](https://mrfitzpa.github.io/distoptica/_autosummary/distoptica.CoordTransformParams.html)\n",
    "for a detailed description of the mathematical form of the coordinate\n",
    "transformation, and the parameters required to specify an instance of such a\n",
    "coordinate transformation. In short, we need to specify the distortion center,\n",
    "and four coefficient matrices: the radial cosine, the radial sine, the\n",
    "tangential cosine, and the tangential sine coefficient matrices. In this\n",
    "demonstration, we will chose coefficient matrices corresponding to a distortion\n",
    "field that is a combination of elliptical, quadratic radial, parabolic, and\n",
    "spiral distortion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f2a45-325f-472b-ad3c-68cc7bc5b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = (0.52, 0.49)\n",
    "\n",
    "quadratic_radial_distortion_amplitude = -0.4\n",
    "\n",
    "spiral_distortion_amplitude = 0.1\n",
    "\n",
    "amplitude = 0.07\n",
    "phase = 7*np.pi/8\n",
    "elliptical_distortion_vector = (amplitude*np.cos(2*phase).item(), \n",
    "                                amplitude*np.sin(2*phase).item())\n",
    "\n",
    "amplitude = 0.1\n",
    "phase = 4*np.pi/3\n",
    "parabolic_distortion_vector = (amplitude*np.cos(phase), \n",
    "                               amplitude*np.sin(phase))\n",
    "\n",
    "\n",
    "\n",
    "A_r_0_2 = quadratic_radial_distortion_amplitude\n",
    "A_r_1_1 = parabolic_distortion_vector[0]\n",
    "A_r_2_0 = elliptical_distortion_vector[0]\n",
    "\n",
    "radial_cosine_coefficient_matrix = ((0.00000, 0.00000, A_r_0_2),\n",
    "                                    (0.00000, A_r_1_1, 0.00000),\n",
    "                                    (A_r_2_0, 0.00000, 0.00000))\n",
    "\n",
    "\n",
    "\n",
    "B_r_0_1 = parabolic_distortion_vector[1]\n",
    "B_r_1_0 = elliptical_distortion_vector[1]\n",
    "\n",
    "radial_sine_coefficient_matrix = ((0.00000, B_r_0_1),\n",
    "                                  (B_r_1_0, 0.00000))\n",
    "\n",
    "\n",
    "    \n",
    "A_t_0_2 = spiral_distortion_amplitude\n",
    "A_t_1_1 = B_r_0_1 / 3\n",
    "A_t_2_0 = B_r_1_0\n",
    "\n",
    "tangential_cosine_coefficient_matrix = ((0.00000, 0.00000, A_t_0_2),\n",
    "                                        (0.00000, A_t_1_1, 0.00000),\n",
    "                                        (A_t_2_0, 0.00000, 0.00000))\n",
    "\n",
    "\n",
    "    \n",
    "B_t_0_1 = -A_r_1_1 / 3\n",
    "B_t_1_0 = -A_r_2_0\n",
    "\n",
    "tangential_sine_coefficient_matrix = ((0.00000, B_t_0_1),\n",
    "                                      (B_t_1_0, 0.00000))\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"center\": \\\n",
    "          center,\n",
    "          \"radial_cosine_coefficient_matrix\": \\\n",
    "          radial_cosine_coefficient_matrix,\n",
    "          \"radial_sine_coefficient_matrix\": \\\n",
    "          radial_sine_coefficient_matrix, \n",
    "          \"tangential_cosine_coefficient_matrix\": \\\n",
    "          tangential_cosine_coefficient_matrix,\n",
    "          \"tangential_sine_coefficient_matrix\": \\\n",
    "          tangential_sine_coefficient_matrix}\n",
    "coord_transform_params = distoptica.CoordTransformParams(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b60bc-6a12-4481-b382-6aa2cda2ae6b",
   "metadata": {},
   "source": [
    "Note that the class ``distoptica.CoordTransformParams`` is a subclass of\n",
    "``fancytypes.PreSerializableAndUpdatable``, meaning that it is a type that is\n",
    "pre-serializable, that can be constructed from a serializable representation,\n",
    "and that has an updatable subset of attributes. See\n",
    "[here](https://mrfitzpa.github.io/fancytypes/_autosummary/fancytypes.PreSerializableAndUpdatable.html)\n",
    "for a definition of pre-serialization, and the documentation for all the\n",
    "attributes and methods associated with the class\n",
    "``fancytypes.PreSerializableAndUpdatable``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db9e91b-26c1-4ecf-9551-f38f18942516",
   "metadata": {},
   "source": [
    "Next, we must specify the parameters of the least-squares algorithm to be used\n",
    "to calculate the right-inverse of the coordinate transformation. See\n",
    "[here](https://mrfitzpa.github.io/distoptica/_autosummary/distoptica.LeastSquaresAlgParams.html)\n",
    "for a discussion on the algorithm and a description of the algorithm's\n",
    "parameters. The values we use for the parameters below should work for most\n",
    "scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb5fbf-4a61-441c-8d7d-9621aec36cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"max_num_iterations\": 20,\n",
    "          \"initial_damping\": 1e-3,\n",
    "          \"factor_for_decreasing_damping\": 9,\n",
    "          \"factor_for_increasing_damping\": 11,\n",
    "          \"improvement_tol\": 0.1, \n",
    "          \"rel_err_tol\": 1e-2, \n",
    "          \"plateau_tol\": 1e-3, \n",
    "          \"plateau_patience\": 2, \n",
    "          \"skip_validation_and_conversion\": False}\n",
    "least_squares_alg_params = distoptica.LeastSquaresAlgParams(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1a8a7-3980-4b3e-9212-36d2320820b3",
   "metadata": {},
   "source": [
    "Note that the class ``distoptica.LeastSquaresAlgParams`` is also a subclass of\n",
    "``fancytypes.PreSerializableAndUpdatable``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7aaea3-03ac-4a0a-be52-b69177d8ec76",
   "metadata": {},
   "source": [
    "Next, we must specify the sampling grid dimensions, in units of pixels. Upon\n",
    "distorting or undistorting an image set, the transformed image set is resampled\n",
    "at a resolution determined by the sampling grid dimensions. See the summary\n",
    "documentation of the class ``distoptica.DistortionModel``\n",
    "[here](https://mrfitzpa.github.io/distoptica/_autosummary/distoptica.DistortionModel.html),\n",
    "wherein there is a full discussion on how image transformation, and subsequent\n",
    "resampling is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e6548-cba4-4103-9b2b-d74b5cf1cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_grid_dims_in_pixels = (200,  # Number of columns.\n",
    "                                200)  # Number of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc9380-15fd-4a74-8d76-2866d535fba6",
   "metadata": {},
   "source": [
    "And lastly, we specify the device to be used to perform computationally\n",
    "intensive calls to PyTorch functions and where to store attributes of the type\n",
    "``torch.Tensor``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7564a69-931c-46b3-8cc2-123fb855cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1113de8-d479-47a5-8fb2-a1d2e283dcee",
   "metadata": {},
   "source": [
    "Putting all the parameters together, we construct our distortion model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603ab06-0217-477b-952c-8c22035ea0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"coord_transform_params\": coord_transform_params,\n",
    "          \"sampling_grid_dims_in_pixels\": sampling_grid_dims_in_pixels,\n",
    "          \"device_name\": device_name,\n",
    "          \"least_squares_alg_params\": least_squares_alg_params}\n",
    "distortion_model = distoptica.DistortionModel(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c124d85-854d-4c26-a355-ca769a2bee02",
   "metadata": {},
   "source": [
    "Note that the class ``distoptica.DistortionModel`` is also a subclass of\n",
    "``fancytypes.PreSerializableAndUpdatable``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbebcb6b-d080-4d2a-bb27-841b388b3d51",
   "metadata": {},
   "source": [
    "One can check whether the distortion model is azimuthally symmetric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd09b2-a2a3-4790-a482-603df621b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion_model.is_azimuthally_symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659697b0-7dbf-4fb1-bd98-ed1ccd2fcd89",
   "metadata": {},
   "source": [
    "An example of a distortion model that is azimuthally symmetric is one that\n",
    "possesses only quadratic radial distortion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c4f3f-604c-48d0-90a8-4933bbc3d1d8",
   "metadata": {},
   "source": [
    "One can also check whether the distortion model is trivial, i.e. that the\n",
    "corresponding coordinate transformation is equivalent to the identity\n",
    "transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3005ddb-ef0d-4685-8177-7a9f1b377dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion_model.is_trivial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad709ed5-fb1d-445b-a602-cffde9c33266",
   "metadata": {},
   "source": [
    "One can also check whether the distortion model is \"standard\". We define a\n",
    "standard distortion model as one that possesses any combination of elliptical,\n",
    "quadratic radial, parabolic, and spiral distortion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b1809-b7ff-4c3a-a1fb-d8642443de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion_model.is_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f93f2-9953-433e-93f3-2167e5e60245",
   "metadata": {},
   "source": [
    "Evidently, the distortion model that we have constructed is standard. See\n",
    "[here](https://mrfitzpa.github.io/distoptica/_autosummary/distoptica.StandardCoordTransformParams.html)\n",
    "for a discussion on the mathematical form of the coordinate transformations that\n",
    "correspond to standard distortion models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c4941-da5d-4b30-ba9b-2eacf74d1f8c",
   "metadata": {},
   "source": [
    "Note that we can get the same information from the object\n",
    "``coord_transform_params``, which we used to construct the distortion model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b8ca7-c486-4fc6-858e-c098c0405be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_transform_params.is_corresponding_model_azimuthally_symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bc9a87-250e-4f8e-a8a9-86aa1863296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_transform_params.is_corresponding_model_trivial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8383e32d-b8ab-4e99-a82f-bdaa2b6e1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_transform_params.is_corresponding_model_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd6f93-5c10-4713-8bf8-4bfe8bcb8100",
   "metadata": {},
   "source": [
    "``distoptica`` offers a more convenient way to construct standard distortion\n",
    "models. First, we need to specify the \"standard\" coordinate transformation\n",
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805f265-f1bb-40ed-92ef-b0906f201bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = \\\n",
    "    {\"center\": \\\n",
    "     center,\n",
    "     \"quadratic_radial_distortion_amplitude\": \\\n",
    "     quadratic_radial_distortion_amplitude,\n",
    "     \"elliptical_distortion_vector\": \\\n",
    "     elliptical_distortion_vector,\n",
    "     \"spiral_distortion_amplitude\": \\\n",
    "     spiral_distortion_amplitude,\n",
    "     \"parabolic_distortion_vector\": \\\n",
    "     parabolic_distortion_vector}\n",
    "standard_coord_transform_params = \\\n",
    "    distoptica.StandardCoordTransformParams(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c816e8c-904b-44d3-8820-6604845027ca",
   "metadata": {},
   "source": [
    "Note that the class ``distoptica.StandardCoordTransformParams`` is also a\n",
    "subclass of ``fancytypes.PreSerializableAndUpdatable``. Moreover, using the\n",
    "instance of this class that we have just constructed, we can also determine\n",
    "whether the corresponding distortion model is azimuthally symmetric, and whether\n",
    "it is trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2400161-eab3-4cf2-bf42-772f4b52b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_coord_transform_params.is_corresponding_model_azimuthally_symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446af4d-960c-42b7-8809-96d3ca4d2605",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_coord_transform_params.is_corresponding_model_trivial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34926cd8-7715-44b0-aabb-61dfc2596105",
   "metadata": {},
   "source": [
    "After constructing the instance of the class\n",
    "``distoptica.StandardCoordTransformParams``, we can construct the same\n",
    "distortion model as before in a similar manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c33af-2f7e-4015-90f0-698b868c30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"coord_transform_params\": standard_coord_transform_params,\n",
    "          \"sampling_grid_dims_in_pixels\": sampling_grid_dims_in_pixels,\n",
    "          \"device_name\": device_name,\n",
    "          \"least_squares_alg_params\": least_squares_alg_params}\n",
    "distortion_model = distoptica.DistortionModel(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a5508-b7a3-480d-b2f4-273a87f39901",
   "metadata": {},
   "source": [
    "Alternatively, we can use the function\n",
    "``distoptica.generate_standard_distortion_model`` to construct the same\n",
    "distortion model as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a70f02-40bf-471e-9df1-647425e7bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"standard_coord_transform_params\": standard_coord_transform_params,\n",
    "          \"sampling_grid_dims_in_pixels\": sampling_grid_dims_in_pixels,\n",
    "          \"device_name\": device_name,\n",
    "          \"least_squares_alg_params\": least_squares_alg_params}\n",
    "distortion_model = distoptica.generate_standard_distortion_model(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d60759-0840-4cdf-a78e-a91e46663c76",
   "metadata": {},
   "source": [
    "As a side note, users can also convert\n",
    "``distoptica.StandardCoordTransformParams`` objects to\n",
    "``distoptica.CoordTransformParams`` objects as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e65d3-02ee-4938-86df-801996899fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = \\\n",
    "    {\"standard_coord_transform_params\": standard_coord_transform_params}\n",
    "coord_transform_params = \\\n",
    "    distoptica.from_standard_to_generic_coord_transform_params(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f63e01-6682-437d-9eb6-994be0ba5b0b",
   "metadata": {},
   "source": [
    "where ``standard_coord_transform_params`` and ``coord_transform_params`` specify\n",
    "the same coordinate transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534623ce-b9aa-4f66-b451-faba8b68dd8f",
   "metadata": {},
   "source": [
    "### Visualizing the convergence of the least-squares algorithm ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e7cc9-9d63-400e-9d0d-7cac2f1e14f0",
   "metadata": {},
   "source": [
    "The distortion model that we have just constructed, ``distortion_model``,\n",
    "samples the flow fields of both the corresponding coordinate transformation, and\n",
    "its right-inverse, and stores the sampled flow fields as attributes. Recall from\n",
    "the discussion above that a least-squares algorithm is employed to calculate the\n",
    "sampled right-inverse of the coordinate transformation, and thus the\n",
    "corresponding flow field as well. In general, the right-inverse of the\n",
    "coordinate transformation will not be necessarily well-defined for all points on\n",
    "the sampling grid, which means that the least-squares algorithm will not\n",
    "converge for such points. A map of the convergence is stored in the attribute\n",
    "``convergence_map_of_distorted_then_resampled_images``. Let's visualize this\n",
    "convergence map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda20eb-fe5e-4226-b826-2a12c20c6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_torch_tensor_to_signal(torch_tensor, title):\n",
    "    numpy_array = torch_tensor.detach().numpy()\n",
    "\n",
    "    metadata = {\"General\": {\"title\": title}, \"Signal\": dict()}\n",
    "    \n",
    "    kwargs = {\"data\": numpy_array, \"metadata\": metadata}\n",
    "    signal = hyperspy.signals.Signal2D(**kwargs)\n",
    "\n",
    "    num_axes = len(numpy_array.shape)\n",
    "    \n",
    "    v_dim, h_dim = numpy_array.shape[-2:]\n",
    "\n",
    "    d_h = 1/h_dim\n",
    "    d_v = -1/v_dim\n",
    "\n",
    "    axes_sizes = (h_dim, v_dim)\n",
    "    axes_scales = (d_h, d_v)\n",
    "    axes_offsets = (0.5*d_h, 1+0.5*d_v)\n",
    "    axes_names = (\"fractional horizontal coordinate\", \n",
    "                  \"fractional vertical coordinate\")\n",
    "\n",
    "    if num_axes == 4:\n",
    "        Y_dim, X_dim = numpy_array.shape[:2]\n",
    "        axes_sizes = (X_dim, Y_dim) + axes_sizes\n",
    "        axes_scales = (1, 1) + axes_scales\n",
    "        axes_offsets = (0, 0) + axes_offsets\n",
    "        axes_names = (\"$X$\", \"$Y$\") + axes_names\n",
    "\n",
    "    for axis_idx in range(num_axes):\n",
    "        signal.axes_manager[axis_idx].size = axes_sizes[axis_idx]\n",
    "        signal.axes_manager[axis_idx].scale = axes_scales[axis_idx]\n",
    "        signal.axes_manager[axis_idx].offset = axes_offsets[axis_idx]\n",
    "        signal.axes_manager[axis_idx].name = axes_names[axis_idx]\n",
    "\n",
    "    return signal\n",
    "\n",
    "\n",
    "\n",
    "attr_name = \"convergence_map_of_distorted_then_resampled_images\"\n",
    "convergence_map = getattr(distortion_model, attr_name)\n",
    "\n",
    "kwargs = {\"torch_tensor\": convergence_map, \n",
    "          \"title\": \"Convergence Map Of Distorted Then Resampled Images\"}\n",
    "convergence_map_signal = convert_torch_tensor_to_signal(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"axes_off\": False, \n",
    "          \"scalebar\": False, \n",
    "          \"colorbar\": False, \n",
    "          \"gamma\": 1,\n",
    "          \"cmap\": \"jet\"}\n",
    "convergence_map_signal.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd1459-3db5-4cd3-9dd2-93ef7a3002a3",
   "metadata": {},
   "source": [
    "From this convergence map, we can conclude that either the calculation of the\n",
    "flow field of the right-inverse of the coordinate transformation is not\n",
    "accurate, or that the right-inverse is not well-defined, at the sampling points\n",
    "in the blue regions. For the flow field of the right-inverse of the coordinate\n",
    "transformation, or for images that have been distorted according to the\n",
    "distortion model, users may want to mask the pixels corresponding to the blue\n",
    "regions prior to performing any subsequent operations on said flow fields or\n",
    "distorted images. Alternatively, if users prefer to use a rectangular mask,\n",
    "distortion models also store as an attribute the specifications of the minimum\n",
    "frame to mask all boolean values of ``False`` in the aforementioned convergence\n",
    "map. The specifications of this mask frame are stored in the attribute\n",
    "``mask_frame_of_distorted_then_resampled_images``. Let's visualize the mask\n",
    "frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7cc50-a622-4c9e-bb77-9e0efe635701",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_name = \"mask_frame_of_distorted_then_resampled_images\"\n",
    "mask_frame = getattr(distortion_model, attr_name)\n",
    "\n",
    "L = mask_frame[0]  # Width in units of pixels of left side of mask frame.\n",
    "R = mask_frame[1]  # Width in units of pixels of right side of mask frame.\n",
    "B = mask_frame[2]  # Width in units of pixels of bottom side of mask frame.\n",
    "T = mask_frame[3]  # Width in units of pixels of top side of mask frame.\n",
    "\n",
    "v_dim, h_dim = convergence_map.shape\n",
    "\n",
    "mask = torch.ones_like(convergence_map)\n",
    "mask[:T, :] = 0\n",
    "mask[v_dim-B:, :] = 0\n",
    "mask[:, :L] = 0\n",
    "mask[:, h_dim-R:] = 0\n",
    "\n",
    "kwargs = {\"torch_tensor\": mask, \n",
    "          \"title\": \"Mask Frame Of Distorted Then Resampled Images\"}\n",
    "mask_signal = convert_torch_tensor_to_signal(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"torch_tensor\": 1.0*mask+1.0*convergence_map, \n",
    "          \"title\": \"Mask Frame + Convergence Map\"}\n",
    "mask_plus_convergence_map_signal = convert_torch_tensor_to_signal(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"axes_off\": False, \n",
    "          \"scalebar\": False, \n",
    "          \"colorbar\": False, \n",
    "          \"gamma\": 1,\n",
    "          \"cmap\": \"jet\"}\n",
    "mask_signal.plot(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"axes_off\": False, \n",
    "          \"scalebar\": False, \n",
    "          \"colorbar\": False, \n",
    "          \"gamma\": 1,\n",
    "          \"cmap\": \"jet\"}\n",
    "mask_plus_convergence_map_signal.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8a2f2-f9e6-4f6b-9f0a-2951ce3e1eea",
   "metadata": {},
   "source": [
    "### Visualizing the flow fields ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097d649-539f-414a-b68f-121d896439b4",
   "metadata": {},
   "source": [
    "Let's now visualize the flow fields of both the coordinate transformation, and\n",
    "its right-inverse, however let's visualize only the flow field vectors at every\n",
    "8th row and column of the sampling grid. To visualize the flow fields, we make\n",
    "use of the attributes ``sampling_grid``, ``flow_field_of_coord_transform``, and\n",
    "``flow_field_of_coord_transform_right_inverse``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c2525-a2dc-47e5-859d-89a93cb7a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_step = 8\n",
    "\n",
    "\n",
    "\n",
    "quiver_kwargs = {\"angles\": \"uv\",\n",
    "                 \"pivot\": \"middle\",\n",
    "                 \"scale_units\": \"width\"}\n",
    "\n",
    "\n",
    "\n",
    "attr_name = \"sampling_grid\"\n",
    "sampling_grid = getattr(distortion_model, attr_name)\n",
    "sampling_grid = (sampling_grid[0].numpy(), sampling_grid[1].numpy())\n",
    "\n",
    "X = sampling_grid[0][::slice_step, ::slice_step]\n",
    "Y = sampling_grid[1][::slice_step, ::slice_step]\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "attr_name = \"flow_field_of_coord_transform\"\n",
    "flow_field = getattr(distortion_model, attr_name)\n",
    "flow_field = (flow_field[0].numpy(), flow_field[1].numpy())\n",
    "\n",
    "U = flow_field[0][::slice_step, ::slice_step]\n",
    "V = flow_field[1][::slice_step, ::slice_step]\n",
    "\n",
    "kwargs = quiver_kwargs\n",
    "ax.quiver(X, Y, U, V, **kwargs)\n",
    "ax.set_title(\"Flow Field Of Coordinate Transformation\")\n",
    "ax.set_xlabel(\"fractional horizontal coordinate\")\n",
    "ax.set_ylabel(\"fractional vertical coordinate\")\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "attr_name = \"flow_field_of_coord_transform_right_inverse\"\n",
    "flow_field = getattr(distortion_model, attr_name)\n",
    "flow_field = (flow_field[0].numpy(), flow_field[1].numpy())\n",
    "\n",
    "U = flow_field[0][::slice_step, ::slice_step]\n",
    "V = flow_field[1][::slice_step, ::slice_step]\n",
    "\n",
    "kwargs = quiver_kwargs\n",
    "ax.quiver(X, Y, U, V, **kwargs)\n",
    "ax.set_title(\"Flow Field Of Right-Inverse Of Coordinate Transformation\")\n",
    "ax.set_xlabel(\"fractional horizontal coordinate\")\n",
    "ax.set_ylabel(\"fractional vertical coordinate\")\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca195455-e50b-45c8-bfa8-868ae6e0f27b",
   "metadata": {},
   "source": [
    "### Distorting then resampling images ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b1b28a-7ac8-4d23-8c8e-90241e437904",
   "metadata": {},
   "source": [
    "Now let's distort then resample our original undistorted image set using the\n",
    "method ``distort_then_resample_images``. See\n",
    "[here](https://mrfitzpa.github.io/distoptica/_autosummary/distoptica.DistortionModel.html#distoptica.DistortionModel.distort_then_resample_images)\n",
    "for a full discussion on the expected input and the resulting output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70c70c-3417-4130-93c9-a22ca45aefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_alias = distortion_model.distort_then_resample_images\n",
    "kwargs = {\"undistorted_images\": undistorted_image_set_signal.data}\n",
    "distorted_then_resampled_image_set = method_alias(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42393096-f4d7-4e41-b806-179fea389bd6",
   "metadata": {},
   "source": [
    "Let's visualize the distorted then resampled image set that we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f60789-4c54-4de0-92e9-20f6bcfacd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_alias = convert_torch_tensor_to_signal\n",
    "kwargs = {\"torch_tensor\": distorted_then_resampled_image_set, \n",
    "          \"title\": \"Distorted Then Resampled Image Set\"}\n",
    "distorted_then_resampled_image_set_signal = func_alias(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"axes_off\": False, \n",
    "          \"scalebar\": False, \n",
    "          \"colorbar\": False, \n",
    "          \"gamma\": 1,\n",
    "          \"cmap\": \"jet\"}\n",
    "distorted_then_resampled_image_set_signal.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a53911-d9f5-4051-b2a7-158d46ebfafd",
   "metadata": {},
   "source": [
    "One can also visualize the out-of-bounds map of distorted then resampled images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a8cc8-48b3-4c66-9347-72aa80f96ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_bounds_map = \\\n",
    "    distortion_model.out_of_bounds_map_of_distorted_then_resampled_images\n",
    "\n",
    "func_alias = convert_torch_tensor_to_signal\n",
    "kwargs = {\"torch_tensor\": out_of_bounds_map, \n",
    "          \"title\": \"Out-Of-Bounds Map Of Distorted Then Resampled Images\"}\n",
    "out_of_bounds_map_signal = func_alias(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"axes_off\": False, \n",
    "          \"scalebar\": False, \n",
    "          \"colorbar\": False, \n",
    "          \"gamma\": 1,\n",
    "          \"cmap\": \"jet\"}\n",
    "out_of_bounds_map_signal.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b59859-9fae-4a20-9b90-03e743c872a5",
   "metadata": {},
   "source": [
    "### Undistorting then resampling images ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f401d7-a7b9-48e5-b87f-d6d5aa13a221",
   "metadata": {},
   "source": [
    "Let's undistort the distorted image set that we created above using the method\n",
    "``undistort_then_resample_images``. See\n",
    "[here](https://mrfitzpa.github.io/distoptica/_autosummary/distoptica.DistortionModel.html#distoptica.DistortionModel.undistort_then_resample_images)\n",
    "for a full discussion on the expected input and the resulting output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ff345-1b19-4dc9-aa47-25e2aedfcd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_alias = distortion_model.undistort_then_resample_images\n",
    "kwargs = {\"distorted_images\": distorted_then_resampled_image_set_signal.data}\n",
    "distortion_corrected_image_set = method_alias(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33016c7a-7900-4809-8ec8-a63eeb87107e",
   "metadata": {},
   "source": [
    "Let's visualize the distortion-corrected image set and juxtapose it to the\n",
    "original undistorted image set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe9512-41a1-4ea0-8d13-55cf1ff608f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_alias = convert_torch_tensor_to_signal\n",
    "kwargs = {\"torch_tensor\": distortion_corrected_image_set, \n",
    "          \"title\": \"Distortion-Corrected Image Set\"}\n",
    "distortion_corrected_image_set_signal = func_alias(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"axes_off\": False, \n",
    "          \"scalebar\": False, \n",
    "          \"colorbar\": False, \n",
    "          \"gamma\": 1,\n",
    "          \"cmap\": \"jet\"}\n",
    "distortion_corrected_image_set_signal.plot(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"axes_off\": False, \n",
    "          \"scalebar\": False, \n",
    "          \"colorbar\": False, \n",
    "          \"gamma\": 1,\n",
    "          \"cmap\": \"jet\"}\n",
    "undistorted_image_set_signal.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e2b99-ddbc-42f8-acd7-d0c8db815973",
   "metadata": {},
   "source": [
    "Note that the pixel values are different between the signals because the first\n",
    "signal is a result of resampling, i.e. it contains more pixels. For each image\n",
    "in the first signal, the sum of all pixels is approximately equal to that in the\n",
    "corresponding image in the second signal, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54933a27-2a6c-4e7a-9d1b-9cc09e50f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pixel sums in first signal:\")\n",
    "print(distortion_corrected_image_set_signal.data.sum(axis=(2, 3)))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Pixel sums in second signal:\")\n",
    "print(undistorted_image_set_signal.data.sum(axis=(2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6198751f-34fd-4a4c-bb4b-cca79e4d546c",
   "metadata": {},
   "source": [
    "Lastly, let's visualize the out-of-bounds map of undistorted then resampled\n",
    "images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899f52d-ca12-4f75-9b2c-b36e2b2ba579",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_bounds_map = \\\n",
    "    distortion_model.out_of_bounds_map_of_undistorted_then_resampled_images\n",
    "\n",
    "func_alias = convert_torch_tensor_to_signal\n",
    "kwargs = {\"torch_tensor\": out_of_bounds_map, \n",
    "          \"title\": \"Out-Of-Bounds Map Of Undistorted Then Resampled Images\"}\n",
    "out_of_bounds_map_signal = func_alias(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {\"axes_off\": False, \n",
    "          \"scalebar\": False, \n",
    "          \"colorbar\": False, \n",
    "          \"gamma\": 1,\n",
    "          \"cmap\": \"jet\"}\n",
    "out_of_bounds_map_signal.plot(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b518f1-a1b3-42d9-a5ba-d67177db6295",
   "metadata": {},
   "source": [
    "### Applying the coordinate transformation directly ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4005038-3a41-4692-82c8-89b9f37b9fa0",
   "metadata": {},
   "source": [
    "Using the coordinate transformation parameters in conjunction with the function\n",
    "``distoptica.apply_coord_transform``, we can apply directly the coordinate\n",
    "transformation to a set of coordinates of points in an undistorted image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c45c48-103c-4c88-97ed-3cdcec837cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ``u_x`` and ``u_y`` together store the fractional coordinates of points in an\n",
    "# undistorted image.\n",
    "u_x = torch.tensor([[0.35, 0.50, 0.65],\n",
    "                    [0.35, 0.50, 0.65]])\n",
    "u_y = torch.tensor([[0.35, 0.35, 0.35],\n",
    "                    [0.35, 0.35, 0.35]])\n",
    "\n",
    "kwargs = {\"u_x\": u_x,\n",
    "          \"u_y\": u_y,\n",
    "          \"coord_transform_params\": coord_transform_params}\n",
    "q_x, q_y = distoptica.apply_coord_transform(**kwargs)\n",
    "\n",
    "print(\"q_x:\")\n",
    "print(q_x)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"q_y:\")\n",
    "print(q_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f72103-a4cf-4c41-b6b4-59d4ee05eed8",
   "metadata": {},
   "source": [
    "Similarly, we can apply the right inverse of the coordinate transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c52de-2c08-4024-8937-cbdee536807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = \\\n",
    "    {\"q_x\": q_x,\n",
    "     \"q_y\": q_y,\n",
    "     \"coord_transform_params\": coord_transform_params, \n",
    "     \"least_squares_alg_params\": least_squares_alg_params}\n",
    "u_x, u_y, convergence_map = \\\n",
    "    distoptica.apply_coord_transform_right_inverse(**kwargs)\n",
    "\n",
    "print(\"u_x:\")\n",
    "print(u_x)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"u_y:\")\n",
    "print(u_y)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"convergence_map:\")\n",
    "print(convergence_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7446b5-d35b-4728-91e9-6013cb7c8691",
   "metadata": {},
   "source": [
    "The tensor ``convergence_map`` stores the convergence map of the iterative\n",
    "algorithm used to apply the right inverse of the coordinate transformation. As\n",
    "we can see, for this example, the iterative algorithm converges for all\n",
    "coordinates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
