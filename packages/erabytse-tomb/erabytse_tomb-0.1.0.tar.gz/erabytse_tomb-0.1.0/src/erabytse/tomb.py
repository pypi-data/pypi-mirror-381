#!/usr/bin/env python3
"""
erabytse-tomb v0.1
A respectful cemetery for dead links â€” not deletion, but remembrance.
"""

import re
import json
import argparse
from pathlib import Path
from urllib.parse import urlparse
import requests

# Timeout court pour ne pas bloquer
TIMEOUT = 5


def is_url_alive(url):
    """VÃ©rifie si une URL rÃ©pond (code 200-399)."""
    try:
        # VÃ©rifie d'abord si c'est un lien interne ou mailto
        parsed = urlparse(url)
        if parsed.scheme in ('', 'mailto', 'tel', 'javascript'):
            return True  # On les considÃ¨re comme "vivants"
        if parsed.scheme not in ('http', 'https'):
            return False

        response = requests.head(url, timeout=TIMEOUT, allow_redirects=True)
        return 200 <= response.status_code < 400
    except:
        return False


def check_wayback(url):
    """VÃ©rifie si l'URL existe sur archive.org."""
    try:
        archive_url = f"https://archive.org/wayback/available?url={url}"
        response = requests.get(archive_url, timeout=TIMEOUT)
        data = response.json()
        if data.get("archived_snapshots", {}).get("closest"):
            return data["archived_snapshots"]["closest"]["url"]
        return None
    except:
        return None


def extract_links_from_file(filepath: Path):
    """Extrait les liens d'un fichier (Markdown ou HTML simple)."""
    content = filepath.read_text(errors='ignore')
    #content = 'test.md'
    # Regex simple pour les liens
    links = re.findall(r'https?://[^\s"<>\)]+', content)
    return list(set(links))  # unique


def main():
    parser = argparse.ArgumentParser(
        description="ğŸ’€ erabytse-tomb: a respectful cemetery for dead links.",
        epilog="This is not deletion. This is remembrance."
    )
    parser.add_argument("--file", type=Path, required=True, help="File to scan (Markdown, HTML, or text)")
    parser.add_argument("--dry-run", action="store_true", help="Show report without modifying anything")

    args = parser.parse_args()

    print("ğŸ’€ erabytse-tomb v0.1 â€” a ritual of digital remembrance")
    print(f"   Scanning: {args.file}\n")

    if not args.file.exists():
        print("âŒ File not found.")
        return

    links = extract_links_from_file(args.file)
    print(f"ğŸ”— Found {len(links)} unique links. Checking status...\n")

    report = {
        "alive": [],
        "dead_unarchived": [],
        "dead_archived": []
    }

    for url in links:
        print(f"   Checking: {url[:60]}...")
        if is_url_alive(url):
            report["alive"].append(url)
        else:
            archived = check_wayback(url)
            if archived:
                report["dead_archived"].append({"original": url, "archive": archived})
            else:
                report["dead_unarchived"].append(url)

    # Affichage du rapport
    print(f"\nâœ… Alive: {len(report['alive'])}")
    print(f"ğŸ›ï¸  Dead but archived: {len(report['dead_archived'])}")
    print(f"âš°ï¸  Dead and lost: {len(report['dead_unarchived'])}")

    if not args.dry_run:
        print("\nğŸ’¡ Use --dry-run to see full details.")
    else:
        # Sauvegarde du rapport
        report_path = args.file.with_name("tomb_report.json")
        report_path.write_text(json.dumps(report, indent=2))
        print(f"\nğŸ“– Full report saved to: {report_path}")

        # GÃ©nÃ©ration de la page "In Memoriam"
        tomb_html = generate_tomb_page(report)
        tomb_path = args.file.with_name("tomb.html")
        tomb_path.write_text(tomb_html)
        print(f"ğŸ•Šï¸  Memorial page saved to: {tomb_path}")


def generate_tomb_page(report):
    """GÃ©nÃ¨re une page HTML simple en hommage aux liens perdus."""
    lost_count = len(report["dead_unarchived"])
    archived_count = len(report["dead_archived"])

    html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>âš°ï¸ Digital Tomb</title>
    <style>
        body {{ font-family: sans-serif; max-width: 800px; margin: 40px auto; line-height: 1.6; }}
        .lost {{ color: #d32f2f; }}
        .archived {{ color: #1976d2; }}
        a {{ text-decoration: none; }}
    </style>
</head>
<body>
    <h1>âš°ï¸ Digital Tomb</h1>
    <p>This page honors links that once lived â€” and what remains of them.</p>

    <h2>ğŸ›ï¸ Archived ({archived_count})</h2>
    <ul>
"""
    for item in report["dead_archived"]:
        html += f'        <li class="archived"><a href="{item["archive"]}" target="_blank">[ARCHIVED]</a> {item["original"]}</li>\n'

    html += f"""    </ul>

    <h2 class="lost">âš°ï¸ Lost to time ({lost_count})</h2>
    <ul>
"""
    for url in report["dead_unarchived"]:
        html += f'        <li class="lost">â— {url}</li>\n'

    html += """    </ul>

    <hr>
    <p><em>Generated by <a href="https://github.com/takouzlo/erabytse-tomb">erabytse-tomb</a> â€” a quiet act of digital remembrance.</em></p>
</body>
</html>"""

    return html


if __name__ == "__main__":
    main()