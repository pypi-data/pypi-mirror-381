{
  "metadata": {
    "title": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 495",
    "source_file": "examples/test_files/test.pdf",
    "pages": 13
  },
  "abstract": "Despite growing interest in applying natural language processing (Despite growing interest in applying natural language processing) and computer vi- sion (and computer vi- sion) models to the scholarly domain, scientific documents remain challenging to work with. They re often in difficult-to-use PDF formats, and the ecosystem of models to process them is fragmented and incom- plete. We introduce papermage, an open- source Python toolkit for analyzing and pro- cessing visually-rich, structured scientific doc- uments. papermage offers clean and intuitive abstractions for seamlessly representing and manipulating both textual and visual document elements. papermage achieves this by integrat- ing disparate state-of-the-art Despite growing interest in applying natural language processing and and computer vi- sion mod- els into a unified framework, and provides turn- key recipes for common scientific document processing use-cases. papermage has powered multiple research prototypes of AI applications over scientific documents, along with Seman- tic Scholar s large-scale production system for processing millions of PDFs. SS github.com allenai papermage1 1",
  "sections": [
    {
      "heading": "Body",
      "text": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 495-507 December 6-10, 2023 (c)2023 Association for Computational Linguistics PaperMage: A Unified Toolkit for Processing, Representing, and Manipulating Visually-Rich Scientific Documents Kyle Loa Zejiang Shena,t Benjamin Newmana Joseph Chee Changa Russell Authura Erin Bransoma Stefan Candraa Yoganand Chandrasekhara Regan Huffa Bailey Kuehla Amanpreet Singha Chris Wilhelma Angele Zamarrona Marti A. Hearstb Daniel S. Welda,o Doug Downeya,e Luca Soldainia aAllen Institute for AI tMassachusetts Institute of Technology bUniversity of California Berkeley oUniversity of Washington eNorthwestern University kylel, lucas allenai.org"
    },
    {
      "heading": "Abstract",
      "text": "Despite growing interest in applying natural language processing (Despite growing interest in applying natural language processing) and computer vi- sion (and computer vi- sion) models to the scholarly domain, scientific documents remain challenging to work with. They re often in difficult-to-use PDF formats, and the ecosystem of models to process them is fragmented and incom- plete. We introduce papermage, an open- source Python toolkit for analyzing and pro- cessing visually-rich, structured scientific doc- uments. papermage offers clean and intuitive abstractions for seamlessly representing and manipulating both textual and visual document elements. papermage achieves this by integrat- ing disparate state-of-the-art Despite growing interest in applying natural language processing and and computer vi- sion mod- els into a unified framework, and provides turn- key recipes for common scientific document processing use-cases. papermage has powered multiple research prototypes of AI applications over scientific documents, along with Seman- tic Scholar s large-scale production system for processing millions of PDFs. SS github.com allenai papermage1 1"
    },
    {
      "heading": "Introduction",
      "text": "Research papers and textbooks are central to the scientific enterprise, and there is increasing inter- est in developing new tools for extracting knowl- edge from these visually-rich documents. Recent research has explored, for example, AI-powered reading support for math symbol definitions , in-situ passage explanations or sum- maries (August et al., 2023; Rachatasumrit et al., 2022; Kim et al., 2023), automatic span highlight- ing (Chang et al., 2023; Fok et al., 2023b), interac- tive clipping and synthesis (Kang et al., 2022, 2023) Core contributors; see author contributions for details. 1We use code snippets to illustrate our toolkit s core de- signs and abstractions. Exact syntax in paper may differ from the actual code, as software will evolve beyond the paper and we opt to simplify syntax when needed for legibility and clarity. We refer readers to our public code for latest documentation. Figure 1: papermage s document creation and represen- tation. (A) Recipes are turn-key methods for processing a PDF. (B) They compose models operating across dif- ferent data modalities and machine learning frameworks to extract document structure, which we conceptualize as layers of annotation that store textual and visual in- formation. (C) Users can access and manipulate layers. and more. Further, extracting clean, properly- structured scientific text from PDF documents (Lo et al., 2020; Wang et al., 2020) forms a critical first step in pretraining language models of sci- ence (Beltagy et al., 2019; Lee et al., 2019; Gu et al., 2020; Luo et al., 2022; Taylor et al., 2022; Tre- wartha et al., 2022; Hong et al., 2023), automatic generation of more accessible paper formats , and developing datasets for scientific natural language processing (and developing datasets for scientific natural language processing) tasks over struc- tured full text (Jain et al., 2020; Subramanian et al., 2020; Dasigi et al., 2021; Lee et al., 2023). However, this type of and developing datasets for scientific natural language processing research on scientific 495 corpora is difficult because the documents come in difficult-to-use formats like PDF,2 and existing tools for working with the documents are limited. Typically, the first step in scientific document pro- cessing is to invoke a parser on a document file to convert it into a sequence of tokens and bounding boxes in inferred reading order. Parsers extract only the raw document content, and obtaining richer document structure (e.g., titles, authors, figures) or linguistic structure and semantics (e.g., sentences, discourse units, scientific claims) requires sending the token sequence through downstream models. Unlike more mature parsers (SS2.1), these down- stream models are often research prototypes (SS2.2) that are limited to extracting only a subset of the structures needed for one s research (e.g., the same model may not provide both sentence splits and fig- ure detection). As a result, users must write exten- sive custom code that strings pipelines of multiple models together. Research projects using models of different modalities (e.g., combining an image- based formula detector with a text-based definition extractor) can require hundreds of lines of code. We introduce papermage, an open-source Python toolkit for processing scientific documents. Its contributions include (1) magelib, a library of primitives and methods for representing and ma- nipulating visually-rich documents as multimodal constructs, (2) Predictors, a set of implementa- tions that integrate different state-of-the-art scien- tific document analysis models into a unified inter- face, even if individual models are written in differ- ent frameworks or operate on different modalities, and (3) Recipes, which provide turn-key access to well-tested combinations of individual (often single-modality) modules to form sophisticated, ex- tensible multimodal pipelines. 2"
    },
    {
      "heading": "Related Work",
      "text": "2.1 Turn-key software for scientific documents Processing visually-rich documents like scientific documents requires a joint understanding of both visual and textual information. In practice, this often requires combining different models into complex processing pipelines. For example, GRO- BID (Grobid, 2008-2023), a widely-adopted soft- ware tool for scientific document processing, uses 2PDFs store text as character glyphs and their (x, y) posi- tions on a page. Converting this data to usable text for and developing datasets for scientific natural language processing requires error-prone operations like inferring token boundaries, whitespacing, and reading order using visual positioning. twelve interdependent sequence labeling models3 to perform its full text extraction. Other similar tools inlude CERMINE and ParsCit . While such software is often an ideal choice for off-the-shelf processing, they are not necessarily designed for easy extension and or integration with newer research models.4 2.2 Models for scientific document processing While aforementioned software tools use CRF or BiLSTM-based models, Transformer-based models have seen wide adoption among and developing datasets for scientific natural language processing researchers for their powerful processing capabilities. Recent years have seen the rise of layout-infused Trans- formers (Xu et al., 2019; Shen et al., 2022; Xu et al., 2021; Huang et al., 2022b; Chen et al., 2023) for processing visually-rich documents, including recovering logical structure (e.g., titles, abstracts) of scientific papers . Similarly, computer vision (computer vision) researchers have also shown impressive capabilities of CNN-based object de- tection models (Ren et al., 2015; Tan et al., 2020) for segmenting visually-rich documents based on their layout. While these research models are pow- erful and extensible for research purposes, it often requires significant glue code and stitching soft- ware tools to create robust processing pipelines. For example, Lincker et al. (2023) bootstraps a so- phisticated processing pipeline around a research model for processing children s textbooks. 2.3 Combining models and pipelines papermage s use case lies between that of turn- key software and a framework for supporting re- search. Similar to Transformers s integration of different research mod- els into standard interfaces, others have done similarly for the visually-rich document domain. LayoutParser provides mod- els for visually-rich documents and supports the creation of document processing pipelines. papermage, in fact, depends on LayoutParser for access to vision models, but is designed to also integrate text models which are omitted from 3https: grobid.readthedocs.io en latest Training-the-models-of-Grobid models 4Most research in and developing datasets for scientific natural language processing requires that a researcher be able to manipulate models within Python. Yet, Grobid requires users to manage a separate service process and send PDFs through a client. In performing evaluation in SS3.3, we also found it difficult to run only the model components isolated from PDF utilities, which makes comparison with other research models challenging without significant glue code. 496 Figure 2: Entities are multimodal content units. Here, spans of a sentence are used to identify its text among all symbols, while boxes map its visual coordinates on a page. spans and boxes can include non-contiguous units, allowing great flexibility in Entities to handle layout nuances. A sentence split across columns pages and interrupted by floating figures footnotes would re- quire multiple spans and bounding boxes to represent. LayoutParser. To allow models of different modalities to work well together, we also devel- oped the magelib library (SS3.1). 3 Design of papermage papermage is three parts: (1) magelib, a library for intuitively representing and manipulating visually- rich documents, (2) Predictors, implementations of models for analyzing scientific papers that unify disparate machine learning frameworks under a common interface, and (3) Recipes, combinations of Predictors that form multimodal pipelines. 3.1 Representing and manipulating visually-rich documents with magelib In this section, we use code snippets to show how our library s abstractions and syntax are tailored for the visually-rich document problem domain. Data Classes. magelib provides three base data classes for representing fundamental elements of visually-rich, structured documents: Document, Layers and Entities. First, a Document might minimally store text as a string of symbols: 1 from papermage import Document 2 doc.symbols 3 Revolt: Collaborative Crowdsourcing ... But visually-rich documents are more than a lin- earized string. For example, analyzing a scientific paper requires access to its visuospatial layout (e.g., pages, blocks, lines), logical structure (e.g., title, abstract, figures, tables, footnotes, sections), se- mantic units (e.g., paragraphs, sentences, tokens), and more (e.g., citations, terms). In practice, this means different parts of doc.symbols can corre- spond to different paragraphs, sentences, tokens, etc. in the Document, each with its own set of corresponding coordinates representing its visual position on a page. magelib represents structure using Layers that can be accessed as attributes of a Document (e.g., doc.sentences, doc.figures, doc.tokens) (Figure 1). Each Layer is a sequence of content units, called Entities, which store both textual (e.g., spans, strings) and visuospatial (e.g., bounding boxes, pixel arrays) information: 1 sentences Layer(entities [ 2 Entity (...), Entity (...) , ... 3 ]) See Figure 2 for an example on how sentences in a scientific document are represented as Entities. Section SS3.2 explains in more detail how a user can generate Entities."
    },
    {
      "heading": "Methods",
      "text": "magelib also provides a set of func- tions for building and interacting with data: aug- menting a Document with additional Layers, traversing and spatially searching for matching Entities in one Layer, and cross-referencing be- tween Layers (see Figure 3). A Document that only contains doc.symbols can be augmented with additional Layers: 1 paragraphs Layer (...) 2 sentences Layer (...) 3 tokens Layer (...) 4 5 doc.add(paragraphs , sentences , tokens) Adding Layers automatically grants users the ability to iterate through Entities and cross- reference intersecting Entities across Layers: 1 for paragraph in doc.paragraphs: 2 for sent in paragraph.sentences: 3 for token in sentence.tokens: 4 ... magelib also supports cross-modality opera- tions. For example, searching for textual Entities within a visual region on the PDF (See Figure 3 F): 1 query Box(l 423, t 71, w 159, h 87) 2 selection doc.find(query , tokens ) 3 [t.text for t in selection] 4 [ Techniques , for , collecting , ...] 497 doc.paragraphs doc.paragraphs.sentences or doc.sentences doc.sentences.tokens[9:13] or doc.tokens[169:173] doc.figures doc.captions user_query Box(l,t,w,h, page 0) selected_tokens doc.find(user_query, layer tokens ) [token.text for token in selected_tokens] [ Techniques , for , collecting , labeled , data , perts , for , manual , annotation , ...] Crowdsourcing provides a scalable and efficient way to con- struct labeled datasets for training machine learning systems. However, creating comprehensive label guidelines for crowd- workers is often prohibitive even for seemingly simple con- cepts. Incomplete or ambiguous label guidelines can then result in differing interpretations of concepts and inconsistent labels. Existing approaches for improving label quality, such as worker screening or detection of poor work, are ineffective for this problem and can lead to rejection of honest work and a missed opportunity to capture rich interpretations about data. We introduce Revolt, a collaborative approach that brings ideas from expert annotation workflows to crowd-based labeling. Revolt eliminates the burden of creating detailed label guide- lines by harnessing crowd disagreements to identify ambigu- ous concepts and create rich structures (groups of semantically related items) for post-hoc label decisions. Experiments com- paring Revolt to traditional crowdsourced labeling show that Revolt produces high quality labels without requiring label guidelines in turn for an increase in monetary cost. This up front cost, however, is mitigated by Revolt s ability to produce reusable structures that can accommodate a variety of label boundaries without requiring new data to be collected. Further comparisons of Revolt s collaborative and non-collaborative variants show that collabvoration reaches higher label accura- cy with lower monetary cost. learned models that must be trained on representative datasets labeled according to target concepts (e.g., speech labeled by their intended commands, faces labeled in images, emails la- beled as spam or not spam). crowdsourcing; machine learning; collaboration; real-time H.5.m. Information Interfaces and Presentation (e.g. HCI): Miscellaneous From conversational assistants on mobile devices, to facial Techniques for collecting labeled data include recruiting ex- perts for manual annotation , extracting relations from readily available sources (e.g., identifying bodies of text in parallel online translations [46, 13]), and automatically gener- ating labels based on user behaviors (e.g., using dwell time to implicitly mark search result relevance ). Recently, many practitioners have also turned to crowdsourcing for cre- ating labeled datasets at low cost . Successful crowd- Figure 1. Revolt creates labels for unanimously labeled certain items (e.g., cats and not cats), and surfaces categories of uncertain items enriched with crowd feedback (e.g., cats and dogs and cartoon cats in the dotted middle region are annotated with crowd explanations). Rich structures allow label requesters to better understand concepts in the data and make post-hoc decisions on label boundaries (e.g., assigning cats and dogs to the cats label and cartoon cats to the not cats label) rather than providing crowd-workers with a priori label guidelines."
    },
    {
      "heading": "Abstract",
      "text": "ACM Classification Keywords Author Keywords INTRODUCTION A B C D E F A B C D E F Figure 3: Illustrates how Entities can be accessed flexibly in different ways: (A) Accessing the Entity of the first paragraph in the Document via its own Layer (B) Accessing a sentence via the paragraph Entity or directly via the sentences Layer (C) Similarly, the same tokens can be accessed via the overlapping sentence Entity or directly via the tokens Layer of the Document (where the first tokens are the title of the paper.) (D, E) Figures, captions, tables and keywords can be accessed in similar ways (F) Additionally, given a bounding box (e.g., of a user selected region), papermage can find the corresponding Entities for a given Layer, in this case finding the tokens under the region. Excerpt from Chang et al. (2017). Protocols and Utilities. To instantiate a Document, magelib provides protocols and utilities like Parsers and Rasterizers, which hook into off-the-shelf PDF processing tools:5 1 import papermage as pm 2 parser pm.PDF2TextParser () 3 doc parser.parse( ...pdf ) 4 [token.text for token in doc.tokens] 5 [ Revolt , : , Collaborative , ...] 6 doc.images 7 None 8 9 rasterizer pm.PDF2ImageRasterizer () 10 doc2 rasterizer.rasterize( ... pdf ) 11 doc.images doc2.images 12 doc.images 13 [Image(np.array (...)) , ...] In this example, papermage runs PDF2TextParser (using pdfplumber) to extract the textual in- formation from a PDF file. Then it runs PDF2ImageRasterizer (using pdf2image) to up- date the first Document with images of pages. 5PDFs are not the only way of representing visually-rich documents. For example, many scientific documents are dis- tributed in XML format. As PDFs are the dominant distribu- tion format of scientific documents, we focus our efforts on PDF-specific needs. Nevertheless, we also provide Parsers in magelib that can instantiate a Document from XML input. See Appendix A.1. 3.2 Interfacing with models for scientific document analysis through Predictors In SS3.1, we described how users create Layers by assembling collections of Entities. But how would they make Entities in the first place For example, to identify multimodal structures in visually-rich documents, researchers might want to build complex pipelines that run and combine output from many different models (e.g., computer vision models for extracting figures, and developing datasets for scientific natural language processing models for classifying body text). papermage provides a unified interface, called Predictors, to ensure models produce Entities that are compatible with the Document. papermage includes several ready-to-use Predictors that leverage state-of-the-art models to extract specific document structures (Table 1). While magelib s abstractions are general for visually-rich documents, Predictors are opti- mized for parsing of scientific documents. They are designed to (1) be compatible with models from many different machine learning frameworks, (2) support inference with text-only, vision-only, and multimodal models, and (3) support both adap- tation of off-the-shelf, pretrained models as well as 498 Use case Description Examples Linguistic Semantic Segments doc into text units often used for down- stream models. SentencePredictor wraps sciSpaCy and PySBD (Sadvilkar and Neumann, 2020) to segment sentences. WordPredictor is a custom scikit-learn model to identify broken words split across PDF lines or columns. ParagraphPredictor is a set of heuristics on top of both layout and logical structure models to extract paragraphs. Layout Structure Segments doc into visual block regions. BoxPredictor wraps models from LayoutParser , which provides vision models like EfficientDet pretrained on scientific layouts . Logical Structure Segments doc into orga- nizational units like title,"
    },
    {
      "heading": "Abstract",
      "text": "caption, and more. SpanPredictor wraps Token Classifiers from Transformers , which provides both pretrained weights from VILA , as well as RoBERTa , SciBERT weights that we ve finetuned on similar data. Task- specific Models for a given sci- entific document process- ing task can be used with papermage if wrapped as a Predictor following common patterns. As many practitioners depend on prompting a model through an API call, we implement APIPredictor which interfaces external APIs, such as GPT-3 , to perform tasks like question answering over a structured Document. We also implement SnippetRetrievalPredictor which wraps models like Con- triever to perform top-k within-document snippet retrieval. See SS4 for how these two can be combined. Table 1: Types of Predictors implemented in papermage. Model Full Grobid Subset P R F1 P R F1 GrobidCRF 40.6 38.3 39.1 81.2 76.7 78.9 GrobidNN 42.0 36.5 37.6 84.1 73.0 78.2 RoBERTa 75.9 80.0 76.8 82.6 83.9 83.2 I-VILA 92.0 94.1 92.7 92.2 95.2 93.7 Table 2: Evaluating performance of CoreRecipe for logical structure recovery on S2-VL . Metrics are computed for token-level classification, macro-averaged over categories. The Grobid Subset limits evaluation to only categories for which Grobid returns bounding box information, which was necessary for evaluation on S2-VL. See Appendix A.3 for details. development of new ones from scratch. Similarly to the Transformers library, a Predictor s implementation is typically independent from its configuration, allowing users to customize each Predictor by tweaking hyperparameters or loading a different set of weights. Below, we showcase how a vision model and two text models (both neural and symbolic) can be applied in succession to a single Document. See Table 1 for a summary of supported Predictors. 1 import papermage as pm 2 cv pm.BoxPredictor (...) 3 tables , figures cv.predict(doc) 4 doc.add(tables , figures) 5 6 nlp_neu pm.SpanPredictor (...) 7 titles , authors nlp_neu.predict(doc) 8 doc.add(titles , authors) 9 10 nlp_sym pm.SentencePredictor (...) 11 sentences nlp_sym.predict(doc) 12 doc.add(sentences) Predictors return a list of Entities, which can be group_by() to organize them based on pre- dicted label value (e.g., tokens classified as title or authors ). Finally, these predictions are passed to doc.annotate() to be added to Document. 3.3 End-to-end processing with Recipes Finally, papermage provides predefined combina- tions of Predictors, called Recipes, for users seeking high-quality options for turn-key process- ing of visually-rich documents: 1 from papermage import CoreRecipe 2 recipe CoreRecipe () 3 doc recipe.run( ... pdf ) 4 doc.captions . text 5 Figure 1. ... Recipes can also be flexibly modified to sup- port development. For example, our current de- fault combines the pdfplumber PDF parsing utility with the I-VILA research model. We show in Table 2 an evaluation comparing this against the same recipe but configured to (1) swap I-VILA for a RoBERTa model, as well as (2) swap both for Grobid API calls. We expect Recipes to appeal to two groups of users--end-to-end con- sumers, and developers of high-level applications. The former is comprised of developers and re- searchers who are looking for a one-step solution to multimodal scientific document analysis. The latter are likely developers and researchers looking to combine document structure primitives to build a complex application (see example in SS4). 499 4 Vignette: Building an Attributed QA System for Scientific Papers How could researchers leverage papermage for their research Here, we walk through a user sce- nario in which a researcher (Lucy) is prototyping an attributed QA system for science. System Design. Drawing inspiration from Ko et al. (2020), Lee et al. (2023), Fok et al. (2023a), and Newman et al. (2023), Lucy is studying how language models can be used to resolve questions that arise while reading a paper (e.g. What does this mean or What does this refer to ). In her prototype interface, a user can highlight a passage in a PDF and ask a question about it. A retrieval model then finds relevant passages from the rest of the paper. The prototype then uses the text of the retrieved passages along with the user question to prompt a language model to generate an answer. When presenting the answer to the user, the proto- type also visually highlights the retrieved passages as supporting evidence to the generated answer. Getting started quickly. As a researcher profi- cient in Python, it only takes Lucy minutes to install papermage using pip and successfully process a lo- cal PDF file by following the example code snippet for CoreRecipe in SS3.2. In an interactive session, she familiarizes herself with the provided Layers by following the traversal, cross-referencing and querying examples in SS3.1. She makes sure she can serialize and re-instantiate her Document (SSA.2). Formatting input. Before using papermage, Lucy has prior experience building QA pipelines, but has only dealt with documents as sentence- split text data (e.g., List[str] ). Lucy realizes that she can reuse her prior text-only code with papermage by implementing a couple of wrappers to gain additional capabilities: First, she converts a user s highlighted passage from a visual selec- tion to text following the example in Figure 3F. Next, she converts Document to her required text format by following the traversal examples in SS3.1 (e.g., using [s.text for s in doc.sentences]). Within a few lines of code, Lucy has everything she needs for text-only input to her QA pipeline. Formatting output. Lucy runs her QA system on her newly acquired text data and now has (1) a model-generated answer and (2) several retrieved evidence passages. She realizes that she already has access to the evidences bounding boxes via a similar call to how she defined the model input con- text (e.g., [s.boxes for s in doc.sentences]). She can easily pass this to the user interface to en- able linking to and highlighting of those passages. Defining a Predictor. The pattern Lucy has followed is used in our many Predictor imple- mentations: (1) gain access to text by traversing Layers (e.g., sentences), (2) perform all usual and developing datasets for scientific natural language processing computation on that text, and (3) format model output as Entities. This simple pattern allows users to reuse familiar models in existing frameworks and eschews lengthy onboarding to papermage. Lucy wraps her prompting and re- trieval code in new classes: APIPredictor and SnippetRetrievalPredictor (see Table 1). Fast iterations. Leveraging the bounding box data from papermage to visually highlight the re- trieved passages, Lucy suspects the retrieval com- ponent is likely underperforming. She makes a sim- ple edit from doc.sentences to doc.paragraphs and evaluates system performance under different input granularity. She also realizes the system of- ten retrieves content outside the main body text. She restricts her traversal to filter out paragraphs that overlap with footnotes--[p.text for p in doc.paragraphs if len(p.footnotes) 0]-- making clever use of the cross-referencing function- ality to detect when a paragraph is actually coming from a footnote. This example demonstrates the versatility of the affordances provided by magelib. 5"
    },
    {
      "heading": "Conclusion",
      "text": "In this work, we ve introduced papermage, an open-source Python toolkit for processing scientific documents. papermage was developed to supply high-quality data and reduce friction for research prototype development at Semantic Scholar. To- day, it is being used in the production PDF process- ing pipeline to provide data for both the literature graph (Ammar et al., 2018; Kinney et al., 2023) and the paper-reading interface . It has also been used in working research prototypes which have since contributed to research publica- tions (Fok et al., 2023b; Kim et al., 2023).6 We open-source papermage in hopes it will simplify research workflows that depend on scientific doc- uments and promote extensions to other visually- rich documents like textbooks and digitized print media . 6See a demo of such a prototype papeo.app demo. 500 Ethical Considerations As a toolkit primarily designed to process scientific documents, there are two areas where papermage could cause harms or have unintended effects. Extraction of bibliographic information papermage could be used to parse author names, affiliation, emails from scientific documents. Like any software, this extraction can be noisy, leading to incorrect parsing and thus mis-attribution of manuscripts. Further, since papermage relies on static PDF documents, rather than metadata dynamically retrieved from publishers, users of papermage need consider how and when extracted names should no longer be associated with authors, a harmful practice called deadnaming (Queer in AI et al., 2023). We recommend papermage users to exercise caution when using our toolkit to extract metadata, to cross-reference extracted content with other sources when possible, and to design systems such that authors have the ability to manually edit any data about themselves. Misrepresentation or fabrication of informa- tion in documents In SS3, we discussed how papermage can be easily extended to support high- level applications. Such applications might include question answering chatbots, or AI summarizers that perform information synthesis over one or more papermage documents. Such applications typically rely on generative models to produce their output, which might fabricate incorrect informa- tion or misstate claims. Developers should be vig- ilant when integrating papermage output into any downstream application, especially in systems that purport to represent information gathered from sci- entific publications. Acknowledgements We thank our teammates at Semantic Scholar for their help on this project. In particular: Rodney Kinney provided insight during discussions about how best to represent data extracted from docu- ments; Paul Sayre provided feedback on initial designs of the library; Chloe Anastasiades, Dany Haddad and Egor Klevak tested earlier versions of the library; Tal August, Raymond Fok, and Andrew Head motivated the need for such a toolkit dur- ing their internships building augmented reading interfaces; Jaron Lochner and Kelsey MacMillan helped us get additional engineering support; and Oren Etzioni provided enthusiasm and support for continued investment in this toolkit. This project was supported in part by NSF Grant OIA-2033558 and NSF Grant CNS-2213656. Author Contributions All authors contributed to the implementation of papermage and or the writing of this paper. Core contributors. Kyle Lo and Zejiang Shen initiated the project and co-wrote initial implemen- tations of magelib and some Predictors. Later, Kyle Lo and Luca Soldaini refactored a majority of magelib, Predictors, and added Recipes. Ben- jamin Newman added new Predictors to support use-cases like those in the Vignette (SS4). Joseph Chee Chang implemented an end-to-end web-based visual interface for papermage and helped iterate on papermage s designs. All core contributors helped with writing. Finally, Kyle Lo led all aspects of the project, including design and implementa- tion, as well as mentorship of other contributors to the toolkit (see below). Other contributors. Russell Authur, Stefan Can- dra, Yoganand Chandrasekhar, Regan Huff, Aman- preet Singh and Angele Zamarron each worked closely with Kyle Lo to contribute a Predictor to papermage. Erin Bransom and Bailey Kuehl helped with data annotation for training and evalu- ating those Predictors. Chris Wilhelm provided feedback on papermage s design and implemented faster indexing of Entities when building Layers. Finally, Marti Hearst, Daniel Weld, and Doug Downey helped with writing and overall advising on the project."
    },
    {
      "heading": "References",
      "text": "Waleed Ammar, Dirk Groeneveld, Chandra Bhagavat- ula, Iz Beltagy, Miles Crawford, Doug Downey, Ja- son Dunkelberger, Ahmed Elgohary, Sergey Feld- man, Vu Ha, Rodney Kinney, Sebastian Kohlmeier, Kyle Lo, Tyler Murray, Hsu-Han Ooi, Matthew Pe- ters, Joanna Power, Sam Skjonsberg, Lucy Lu Wang, Chris Wilhelm, Zheng Yuan, Madeleine van Zuylen, and Oren Etzioni. 2018. Construction of the litera- ture graph in semantic scholar. In Proceedings of the 2018 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Indus- try Papers), pages 84-91, New Orleans - Louisiana. Association for Computational Linguistics. Tal August, Lucy Lu Wang, Jonathan Bragg, Marti A. Hearst, Andrew Head, and Kyle Lo. 2023. Paper 501 plain: Making medical research papers approachable to healthcare consumers with natural language pro- cessing. ACM Trans. Comput.-Hum. Interact., 30(5). Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciB- ERT: A pretrained language model for scientific text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Lan- guage Processing (Conference on Empirical Methods in Natural Language Processing-IJCNLP), pages 3615- 3620, Hong Kong, China. Association for Computa- tional Linguistics. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma- teusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems, volume 33, pages 1877-1901. Curran Associates, Inc. Joseph Chee Chang, Saleema Amershi, and Ece Kamar. 2017. Revolt: Collaborative crowdsourcing for label- ing machine learning datasets. In Proceedings of the 2017 CHI Conference on Human Factors in Comput- ing Systems, CHI 17, page 2334-2346, New York, NY, USA. Association for Computing Machinery. Joseph Chee Chang, Amy X. Zhang, Jonathan Bragg, Andrew Head, Kyle Lo, Doug Downey, and Daniel S. Weld. 2023. Citesee: Augmenting citations in scien- tific papers with persistent and personalized historical context. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, CHI 23, New York, NY, USA. Association for Computing Machinery. Catherine Chen, Zejiang Shen, Dan Klein, Gabriel Stanovsky, Doug Downey, and Kyle Lo. 2023. Are layout-infused language models robust to layout dis- tribution shifts a case study with scientific docu- ments. In Findings of the Association for Computa- tional Linguistics: ACL 2023, pages 13345-13360, Toronto, Canada. Association for Computational Lin- guistics. Isaac Councill, C. Lee Giles, and Min-Yen Kan. 2008. ParsCit: an open-source CRF reference string pars- ing package. In Proceedings of the Sixth Interna- tional Conference on Language Resources and Eval- uation (LREC 08), Marrakech, Morocco. European Language Resources Association (European Language Resources Association). Pradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan, Noah A. Smith, and Matt Gardner. 2021. A dataset of information-seeking questions and answers an- chored in research papers. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Hu- man Language Technologies, pages 4599-4610, On- line. Association for Computational Linguistics. Raymond Fok, Joseph Chee Chang, Tal August, Amy X. Zhang, and Daniel S. Weld. 2023a. Qlarify: Bridg- ing scholarly abstracts and papers with recursively expandable summaries. arXiv, abs 2310.07581. Raymond Fok, Hita Kambhamettu, Luca Soldaini, Jonathan Bragg, Kyle Lo, Marti Hearst, Andrew Head, and Daniel S Weld. 2023b. Scim: Intelligent skimming support for scientific papers. In Proceed- ings of the 28th International Conference on Intelli- gent User Interfaces, IUI 23, page 476-490, New York, NY, USA. Association for Computing Machin- ery. Grobid. 2008-2023. Grobid. https: github.com kermitt2 grobid. Yu Gu, Robert Tinn, Hao Cheng, Michael R. Lucas, Naoto Usuyama, Xiaodong Liu, Tristan Naumann, Jianfeng Gao, and Hoifung Poon. 2020. Domain- specific language model pretraining for biomedical natural language processing. ACM Transactions on Computing for Healthcare (ACM Transactions on Computing for Healthcare), 3:1 - 23. Andrew Head, Kyle Lo, Dongyeop Kang, Raymond Fok, Sam Skjonsberg, Daniel S. Weld, and Marti A. Hearst. 2021. Augmenting scientific papers with just- in-time, position-sensitive definitions of terms and symbols. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, CHI 21, New York, NY, USA. Association for Computing Machinery. Zhi Hong, Aswathy Ajith, James Pauloski, Eamon Duede, Kyle Chard, and Ian Foster. 2023. The dimin- ishing returns of masked language models to science. In Findings of the Association for Computational Linguistics: ACL 2023, pages 1270-1283, Toronto, Canada. Association for Computational Linguistics. Po-Wei Huang, Abhinav Ramesh Kashyap, Yanxia Qin, Yajing Yang, and Min-Yen Kan. 2022a. Lightweight contextual logical structure recovery. In Proceedings of the Third Workshop on Scholarly Document Pro- cessing, pages 37-48, Gyeongju, Republic of Korea. Association for Computational Linguistics. Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, and Furu Wei. 2022b. Layoutlmv3: Pre-training for doc- ument ai with unified text and image masking. Pro- ceedings of the 30th ACM International Conference on Multimedia. Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebas- tian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2022. Unsupervised dense informa- tion retrieval with contrastive learning. Transactions on Machine Learning Research. Sarthak Jain, Madeleine van Zuylen, Hannaneh Ha- jishirzi, and Iz Beltagy. 2020. SciREX: A challenge dataset for document-level information extraction. In 502 Proceedings of the 58th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 7506- 7516, Online. Association for Computational Lin- guistics. Hyeonsu B. Kang, Joseph Chee Chang, Yongsung Kim, and Aniket Kittur. 2022. Threddy: An interactive system for personalized thread-based exploration and organization of scientific literature. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology, UIST 22, New York, NY, USA. Association for Computing Machinery. Hyeonsu B. Kang, Sherry Tongshuang Wu, Joseph Chee Chang, and Aniket Kittur. 2023. Synergi: A mixed- initiative system for scholarly synthesis and sense- making. In Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technol- ogy. Association for Computing Machinery. Tae Soo Kim, Matt Latzke, Jonathan Bragg, Amy X. Zhang, and Joseph Chee Chang. 2023. Papeos: Aug- menting research papers with talk videos. In Proceed- ings of the 36th Annual ACM Symposium on User Interface Software and Technology. Rodney Kinney, Chloe Anastasiades, Russell Authur, Iz Beltagy, Jonathan Bragg, Alexandra Buraczyn- ski, Isabel Cachola, Stefan Candra, Yoganand Chan- drasekhar, Arman Cohan, Miles Crawford, Doug Downey, Jason Dunkelberger, Oren Etzioni, Rob Evans, Sergey Feldman, Joseph Gorney, David Gra- ham, Fangzhou Hu, Regan Huff, Daniel King, Se- bastian Kohlmeier, Bailey Kuehl, Michael Langan, Daniel Lin, Haokun Liu, Kyle Lo, Jaron Lochner, Kelsey MacMillan, Tyler Murray, Chris Newell, Smita Rao, Shaurya Rohatgi, Paul Sayre, Zejiang Shen, Amanpreet Singh, Luca Soldaini, Shivashankar Subramanian, Amber Tanaka, Alex D. Wade, Linda Wagner, Lucy Lu Wang, Chris Wilhelm, Caroline Wu, Jiangjiang Yang, Angele Zamarron, Madeleine Van Zuylen, and Daniel S. Weld. 2023. The Semantic Scholar Open Data Platform. ArXiv, abs 2301.10140. Wei-Jen Ko, Te-yuan Chen, Yiyan Huang, Greg Durrett, and Junyi Jessy Li. 2020. Inquisitive question gener- ation for high level text comprehension. In Proceed- ings of the 2020 Conference on Empirical Methods in Natural Language Processing (Conference on Empirical Methods in Natural Language Processing), pages 6544-6555, Online. Association for Computational Linguistics. Benjamin Charles Germain Lee, Jaime Mears, Eileen Jakeway, Meghan Ferriter, Chris Adams, Nathan Yarasavage, Deborah Thomas, Kate Zwaard, and Daniel S. Weld. 2020. The newspaper navigator dataset: Extracting headlines and visual content from 16 million historic newspaper pages in chronicling america. In Proceedings of the 29th ACM Interna- tional Conference on Information Knowledge Man- agement, CIKM 20, page 3055-3062, New York, NY, USA. Association for Computing Machinery. Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang. 2019. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics, 36(4):1234-1240. Yoonjoo Lee, Kyungjae Lee, Sunghyun Park, Dasol Hwang, Jaehyeon Kim, Hong-In Lee, and Moontae Lee. 2023. QASA: Advanced question answering on scientific articles. In Proceedings of the 40th Inter- national Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 19036-19052. PMLR. Elise Lincker, Olivier Pons, Camille Guinaudeau, Is- abelle Barbet, Jerome Dupire, Celine Hudelot, Vin- cent Mousseau, and Caroline Huron. 2023. Layout and activity-based textbook modeling for automatic pdf textbook extraction. In iTextbooks AIED. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretrain- ing Approach. ArXiv, abs 1907.11692. Kyle Lo, Joseph Chee Chang, Andrew Head, Jonathan Bragg, Amy X. Zhang, Cassidy Trier, Chloe Anas- tasiades, Tal August, Russell Authur, Danielle Bragg, Erin Bransom, Isabel Cachola, Stefan Candra, Yo- ganand Chandrasekhar, Yen-Sung Chen, Evie Yu- Yen Cheng, Yvonne Chou, Doug Downey, Rob Evans, Raymond Fok, Fangzhou Hu, Regan Huff, Dongyeop Kang, Tae Soo Kim, Rodney Kinney, Aniket Kittur, Hyeonsu Kang, Egor Klevak, Bai- ley Kuehl, Michael Langan, Matt Latzke, Jaron Lochner, Kelsey MacMillan, Eric Marsh, Tyler Mur- ray, Aakanksha Naik, Ngoc-Uyen Nguyen, Srishti Palani, Soya Park, Caroline Paulic, Napol Rachata- sumrit, Smita Rao, Paul Sayre, Zejiang Shen, Pao Siangliulue, Luca Soldaini, Huy Tran, Madeleine van Zuylen, Lucy Lu Wang, Christopher Wilhelm, Caro- line Wu, Jiangjiang Yang, Angele Zamarron, Marti A. Hearst, and Daniel S. Weld. 2023. The Semantic Reader Project: Augmenting Scholarly Documents through AI-Powered Interactive Reading Interfaces. ArXiv, abs 2303.14334. Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kin- ney, and Daniel Weld. 2020. S2ORC: The semantic scholar open research corpus. In Proceedings of the 58th Annual Meeting of the Association for Compu- tational Linguistics, pages 4969-4983, Online. Asso- ciation for Computational Linguistics. Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu. 2022. Biogpt: Generative pre-trained transformer for biomedical text generation and mining. Briefings in bioinformatics. Mark Neumann, Daniel King, Iz Beltagy, and Waleed Ammar. 2019. ScispaCy: Fast and robust models for biomedical natural language processing. In Pro- ceedings of the 18th BioNLP Workshop and Shared Task, pages 319-327, Florence, Italy. Association for Computational Linguistics. 503 Benjamin Newman, Luca Soldaini, Raymond Fok, Ar- man Cohan, and Kyle Lo. 2023. A question answer- ing framework for decontextualizing user-facing snip- pets from scientific documents. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (Conference on Empirical Methods in Natural Language Processing). Organizers of Queer in AI, Anaelia Ovalle, Arjun Sub- ramonian, Ashwin Singh, Claas Voelcker, Danica J. Sutherland, Davide Locatelli, Eva Breznik, Filip Klu- bicka, Hang Yuan, Hetvi J, Huan Zhang, Jaidev Shriram, Kruno Lehman, Luca Soldaini, Maarten Sap, Marc Peter Deisenroth, Maria Leonor Pacheco, Maria Ryskina, Martin Mundt, Milind Agarwal, Nyx Mclean, Pan Xu, A Pranav, Raj Korpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, St John, Tanvi Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J. Wang, Zeerak Talat, Avijit Ghosh, Nathaniel Dennler, Michael Noseworthy, Sharvani Jha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew Mcnamara, Raphael Gontijo-Lopes, Alex Markham, Evyn Dong, Jackie Kay, Manu Saraswat, Nikhil Vytla, and Luke Stark. 2023. Queer In AI: A Case Study in Community-Led Participatory AI. In Proceedings of the 2023 ACM Conference on Fair- ness, Accountability, and Transparency, FAccT 23, page 1882-1895, New York, NY, USA. Association for Computing Machinery. Napol Rachatasumrit, Jonathan Bragg, Amy X. Zhang, and Daniel S Weld. 2022. Citeread: Integrating lo- calized citation contexts into scientific paper reading. In 27th International Conference on Intelligent User Interfaces, IUI 22, page 707-719, New York, NY, USA. Association for Computing Machinery. Shaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. 2015. Faster r-cnn: Towards real-time object de- tection with region proposal networks. IEEE Trans- actions on Pattern Analysis and Machine Intelligence, 39:1137-1149. Nipun Sadvilkar and Mark Neumann. 2020. PySBD: Pragmatic sentence boundary disambiguation. In Proceedings of Second Workshop for and developing datasets for scientific natural language processing Open Source Software (and developing datasets for scientific natural language processing-OSS), pages 110-114, Online. Association for Computational Linguistics. Zejiang Shen, Kyle Lo, Lucy Lu Wang, Bailey Kuehl, Daniel S. Weld, and Doug Downey. 2022. VILA: Im- proving structured content extraction from scientific PDFs using visual layout groups. Transactions of the Association for Computational Linguistics, 10:376- 392. Zejiang Shen, Ruochen Zhang, Melissa Dell, B. Lee, Jacob Carlson, and Weining Li. 2021. Layoutparser: A unified toolkit for deep learning based document image analysis. In IEEE International Conference on Document Analysis and Recognition. Sanjay Subramanian, Lucy Lu Wang, Ben Bogin, Sachin Mehta, Madeleine van Zuylen, Sravanthi Parasa, Sameer Singh, Matt Gardner, and Hannaneh Hajishirzi. 2020. MedICaT: A dataset of medical images, captions, and textual references. In Find- ings of the Association for Computational Linguistics: Conference on Empirical Methods in Natural Language Processing 2020, pages 2112-2120, Online. Association for Computational Linguistics. M. Tan, R. Pang, and Q. V. Le. 2020. Efficientdet: Scalable and efficient object detection. In 2020 IEEE CVF Conference on Computer Vision and Pat- tern Recognition (IEEE CVF Conference on Computer Vision and Pat- tern Recognition), pages 10778-10787, Los Alamitos, CA, USA. IEEE Computer Society. Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony S. Hartshorn, Elvis Saravia, An- drew Poulton, Viktor Kerkez, and Robert Stojnic. 2022. Galactica: A large language model for science. ArXiv, abs 2211.09085. pdf2image. 2023. pdf2image. https: github. com Belval pdf2image. pdfplumber. 2023. pdfplumber. https: github. com jsvine pdfplumber. Dominika Tkaczyk, Pawel Szostek, Mateusz Fedo- ryszak, Piotr Jan Dendek, and Lukasz Bolikowski. 2015. Cermine: Automatic extraction of structured metadata from scientific literature. Int. J. Doc. Anal. Recognit., 18(4):317-335. Amalie Trewartha, Nicholas Walker, Haoyan Huo, Sanghoon Lee, Kevin Cruse, John Dagdelen, Alex Dunn, Kristin Aslaug Persson, Gerbrand Ceder, and Anubhav Jain. 2022. Quantifying the advantage of domain-specific pre-training on named entity recog- nition tasks in materials science. Patterns, 3. Lucy Lu Wang, Isabel Cachola, Jonathan Bragg, Evie (Yu-Yen) Cheng, Chelsea Hess Haupt, Matt Latzke, Bailey Kuehl, Madeleine van Zuylen, Linda M. Wag- ner, and Daniel S. Weld. 2021. Improving the acces- sibility of scientific documents: Current state, user needs, and a system solution to enhance scientific pdf accessibility for blind and low vision users. ArXiv, abs 2105.00076. Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar, Russell Reas, Jiangjiang Yang, Doug Burdick, Darrin Eide, Kathryn Funk, Yannis Katsis, Rodney Michael Kinney, Yunyao Li, Ziyang Liu, William Merrill, Paul Mooney, Dewey A. Murdick, Devvret Rishi, Jerry Sheehan, Zhihong Shen, Brandon Stilson, Alex D. Wade, Kuansan Wang, Nancy Xin Ru Wang, Christopher Wilhelm, Boya Xie, Douglas M. Ray- mond, Daniel S. Weld, Oren Etzioni, and Sebastian Kohlmeier. 2020. CORD-19: The COVID-19 open research dataset. In Proceedings of the 1st Work- shop on and developing datasets for scientific natural language processing for COVID-19 at ACL 2020, Online. Association for Computational Linguistics. Rosalee Wolfe, John McDonald, Ronan Johnson, Ben Sturr, Syd Klinghoffer, Anthony Bonzani, Andrew Alexander, and Nicole Barnekow. 2022. Supporting mouthing in signed languages: New innovations and a proposal for future corpus building. In Proceedings of the 7th International Workshop on Sign Language 504 Translation and Avatar Technology: The Junction of the Visual and the Textual: Challenges and Perspec- tives, pages 125-130, Marseille, France. European Language Resources Association. Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, and Lidong Zhou. 2021. LayoutLMv2: Multi-modal pre-training for visually-rich document understanding. In Proceed- ings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2579-2591, Online. Association for Computational Linguistics. Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, and Ming Zhou. 2019. Layoutlm: Pre-training of text and layout for document image understanding. Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery Data Mining. Xu Zhong, Jianbin Tang, and Antonio Jimeno Yepes. 2019. Publaynet: largest dataset ever for document layout analysis. In 2019 International Conference on Document Analysis and Recognition (International Conference on Document Analysis and Recognition), pages 1015-1022. IEEE. 505 A Appendix A.1 Comparison and Compatibility with XML One can view Layers as capturing content hier- archy (e.g., tokens vs sentences) similar to that of other structured document representations, like TEI XML trees. We note that Layers are stored as un- ordered attributes and don t require nesting. This allows for specific cross-layer referencing opera- tions that don t adhere to strict nesting relationships. For example: 1 for sentence in doc.sentences: 2 for line in sentence.lines: 3 ... Recall that a sentence can begin or end midway through a line and cross multiple lines (SS3.1). Sim- ilarly, not all lines are exactly contained within the boundaries of a sentence. As such, sentences and lines are not strictly nested within each other. This relationship would be difficult to encode in an XML format adhering to document tree structure. Regardless, the way we represent structure in documents is highly versatile. We demon- strate this by also implementing GrobidParser as an alternative to the PDF2TextParser in SS3.1. GrobidParser invokes Grobid to process PDFs, and reads the resulting TEI XML file generated by Grobid by converting each XML tag of a common level into an Entity of its own Layer. We use this to perform the evaluation in Table 2. A.2 Additional magelib Protocols and Utilities Serialization. Any Document and all of its Layers can be exported to a JSON format, and perfectly reconstructed: 1 import json 2 with open( .... json , w ) as f_out: 3 json.dump(doc.to_json(), f_out) 4 5 with open( ... json , r ) as f_in: 6 doc json.load(f_in) A.3 Evaluating papermage s CoreRecipe against Grobid Here, we detail how we performed the evaluation reported in SS3.3 (Table 2). We also provide a full breakdown by category in Table 3. As described earlier in the paper, Grobid is quite difficult to evaluate as it is developed with tight coupling between the PDF parser (pdfalto) and the models it employs to perform logical struc- ture recovery over the resulting token stream. As such, there is no straightforward way to run just the model components of Grobid on an alternative token stream like that provided in the S2-VL dataset. To perform this baseline evaluation, we ran the original PDFs that were annotated for S2-VL through our GrobidParser using v0.7.3. Grobid also returns bounding boxes of some predicted cat- egories (e.g., authors, abstract, paragraphs). We use these bounding boxes to create Entities that we annotate on a Document constructed manually from from S2-VL data. Using magelib cross-layer referencing, we were able to match Grobid predic- tions to S2-VL data to perform this evaluation. Though we found there are certain categories for which bounding box information was either not available (e.g., Titles) or Grobid simply did not re- turn that output (e.g., Figure text extraction). These are represented by zeros in Table 3, which con- tributes to the lower scores in Table 2 after macro averaging. For a more apples-to-apples compari- son, we also included a Grobid Subset evaluation which restricted to just categories in S2-VL for which Grobid produced bounding box information. In addition to Grobid, we evaluate two of our pro- vided Transformer-based models. The RoBERTa- large model is a Transformers token classification model that we finetuned on the S2-VL training set. The I-VILA model is a layout- infused Transformer model pretrained by Shen et al. (2022) on the S2-VL training set. Like we did with Grobid, we ran our CoreRecipe using these two models on the original PDFs in S2-VL, and per- formed a similar token mapping operation since our PDF2TextParser also produces a different token stream than that provided in S2-VL. At the end of the day, the Transformer-based models performed better at this task than Grobid. This is unsurprising given expected improvements using a Transformer model over a CRF or BiL- STM. The Transformer models were also trained on S2-VL data, which gave them an advantage over Grobid. Overall, this evaluation intended to show how papermage enables cross-system comparisons, even eschewing token stream incompatibility, and to illustrate an upper bound of the performance left on the table by existing software systems that don t use of state-of-the-art models. 506 Structure Category GROBIDCRF GROBIDNN RoBERTa I-VILA P R F1 P R F1 P R F1 P R F1 Abstract 81.9 89.1 85.3 85.3 89.8 87.5 89.2 93.7 91.4 97.4 98.3 97.8 Author 55.2 42.6 48.1 75.1 14.0 23.6 87.5 73.5 79.9 65.5 96.9 78.2 Bibliography 96.5 98.6 97.5 95.5 97.6 96.5 93.6 93.3 93.5 99.7 98.2 99.0 Caption 70.3 70.0 70.2 70.2 69.7 70.0 80.0 77.3 78.6 93.1 89.6 91.3 Equation 71.1 85.3 77.6 71.1 85.3 77.6 55.0 85.7 67.0 90.7 94.2 92.4 Figure 0.0 0.0 0.0 0.0 0.0 0.0 88.9 82.3 85.4 99.8 96.8 98.3 Footer 0.0 0.0 0.0 0.0 0.0 0.0 56.1 59.9 57.9 96.8 78.1 86.5 Footnote 0.0 0.0 0.0 0.0 0.0 0.0 59.8 44.3 50.9 80.2 93.5 86.3 Header 0.0 0.0 0.0 0.0 0.0 0.0 40.5 84.3 54.7 92.9 99.1 95.9 Keywords 0.0 0.0 0.0 0.0 0.0 0.0 93.8 97.1 95.4 96.9 99.4 98.1 List 0.0 0.0 0.0 0.0 0.0 0.0 61.9 63.8 62.9 76.7 82.4 79.4 Paragraph 94.5 89.8 92.1 94.4 89.9 92.1 93.5 93.0 93.3 98.7 97.9 98.3 Section 83.0 79.4 81.1 83.0 79.4 81.1 67.7 82.7 74.4 96.2 91.6 93.9 Table 97.3 58.6 73.2 97.9 58.6 73.3 94.7 71.8 81.7 96.1 94.9 95.5 Title 0.0 0.0 0.0 0.0 0.0 0.0 76.3 96.7 85.3 98.7 99.9 99.3 Macro Avg (Full S2-VL) 40.6 38.3 39.1 42.0 36.5 37.6 75.9 80.0 76.8 92.0 94.1 92.7 Macro Avg (Grobid Subset) 81.2 76.7 78.9 84.1 73.0 78.2 82.6 83.9 83.2 92.2 95.2 93.7 Table 3: Evaluating CoreRecipe for logical structure recovery on S2-VL . These are per-category metrics for Table 2. Metrics are computed for token-level classification, macro-averaged over categories. The Grobid Subset limits evaluation to only categories for which Grobid returns bounding box information, which was necessary for evaluation on S2-VL. 507"
    }
  ],
  "figures": [
    {
      "type": "figure",
      "number": "1",
      "caption": "Figure 1: papermage\u2019s document creation and represen-\ntation. (A) Recipes are turn-key methods for processing\na PDF. (B) They compose models operating across dif-\nferent data modalities and machine learning frameworks\nto extract document structure, which we conceptualize\nas layers of annotation that",
      "page": 1
    },
    {
      "type": "figure",
      "number": "2",
      "caption": "Figure 2: Entities are multimodal content units. Here,\nspans of a sentence are used to identify its text among\nall symbols, while boxes map its visual coordinates on\na page. spans and boxes can include non-contiguous\nunits, allowing great flexibility in Entities to handle\nlayout nuances. A sentence",
      "page": 3
    },
    {
      "type": "figure",
      "number": "1",
      "caption": "Figure 1). Each Layer is a sequence of content\nunits, called Entities, which store both textual\n(e.g.,\nspans,\nstrings) and visuospatial (e.g.,\nbounding boxes, pixel arrays) information:\n1 >>> sentences = Layer(entities =[\n2\nEntity (...), Entity (...) , ...\n3\n])\nSee Figure 2 for an example on how \u201cse",
      "page": 3
    },
    {
      "type": "figure",
      "number": "2",
      "caption": "Figure 2 for an example on how \u201csentences\u201d in\na scientific document are represented as Entities.\nSection \u00a73.2 explains in more detail how a user can\ngenerate Entities.\nMethods.\nmagelib also provides a set of func-\ntions for building and interacting with data: aug-\nmenting a Document with additional",
      "page": 3
    },
    {
      "type": "figure",
      "number": "3",
      "caption": "Figure 3).\nA Document that only contains doc.symbols\ncan be augmented with additional Layers:\n1 >>> paragraphs = Layer (...)\n2 >>> sentences = Layer (...)\n3 >>> tokens = Layer (...)\n4\n5 >>> doc.add(paragraphs , sentences , tokens)\nAdding Layers automatically grants users the\nability to iterate throu",
      "page": 3
    },
    {
      "type": "figure",
      "number": "3",
      "caption": "Figure 3 F):\n1 >>> query = Box(l=423, t=71, w=159, h=87)\n2 >>> selection = doc.find(query , \"tokens\")\n3 >>> [t.text for t in selection]\n4 [\"Techniques\", \"for\", \"collecting\", ...]\n497",
      "page": 3
    },
    {
      "type": "figure",
      "number": "1",
      "caption": "Figure 1. Revolt creates labels for unanimously labeled \u201ccertain\u201d items \n(e.g., cats and not cats), and surfaces categories of \u201cuncertain\u201d items \nenriched with crowd feedback (e.g., cats and dogs and cartoon cats in \nthe dotted middle region are annotated with crowd explanations). Rich \nstructures a",
      "page": 4
    },
    {
      "type": "figure",
      "number": "3",
      "caption": "Figure 3: Illustrates how Entities can be accessed flexibly in different ways: (A) Accessing the Entity of the first\nparagraph in the Document via its own Layer (B) Accessing a sentence via the paragraph Entity or directly via the\nsentences Layer (C) Similarly, the same tokens can be accessed via th",
      "page": 4
    },
    {
      "type": "figure",
      "number": "1",
      "caption": "Figure 1. ...\"\nRecipes can also be flexibly modified to sup-\nport development. For example, our current de-\nfault combines the pdfplumber PDF parsing utility\nwith the I-VILA (Shen et al., 2022) research model.\nWe show in Table 2 an evaluation comparing this\nagainst the same recipe but configured to",
      "page": 5
    },
    {
      "type": "figure",
      "number": "3",
      "caption": "Figure 3F.\nNext, she converts Document to her required text\nformat by following the traversal examples in \u00a73.1\n(e.g., using [s.text for s in doc.sentences]).\nWithin a few lines of code, Lucy has everything\nshe needs for text-only input to her QA pipeline.\nFormatting output.\nLucy runs her QA system\no",
      "page": 6
    },
    {
      "type": "figure",
      "number": "0",
      "caption": "Figure\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n88.9\n82.3\n85.4\n99.8\n96.8\n98.3\nFooter\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n56.1\n59.9\n57.9\n96.8\n78.1\n86.5\nFootnote\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n59.8\n44.3\n50.9\n80.2\n93.5\n86.3\nHeader\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n40.5\n84.3\n54.7\n92.9\n99.1\n95.9\nKeywords\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n93.8\n97.1\n95.4\n96.9\n9",
      "page": 13
    }
  ],
  "tables": [
    {
      "type": "table",
      "number": "1",
      "caption": "Table 1).\nWhile magelib\u2019s abstractions are general for\nvisually-rich documents, Predictors are opti-\nmized for parsing of scientific documents. They\nare designed to (1) be compatible with models\nfrom many different machine learning frameworks,\n(2) support inference with text-only, vision-only,\nand m",
      "page": 4
    },
    {
      "type": "table",
      "number": "1",
      "caption": "Table 1: Types of Predictors implemented in papermage.\nModel\nFull\nGrobid Subset\nP\nR\nF1\nP\nR\nF1\nGrobidCRF\n40.6\n38.3\n39.1\n81.2\n76.7\n78.9\nGrobidNN\n42.0\n36.5\n37.6\n84.1\n73.0\n78.2\nRoBERTa\n75.9\n80.0\n76.8\n82.6\n83.9\n83.2\nI-VILA\n92.0\n94.1\n92.7\n92.2\n95.2\n93.7\nTable 2: Evaluating performance of CoreRecipe for\nlo",
      "page": 5
    },
    {
      "type": "table",
      "number": "2",
      "caption": "Table 2: Evaluating performance of CoreRecipe for\nlogical structure recovery on S2-VL (Shen et al., 2022).\nMetrics are computed for token-level classification,\nmacro-averaged over categories. The \u201cGrobid Subset\u201d\nlimits evaluation to only categories for which Grobid\nreturns bounding box information,",
      "page": 5
    },
    {
      "type": "table",
      "number": "1",
      "caption": "Table 1 for a summary of supported Predictors.\n1 >>> import papermage as pm\n2 >>> cv = pm.BoxPredictor (...)\n3 >>> tables , figures = cv.predict(doc)\n4 >>> doc.add(tables , figures)\n5\n6 >>> nlp_neu = pm.SpanPredictor (...)\n7 >>> titles , authors = nlp_neu.predict(doc)\n8 >>> doc.add(titles , authors)",
      "page": 5
    },
    {
      "type": "table",
      "number": "2",
      "caption": "Table 2 an evaluation comparing this\nagainst the same recipe but configured to (1) swap\nI-VILA for a RoBERTa model, as well as (2) swap\nboth for Grobid API calls. We expect Recipes\nto appeal to two groups of users\u2014end-to-end con-\nsumers, and developers of high-level applications.\nThe former is compr",
      "page": 5
    },
    {
      "type": "table",
      "number": "1",
      "caption": "Table 1).\nFast iterations.\nLeveraging the bounding box\ndata from papermage to visually highlight the re-\ntrieved passages, Lucy suspects the retrieval com-\nponent is likely underperforming. She makes a sim-\nple edit from doc.sentences to doc.paragraphs\nand evaluates system performance under differen",
      "page": 6
    },
    {
      "type": "table",
      "number": "2",
      "caption": "Table 2.\nA.2\nAdditional magelib Protocols and\nUtilities\nSerialization.\nAny Document and all of its\nLayers can be exported to a JSON format, and\nperfectly reconstructed:\n1 import json\n2 with open(\".... json\", \"w\") as f_out:\n3\njson.dump(doc.to_json(), f_out)\n4\n5 with open(\"... json\", \"r\") as f_in:\n6\nd",
      "page": 12
    },
    {
      "type": "table",
      "number": "2",
      "caption": "Table 2). We also provide a full\nbreakdown by category in Table 3.\nAs described earlier in the paper, Grobid is quite\ndifficult to evaluate as it is developed with tight\ncoupling between the PDF parser (pdfalto) and\nthe models it employs to perform logical struc-\nture recovery over the resulting tok",
      "page": 12
    },
    {
      "type": "table",
      "number": "3",
      "caption": "Table 3.\nAs described earlier in the paper, Grobid is quite\ndifficult to evaluate as it is developed with tight\ncoupling between the PDF parser (pdfalto) and\nthe models it employs to perform logical struc-\nture recovery over the resulting token stream. As\nsuch, there is no straightforward way to run",
      "page": 12
    },
    {
      "type": "table",
      "number": "3",
      "caption": "Table 3, which con-\ntributes to the lower scores in Table 2 after macro\naveraging. For a more apples-to-apples compari-\nson, we also included a \u201cGrobid Subset\u201d evaluation\nwhich restricted to just categories in S2-VL for\nwhich Grobid produced bounding box information.\nIn addition to Grobid, we evalua",
      "page": 12
    },
    {
      "type": "table",
      "number": "2",
      "caption": "Table 2 after macro\naveraging. For a more apples-to-apples compari-\nson, we also included a \u201cGrobid Subset\u201d evaluation\nwhich restricted to just categories in S2-VL for\nwhich Grobid produced bounding box information.\nIn addition to Grobid, we evaluate two of our pro-\nvided Transformer-based models. T",
      "page": 12
    },
    {
      "type": "table",
      "number": "97",
      "caption": "Table\n97.3\n58.6\n73.2\n97.9\n58.6\n73.3\n94.7\n71.8\n81.7\n96.1\n94.9\n95.5\nTitle\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n76.3\n96.7\n85.3\n98.7\n99.9\n99.3\nMacro Avg\n(Full S2-VL)\n40.6\n38.3\n39.1\n42.0\n36.5\n37.6\n75.9\n80.0\n76.8\n92.0\n94.1\n92.7\nMacro Avg\n(Grobid Subset)\n81.2\n76.7\n78.9\n84.1\n73.0\n78.2\n82.6\n83.9\n83.2\n92.2\n95.2\n93.7\nTable",
      "page": 13
    },
    {
      "type": "table",
      "number": "3",
      "caption": "Table 3: Evaluating CoreRecipe for logical structure recovery on S2-VL (Shen et al., 2022). These are per-category\nmetrics for Table 2. Metrics are computed for token-level classification, macro-averaged over categories. The\n\u201cGrobid Subset\u201d limits evaluation to only categories for which Grobid retur",
      "page": 13
    },
    {
      "type": "table",
      "number": "2",
      "caption": "Table 2. Metrics are computed for token-level classification, macro-averaged over categories. The\n\u201cGrobid Subset\u201d limits evaluation to only categories for which Grobid returns bounding box information, which was\nnecessary for evaluation on S2-VL.\n507",
      "page": 13
    }
  ],
  "equations": [
    {
      "type": "equation",
      "number": "71",
      "page": 13
    }
  ],
  "references": [
    {
      "number": "2017",
      "text": "Revolt: Collaborative crowdsourcing for label-\ning machine learning datasets. In Proceedings of the\n2017 CHI Conference on Human Factors in Comput-\ning Systems, CHI \u201917, page 2334\u20132346, New York,\nNY, USA. Association for Computing Machinery.\nJoseph Chee Chang, Amy X. Zhang, Jonathan Bragg,\nAndrew Head, Kyle Lo, Doug Downey, and Daniel S.\nWeld. 2023. Citesee: Augmenting citations in scien-\ntific papers with persistent and personalized historical\ncontext. In Proceedings of the 2023 CHI Conference\non Human Factors in Computing Systems, CHI \u201923,\nNew York, NY, USA. Association for Computing\nMachinery.\nCatherine Chen, Zejiang Shen, Dan Klein, Gabriel\nStanovsky, Doug Downey, and Kyle Lo. 2023. Are\nlayout-infused language models robust to layout dis-\ntribution shifts? a case study with scientific docu-\nments. In Findings of the Association for Computa-\ntional Linguistics: ACL 2023, pages 13345\u201313360,\nToronto, Canada. Association for Computational Lin-\nguistics.\nIsaac Councill, C. Lee Giles, and Min-Yen Kan. 2008.\nParsCit: an open-source CRF reference string pars-\ning package. In Proceedings of the Sixth Interna-\ntional Conference on Language Resources and Eval-\nuation (LREC\u201908), Marrakech, Morocco. European\nLanguage Resources Association (ELRA).\nPradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan,\nNoah A. Smith, and Matt Gardner. 2021. A dataset\nof information-seeking questions and answers an-\nchored in research papers. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 4599\u20134610, On-\nline. Association for Computational Linguistics.\nRaymond Fok, Joseph Chee Chang, Tal August, Amy X.\nZhang, and Daniel S. Weld. 2023a. Qlarify: Bridg-\ning scholarly abstracts and papers with recursively\nexpandable summaries. arXiv, abs/2310.07581.\nRaymond Fok, Hita Kambhamettu, Luca Soldaini,\nJonathan Bragg, Kyle Lo, Marti Hearst, Andrew\nHead, and Daniel S Weld. 2023b. Scim: Intelligent\nskimming support for scientific papers. In Proceed-\nings of the 28th International Conference on Intelli-\ngent User Interfaces, IUI \u201923, page 476\u2013490, New\nYork, NY, USA. Association for Computing Machin-\nery.\nGrobid. 2008\u20132023. Grobid. https://github.com/\nkermitt2/grobid.\nYu Gu, Robert Tinn, Hao Cheng, Michael R. Lucas,\nNaoto Usuyama, Xiaodong Liu, Tristan Naumann,\nJianfeng Gao, and Hoifung Poon. 2020. Domain-\nspecific language model pretraining for biomedical\nnatural language processing. ACM Transactions on\nComputing for Healthcare (HEALTH), 3:1 \u2013 23.\nAndrew Head, Kyle Lo, Dongyeop Kang, Raymond\nFok, Sam Skjonsberg, Daniel S. Weld, and Marti A.\nHearst. 2021. Augmenting scientific papers with just-\nin-time, position-sensitive definitions of terms and\nsymbols. In Proceedings of the 2021 CHI Conference\non Human Factors in Computing Systems, CHI \u201921,\nNew York, NY, USA. Association for Computing\nMachinery.\nZhi Hong, Aswathy Ajith, James Pauloski, Eamon\nDuede, Kyle Chard, and Ian Foster. 2023. The dimin-\nishing returns of masked language models to science.\nIn Findings of the Association for Computational\nLinguistics: ACL 2023, pages 1270\u20131283, Toronto,\nCanada. Association for Computational Linguistics.\nPo-Wei Huang, Abhinav Ramesh Kashyap, Yanxia Qin,\nYajing Yang, and Min-Yen Kan. 2022a. Lightweight\ncontextual logical structure recovery. In Proceedings\nof the Third Workshop on Scholarly Document Pro-\ncessing, pages 37\u201348, Gyeongju, Republic of Korea.\nAssociation for Computational Linguistics.\nYupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, and\nFuru Wei. 2022b. Layoutlmv3: Pre-training for doc-\nument ai with unified text and image masking. Pro-\nceedings of the 30th ACM International Conference\non Multimedia.\nGautier Izacard, Mathilde Caron, Lucas Hosseini, Sebas-\ntian Riedel, Piotr Bojanowski, Armand Joulin, and\nEdouard Grave. 2022. Unsupervised dense informa-\ntion retrieval with contrastive learning. Transactions\non Machine Learning Research.\nSarthak Jain, Madeleine van Zuylen, Hannaneh Ha-\njishirzi, and Iz Beltagy. 2020. SciREX: A challenge\ndataset for document-level information extraction. In\n502\n\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics, pages 7506\u2013\n7516, Online. Association for Computational Lin-\nguistics.\nHyeonsu B. Kang, Joseph Chee Chang, Yongsung Kim,\nand Aniket Kittur. 2022. Threddy: An interactive\nsystem for personalized thread-based exploration and\norganization of scientific literature. In Proceedings of\nthe 35th Annual ACM Symposium on User Interface\nSoftware and Technology, UIST \u201922, New York, NY,\nUSA. Association for Computing Machinery.\nHyeonsu B. Kang, Sherry Tongshuang Wu, Joseph Chee\nChang, and Aniket Kittur. 2023. Synergi: A mixed-\ninitiative system for scholarly synthesis and sense-\nmaking. In Proceedings of the 36th Annual ACM\nSymposium on User Interface Software and Technol-\nogy. Association for Computing Machinery.\nTae Soo Kim, Matt Latzke, Jonathan Bragg, Amy X.\nZhang, and Joseph Chee Chang. 2023. Papeos: Aug-\nmenting research papers with talk videos. In Proceed-\nings of the 36th Annual ACM Symposium on User\nInterface Software and Technology.\nRodney Kinney, Chloe Anastasiades, Russell Authur,\nIz Beltagy, Jonathan Bragg, Alexandra Buraczyn-\nski, Isabel Cachola, Stefan Candra, Yoganand Chan-\ndrasekhar, Arman Cohan, Miles Crawford, Doug\nDowney, Jason Dunkelberger, Oren Etzioni, Rob\nEvans, Sergey Feldman, Joseph Gorney, David Gra-\nham, Fangzhou Hu, Regan Huff, Daniel King, Se-\nbastian Kohlmeier, Bailey Kuehl, Michael Langan,\nDaniel Lin, Haokun Liu, Kyle Lo, Jaron Lochner,\nKelsey MacMillan, Tyler Murray, Chris Newell,\nSmita Rao, Shaurya Rohatgi, Paul Sayre, Zejiang\nShen, Amanpreet Singh, Luca Soldaini, Shivashankar\nSubramanian, Amber Tanaka, Alex D. Wade, Linda\nWagner, Lucy Lu Wang, Chris Wilhelm, Caroline Wu,\nJiangjiang Yang, Angele Zamarron, Madeleine Van\nZuylen, and Daniel S. Weld. 2023. The Semantic\nScholar Open Data Platform. ArXiv, abs/2301.10140.\nWei-Jen Ko, Te-yuan Chen, Yiyan Huang, Greg Durrett,\nand Junyi Jessy Li. 2020. Inquisitive question gener-\nation for high level text comprehension. In Proceed-\nings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), pages\n6544\u20136555, Online. Association for Computational\nLinguistics.\nBenjamin Charles Germain Lee, Jaime Mears, Eileen\nJakeway, Meghan Ferriter, Chris Adams, Nathan\nYarasavage, Deborah Thomas, Kate Zwaard, and\nDaniel S. Weld. 2020.\nThe newspaper navigator\ndataset: Extracting headlines and visual content from\n16 million historic newspaper pages in chronicling\namerica. In Proceedings of the 29th ACM Interna-\ntional Conference on Information & Knowledge Man-\nagement, CIKM \u201920, page 3055\u20133062, New York,\nNY, USA. Association for Computing Machinery.\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon\nKim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang."
    },
    {
      "number": "2019",
      "text": "BioBERT: a pre-trained biomedical language\nrepresentation model for biomedical text mining.\nBioinformatics, 36(4):1234\u20131240.\nYoonjoo Lee, Kyungjae Lee, Sunghyun Park, Dasol\nHwang, Jaehyeon Kim, Hong-In Lee, and Moontae\nLee. 2023. QASA: Advanced question answering on\nscientific articles. In Proceedings of the 40th Inter-\nnational Conference on Machine Learning, volume\n202 of Proceedings of Machine Learning Research,\npages 19036\u201319052. PMLR.\n\u00c9lise Lincker, Olivier Pons, Camille Guinaudeau, Is-\nabelle Barbet, J\u00e9r\u00f4me Dupire, C\u00e9line Hudelot, Vin-\ncent Mousseau, and Caroline Huron. 2023. Layout\nand activity-based textbook modeling for automatic\npdf textbook extraction. In iTextbooks@AIED.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoBERTa: A Robustly Optimized BERT Pretrain-\ning Approach. ArXiv, abs/1907.11692.\nKyle Lo, Joseph Chee Chang, Andrew Head, Jonathan\nBragg, Amy X. Zhang, Cassidy Trier, Chloe Anas-\ntasiades, Tal August, Russell Authur, Danielle Bragg,\nErin Bransom, Isabel Cachola, Stefan Candra, Yo-\nganand Chandrasekhar, Yen-Sung Chen, Evie Yu-\nYen Cheng, Yvonne Chou, Doug Downey, Rob\nEvans, Raymond Fok, Fangzhou Hu, Regan Huff,\nDongyeop Kang, Tae Soo Kim, Rodney Kinney,\nAniket Kittur, Hyeonsu Kang, Egor Klevak, Bai-\nley Kuehl, Michael Langan, Matt Latzke, Jaron\nLochner, Kelsey MacMillan, Eric Marsh, Tyler Mur-\nray, Aakanksha Naik, Ngoc-Uyen Nguyen, Srishti\nPalani, Soya Park, Caroline Paulic, Napol Rachata-\nsumrit, Smita Rao, Paul Sayre, Zejiang Shen, Pao\nSiangliulue, Luca Soldaini, Huy Tran, Madeleine van\nZuylen, Lucy Lu Wang, Christopher Wilhelm, Caro-\nline Wu, Jiangjiang Yang, Angele Zamarron, Marti A.\nHearst, and Daniel S. Weld. 2023. The Semantic\nReader Project: Augmenting Scholarly Documents\nthrough AI-Powered Interactive Reading Interfaces.\nArXiv, abs/2303.14334.\nKyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kin-\nney, and Daniel Weld. 2020. S2ORC: The semantic\nscholar open research corpus. In Proceedings of the\n58th Annual Meeting of the Association for Compu-\ntational Linguistics, pages 4969\u20134983, Online. Asso-\nciation for Computational Linguistics.\nRenqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng\nZhang, Hoifung Poon, and Tie-Yan Liu. 2022.\nBiogpt:\nGenerative pre-trained transformer for\nbiomedical text generation and mining. Briefings\nin bioinformatics.\nMark Neumann, Daniel King, Iz Beltagy, and Waleed\nAmmar. 2019. ScispaCy: Fast and robust models\nfor biomedical natural language processing. In Pro-\nceedings of the 18th BioNLP Workshop and Shared\nTask, pages 319\u2013327, Florence, Italy. Association for\nComputational Linguistics.\n503\n\nBenjamin Newman, Luca Soldaini, Raymond Fok, Ar-\nman Cohan, and Kyle Lo. 2023. A question answer-\ning framework for decontextualizing user-facing snip-\npets from scientific documents. In Proceedings of the\n2023 Conference on Empirical Methods in Natural\nLanguage Processing (EMNLP).\nOrganizers of Queer in AI, Anaelia Ovalle, Arjun Sub-\nramonian, Ashwin Singh, Claas Voelcker, Danica J.\nSutherland, Davide Locatelli, Eva Breznik, Filip Klu-\nbicka, Hang Yuan, Hetvi J, Huan Zhang, Jaidev\nShriram, Kruno Lehman, Luca Soldaini, Maarten\nSap, Marc Peter Deisenroth, Maria Leonor Pacheco,\nMaria Ryskina, Martin Mundt, Milind Agarwal, Nyx\nMclean, Pan Xu, A Pranav, Raj Korpan, Ruchira\nRay, Sarah Mathew, Sarthak Arora, St John, Tanvi\nAnand, Vishakha Agrawal, William Agnew, Yanan\nLong, Zijie J. Wang, Zeerak Talat, Avijit Ghosh,\nNathaniel Dennler, Michael Noseworthy, Sharvani\nJha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko,\nAndrew Mcnamara, Raphael Gontijo-Lopes, Alex\nMarkham, Evyn Dong, Jackie Kay, Manu Saraswat,\nNikhil Vytla, and Luke Stark. 2023. Queer In AI: A\nCase Study in Community-Led Participatory AI. In\nProceedings of the 2023 ACM Conference on Fair-\nness, Accountability, and Transparency, FAccT \u201923,\npage 1882\u20131895, New York, NY, USA. Association\nfor Computing Machinery.\nNapol Rachatasumrit, Jonathan Bragg, Amy X. Zhang,\nand Daniel S Weld. 2022. Citeread: Integrating lo-\ncalized citation contexts into scientific paper reading.\nIn 27th International Conference on Intelligent User\nInterfaces, IUI \u201922, page 707\u2013719, New York, NY,\nUSA. Association for Computing Machinery.\nShaoqing Ren, Kaiming He, Ross B. Girshick, and Jian\nSun. 2015. Faster r-cnn: Towards real-time object de-\ntection with region proposal networks. IEEE Trans-\nactions on Pattern Analysis and Machine Intelligence,\n39:1137\u20131149.\nNipun Sadvilkar and Mark Neumann. 2020. PySBD:\nPragmatic sentence boundary disambiguation. In\nProceedings of Second Workshop for NLP Open\nSource Software (NLP-OSS), pages 110\u2013114, Online.\nAssociation for Computational Linguistics.\nZejiang Shen, Kyle Lo, Lucy Lu Wang, Bailey Kuehl,\nDaniel S. Weld, and Doug Downey. 2022. VILA: Im-\nproving structured content extraction from scientific\nPDFs using visual layout groups. Transactions of the\nAssociation for Computational Linguistics, 10:376\u2013"
    },
    {
      "number": "392",
      "text": "Zejiang Shen, Ruochen Zhang, Melissa Dell, B. Lee,\nJacob Carlson, and Weining Li. 2021. Layoutparser:\nA unified toolkit for deep learning based document\nimage analysis. In IEEE International Conference\non Document Analysis and Recognition.\nSanjay Subramanian, Lucy Lu Wang, Ben Bogin,\nSachin Mehta, Madeleine van Zuylen, Sravanthi\nParasa, Sameer Singh, Matt Gardner, and Hannaneh\nHajishirzi. 2020. MedICaT: A dataset of medical\nimages, captions, and textual references. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2020, pages 2112\u20132120, Online. Association\nfor Computational Linguistics.\nM. Tan, R. Pang, and Q. V. Le. 2020. Efficientdet:\nScalable and efficient object detection.\nIn 2020\nIEEE/CVF Conference on Computer Vision and Pat-\ntern Recognition (CVPR), pages 10778\u201310787, Los\nAlamitos, CA, USA. IEEE Computer Society.\nRoss Taylor, Marcin Kardas, Guillem Cucurull, Thomas\nScialom, Anthony S. Hartshorn, Elvis Saravia, An-\ndrew Poulton, Viktor Kerkez, and Robert Stojnic."
    },
    {
      "number": "2022",
      "text": "Galactica: A large language model for science.\nArXiv, abs/2211.09085.\npdf2image. 2023.\npdf2image.\nhttps://github.\ncom/Belval/pdf2image.\npdfplumber. 2023. pdfplumber. https://github.\ncom/jsvine/pdfplumber.\nDominika Tkaczyk, Pawe\u0142 Szostek, Mateusz Fedo-\nryszak, Piotr Jan Dendek, and Lukasz Bolikowski."
    },
    {
      "number": "2015",
      "text": "Cermine: Automatic extraction of structured\nmetadata from scientific literature. Int. J. Doc. Anal.\nRecognit., 18(4):317\u2013335.\nAmalie Trewartha, Nicholas Walker, Haoyan Huo,\nSanghoon Lee, Kevin Cruse, John Dagdelen, Alex\nDunn, Kristin Aslaug Persson, Gerbrand Ceder, and\nAnubhav Jain. 2022. Quantifying the advantage of\ndomain-specific pre-training on named entity recog-\nnition tasks in materials science. Patterns, 3.\nLucy Lu Wang, Isabel Cachola, Jonathan Bragg, Evie\n(Yu-Yen) Cheng, Chelsea Hess Haupt, Matt Latzke,\nBailey Kuehl, Madeleine van Zuylen, Linda M. Wag-\nner, and Daniel S. Weld. 2021. Improving the acces-\nsibility of scientific documents: Current state, user\nneeds, and a system solution to enhance scientific pdf\naccessibility for blind and low vision users. ArXiv,\nabs/2105.00076.\nLucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar,\nRussell Reas, Jiangjiang Yang, Doug Burdick, Darrin\nEide, Kathryn Funk, Yannis Katsis, Rodney Michael\nKinney, Yunyao Li, Ziyang Liu, William Merrill,\nPaul Mooney, Dewey A. Murdick, Devvret Rishi,\nJerry Sheehan, Zhihong Shen, Brandon Stilson,\nAlex D. Wade, Kuansan Wang, Nancy Xin Ru Wang,\nChristopher Wilhelm, Boya Xie, Douglas M. Ray-\nmond, Daniel S. Weld, Oren Etzioni, and Sebastian\nKohlmeier. 2020. CORD-19: The COVID-19 open\nresearch dataset. In Proceedings of the 1st Work-\nshop on NLP for COVID-19 at ACL 2020, Online.\nAssociation for Computational Linguistics.\nRosalee Wolfe, John McDonald, Ronan Johnson, Ben\nSturr, Syd Klinghoffer, Anthony Bonzani, Andrew\nAlexander, and Nicole Barnekow. 2022. Supporting\nmouthing in signed languages: New innovations and\na proposal for future corpus building. In Proceedings\nof the 7th International Workshop on Sign Language\n504\n\nTranslation and Avatar Technology: The Junction of\nthe Visual and the Textual: Challenges and Perspec-\ntives, pages 125\u2013130, Marseille, France. European\nLanguage Resources Association.\nYang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu\nWei, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha\nZhang, Wanxiang Che, Min Zhang, and Lidong Zhou."
    },
    {
      "number": "2021",
      "text": "LayoutLMv2: Multi-modal pre-training for\nvisually-rich document understanding. In Proceed-\nings of the 59th Annual Meeting of the Association for\nComputational Linguistics and the 11th International\nJoint Conference on Natural Language Processing\n(Volume 1: Long Papers), pages 2579\u20132591, Online.\nAssociation for Computational Linguistics.\nYiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu\nWei, and Ming Zhou. 2019. Layoutlm: Pre-training\nof text and layout for document image understanding.\nProceedings of the 26th ACM SIGKDD International\nConference on Knowledge Discovery & Data Mining.\nXu Zhong, Jianbin Tang, and Antonio Jimeno Yepes."
    },
    {
      "number": "2019",
      "text": "Publaynet: largest dataset ever for document\nlayout analysis. In 2019 International Conference on\nDocument Analysis and Recognition (ICDAR), pages\n1015\u20131022. IEEE.\n505\n\nA"
    }
  ],
  "acronyms": {
    "NLP": "and developing datasets for scientific natural language processing",
    "CV": "computer vision",
    "ELRA": "European Language Resources Association",
    "HEALTH": "ACM Transactions on Computing for Healthcare",
    "EMNLP": "Conference on Empirical Methods in Natural Language Processing",
    "CVPR": "IEEE CVF Conference on Computer Vision and Pat- tern Recognition",
    "ICDAR": "International Conference on Document Analysis and Recognition"
  }
}