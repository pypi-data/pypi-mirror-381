Metadata-Version: 2.4
Name: ruleboost
Version: 0.4.0
Summary: Efficient interpretable rule ensemble learning via gradient boosting implemented with numba.
Author-email: Mario Boley <mario.boley@gmail.com>, Fan Yang <fan.yang1@monash.edu>
License-Expression: MIT
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy<2.3,>=2.2.6
Requires-Dist: scipy<1.16,>=1.15.3
Requires-Dist: numba<1.0,>=0.61.2
Requires-Dist: scikit-learn<2.0,>=1.7.0
Requires-Dist: optikon<0.4,==0.3.0
Dynamic: license-file

# RuleBoost

Learn additive rule ensembles via gradient boosting.

## Usage Example for Classification

```python
>>> from ruleboost import RuleBoostingClassifier
>>> import numpy as np
>>> x = np.array([[0.1], [0.2], [0.3], [0.4], [0.5], [0.6], [0.7], [0.8], [0.9]])
>>> y = np.array([0, 0, 0, 1, 1, 1, 0, 0, 0])
>>> model = RuleBoostingClassifier(num_rules=1, fit_intercept=True).fit(x, y)
>>> print(model.rules_str()) # doctest: +NORMALIZE_WHITESPACE
    -0.475 if  
    +0.675 if x1 >= 0.400 & x1 <= 0.600
>>> model.predict(x)
array([0, 0, 0, 1, 1, 1, 0, 0, 0])
>>> np.round(model.predict_proba(x)[:, 1], 2)
array([0.38, 0.38, 0.38, 0.55, 0.55, 0.55, 0.38, 0.38, 0.38])
```
